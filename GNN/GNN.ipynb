{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced paper: Neural Graph Collaborative Filtering \n",
    "# https://arxiv.org/abs/1905.08108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.load_data import Data\n",
    "from utils.helper_functions import early_stopping,\\\n",
    "                                   train,\\\n",
    "                                   split_matrix,\\\n",
    "                                   compute_ndcg_k,\\\n",
    "                                   eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim, layers, reg, node_dropout, mess_dropout,\n",
    "        adj_mtx):\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize Class attributes\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.adj_mtx = adj_mtx\n",
    "        self.laplacian = adj_mtx - sp.eye(adj_mtx.shape[0])\n",
    "        self.reg = reg\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(self.layers)\n",
    "        self.node_dropout = node_dropout\n",
    "        self.mess_dropout = mess_dropout\n",
    "\n",
    "        #self.u_g_embeddings = nn.Parameter(torch.empty(n_users, emb_dim+np.sum(self.layers)))\n",
    "        #self.i_g_embeddings = nn.Parameter(torch.empty(n_items, emb_dim+np.sum(self.layers)))\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weight_dict = self._init_weights()\n",
    "        print(\"Weights initialized.\")\n",
    "\n",
    "        # Create Matrix 'A', PyTorch sparse tensor of SP adjacency_mtx\n",
    "        self.A = self._convert_sp_mat_to_sp_tensor(self.adj_mtx)\n",
    "        self.L = self._convert_sp_mat_to_sp_tensor(self.laplacian)\n",
    "\n",
    "    # initialize weights\n",
    "    def _init_weights(self):\n",
    "        print(\"Initializing weights...\")\n",
    "        weight_dict = nn.ParameterDict()\n",
    "\n",
    "        initializer = torch.nn.init.xavier_uniform_\n",
    "        \n",
    "        weight_dict['user_embedding'] = nn.Parameter(initializer(torch.empty(self.n_users, self.emb_dim).to(device)))\n",
    "        weight_dict['item_embedding'] = nn.Parameter(initializer(torch.empty(self.n_items, self.emb_dim).to(device)))\n",
    "\n",
    "        weight_size_list = [self.emb_dim] + self.layers\n",
    "      \n",
    "        for k in range(self.n_layers):\n",
    "            weight_dict['W_gc_%d' %k] = nn.Parameter(initializer(torch.empty(weight_size_list[k], weight_size_list[k+1]).to(device)))\n",
    "            weight_dict['b_gc_%d' %k] = nn.Parameter(initializer(torch.empty(1, weight_size_list[k+1]).to(device)))\n",
    "            \n",
    "            weight_dict['W_bi_%d' %k] = nn.Parameter(initializer(torch.empty(weight_size_list[k], weight_size_list[k+1]).to(device)))\n",
    "            weight_dict['b_bi_%d' %k] = nn.Parameter(initializer(torch.empty(1, weight_size_list[k+1]).to(device)))\n",
    "           \n",
    "        return weight_dict\n",
    "\n",
    "    # convert sparse matrix into sparse PyTorch tensor\n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        \"\"\"\n",
    "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X = Adjacency matrix, scipy sparse matrix\n",
    "        \"\"\"\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "\n",
    "    # apply node_dropout\n",
    "    def _droupout_sparse(self, X):\n",
    "        \"\"\"\n",
    "        Drop individual locations in X\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "        X = adjacency matrix (PyTorch sparse tensor)\n",
    "        dropout = fraction of nodes to drop\n",
    "        noise_shape = number of non non-zero entries of X\n",
    "        \"\"\"\n",
    "        \n",
    "        node_dropout_mask = ((self.node_dropout) + torch.rand(X._nnz())).floor().bool().to(device)\n",
    "        i = X.coalesce().indices()\n",
    "        v = X.coalesce()._values()\n",
    "        i[:,node_dropout_mask] = 0\n",
    "        v[node_dropout_mask] = 0\n",
    "        X_dropout = torch.sparse.FloatTensor(i, v, X.shape).to(X.device)\n",
    "\n",
    "        return  X_dropout.mul(1/(1-self.node_dropout))\n",
    "\n",
    "    def forward(self, u, i, j):\n",
    "        \"\"\"\n",
    "        Computes the forward pass\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "        u = user\n",
    "        i = positive item (user interacted with item)\n",
    "        j = negative item (user did not interact with item)\n",
    "        \"\"\"\n",
    "        # apply drop-out mask\n",
    "        A_hat = self._droupout_sparse(self.A) if self.node_dropout > 0 else self.A\n",
    "        L_hat = self._droupout_sparse(self.L) if self.node_dropout > 0 else self.L\n",
    "\n",
    "        ego_embeddings = torch.cat([self.weight_dict['user_embedding'], self.weight_dict['item_embedding']], 0)\n",
    "\n",
    "        all_embeddings = [ego_embeddings]\n",
    "\n",
    "        # forward pass for 'n' propagation layers\n",
    "        for k in range(self.n_layers):\n",
    "\n",
    "            # weighted sum messages of neighbours\n",
    "            side_embeddings = torch.sparse.mm(A_hat, ego_embeddings)\n",
    "            side_L_embeddings = torch.sparse.mm(L_hat, ego_embeddings)\n",
    "\n",
    "            # transformed sum weighted sum messages of neighbours\n",
    "            sum_embeddings = torch.matmul(side_embeddings, self.weight_dict['W_gc_%d' % k]) + self.weight_dict['b_gc_%d' % k]\n",
    "\n",
    "            # bi messages of neighbours\n",
    "            bi_embeddings = torch.mul(ego_embeddings, side_L_embeddings)\n",
    "            # transformed bi messages of neighbours\n",
    "            bi_embeddings = torch.matmul(bi_embeddings, self.weight_dict['W_bi_%d' % k]) + self.weight_dict['b_bi_%d' % k]\n",
    "\n",
    "            # non-linear activation \n",
    "            ego_embeddings = F.leaky_relu(sum_embeddings + bi_embeddings)\n",
    "            # + message dropout\n",
    "            mess_dropout_mask = nn.Dropout(self.mess_dropout)\n",
    "            ego_embeddings = mess_dropout_mask(ego_embeddings)\n",
    "\n",
    "            # normalize activation\n",
    "            norm_embeddings = F.normalize(ego_embeddings, p=2, dim=1)\n",
    "\n",
    "            all_embeddings.append(norm_embeddings)\n",
    "\n",
    "        all_embeddings = torch.cat(all_embeddings, 1)\n",
    "        \n",
    "        # back to user/item dimension\n",
    "        u_g_embeddings, i_g_embeddings = all_embeddings.split([self.n_users, self.n_items], 0)\n",
    "\n",
    "        self.u_g_embeddings = nn.Parameter(u_g_embeddings)\n",
    "        self.i_g_embeddings = nn.Parameter(i_g_embeddings)\n",
    "        \n",
    "        u_emb = u_g_embeddings[u] # user embeddings\n",
    "        p_emb = i_g_embeddings[i] # positive item embeddings\n",
    "        n_emb = i_g_embeddings[j] # negative item embeddings\n",
    "\n",
    "        y_ui = torch.mul(u_emb, p_emb).sum(dim=1)\n",
    "        y_uj = torch.mul(u_emb, n_emb).sum(dim=1)\n",
    "        log_prob = (torch.log(torch.sigmoid(y_ui-y_uj))).mean()\n",
    "\n",
    "        # compute bpr-loss\n",
    "        bpr_loss = -log_prob\n",
    "        if self.reg > 0.:\n",
    "            l2norm = (torch.sum(u_emb**2)/2. + torch.sum(p_emb**2)/2. + torch.sum(n_emb**2)/2.) / u_emb.shape[0]\n",
    "            l2reg  = self.reg*l2norm\n",
    "            bpr_loss =  -log_prob + l2reg\n",
    "\n",
    "        return bpr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=943, n_items=1682\n",
      "n_interactions=100000\n",
      "n_train=80064, n_test=19936, sparsity=0.06305\n",
      "Creating interaction matrices R_train and R_test...\n",
      "Complete. Interaction matrices R_train and R_test created in 0.8148708343505859 sec\n",
      "Loaded adjacency-matrix (shape: (2625, 2625) ) in 0.00932002067565918 sec.\n"
     ]
    }
   ],
   "source": [
    "batch_size=1024\n",
    "data_dir='./data/'\n",
    "dataset='ml-100k'\n",
    "emb_dim=64\n",
    "eval_N=1\n",
    "k=20\n",
    "layers=[64]\n",
    "lr=0.0001\n",
    "mess_dropout=0.1\n",
    "n_epochs=400\n",
    "node_dropout=0.0\n",
    "reg=1e-05\n",
    "esults_dir='results'\n",
    "save_results=1\n",
    "\n",
    "# generate the NGCF-adjacency matrix\n",
    "data_generator = Data(path=data_dir + dataset, batch_size=batch_size)\n",
    "adj_mtx = data_generator.get_adj_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights initialized.\n"
     ]
    }
   ],
   "source": [
    "# create model name and save\n",
    "modelname =  \"NGCF\" + \\\n",
    "        \"_bs_\" + str(batch_size) + \\\n",
    "        \"_nemb_\" + str(emb_dim) + \\\n",
    "        \"_layers_\" + str(layers) + \\\n",
    "        \"_nodedr_\" + str(node_dropout) + \\\n",
    "        \"_messdr_\" + str(mess_dropout) + \\\n",
    "        \"_reg_\" + str(reg) + \\\n",
    "        \"_lr_\"  + str(lr)\n",
    "\n",
    "# create NGCF model\n",
    "model = NGCF(data_generator.n_users, \n",
    "                 data_generator.n_items,\n",
    "                 emb_dim,\n",
    "                 layers,\n",
    "                 reg,\n",
    "                 node_dropout,\n",
    "                 mess_dropout,\n",
    "                 adj_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at 2021-04-10 21:40:29.014338\n",
      "Using cuda for computations\n",
      "Params on CUDA: True\n",
      "Epoch: 0, Training time: 2.64s, Loss: 54.7800\n",
      "Evaluate current model:\n",
      " Epoch: 0, Validation time: 0.69s \n",
      " Loss: 54.7800: \n",
      " Recall@20: 0.0103 \n",
      " NDCG@20: 0.0743\n",
      "Epoch: 1, Training time: 2.64s, Loss: 54.6990\n",
      "Evaluate current model:\n",
      " Epoch: 1, Validation time: 0.65s \n",
      " Loss: 54.6990: \n",
      " Recall@20: 0.0112 \n",
      " NDCG@20: 0.0778\n",
      "Epoch: 2, Training time: 2.59s, Loss: 54.6064\n",
      "Evaluate current model:\n",
      " Epoch: 2, Validation time: 0.66s \n",
      " Loss: 54.6064: \n",
      " Recall@20: 0.0109 \n",
      " NDCG@20: 0.0759\n",
      "Epoch: 3, Training time: 2.69s, Loss: 54.5517\n",
      "Evaluate current model:\n",
      " Epoch: 3, Validation time: 0.68s \n",
      " Loss: 54.5517: \n",
      " Recall@20: 0.0140 \n",
      " NDCG@20: 0.0892\n",
      "Epoch: 4, Training time: 2.61s, Loss: 54.4445\n",
      "Evaluate current model:\n",
      " Epoch: 4, Validation time: 0.65s \n",
      " Loss: 54.4445: \n",
      " Recall@20: 0.0141 \n",
      " NDCG@20: 0.0881\n",
      "Epoch: 5, Training time: 2.61s, Loss: 54.3108\n",
      "Evaluate current model:\n",
      " Epoch: 5, Validation time: 0.62s \n",
      " Loss: 54.3108: \n",
      " Recall@20: 0.0161 \n",
      " NDCG@20: 0.0969\n",
      "Epoch: 6, Training time: 2.63s, Loss: 54.1072\n",
      "Evaluate current model:\n",
      " Epoch: 6, Validation time: 0.64s \n",
      " Loss: 54.1072: \n",
      " Recall@20: 0.0192 \n",
      " NDCG@20: 0.1051\n",
      "Epoch: 7, Training time: 2.61s, Loss: 53.8340\n",
      "Evaluate current model:\n",
      " Epoch: 7, Validation time: 0.62s \n",
      " Loss: 53.8340: \n",
      " Recall@20: 0.0234 \n",
      " NDCG@20: 0.1253\n",
      "Epoch: 8, Training time: 2.61s, Loss: 53.3746\n",
      "Evaluate current model:\n",
      " Epoch: 8, Validation time: 0.62s \n",
      " Loss: 53.3746: \n",
      " Recall@20: 0.0267 \n",
      " NDCG@20: 0.1378\n",
      "Epoch: 9, Training time: 2.60s, Loss: 52.6101\n",
      "Evaluate current model:\n",
      " Epoch: 9, Validation time: 0.62s \n",
      " Loss: 52.6101: \n",
      " Recall@20: 0.0462 \n",
      " NDCG@20: 0.1734\n",
      "Epoch: 10, Training time: 2.60s, Loss: 51.3430\n",
      "Evaluate current model:\n",
      " Epoch: 10, Validation time: 0.61s \n",
      " Loss: 51.3430: \n",
      " Recall@20: 0.0550 \n",
      " NDCG@20: 0.1955\n",
      "Epoch: 11, Training time: 2.59s, Loss: 49.0804\n",
      "Evaluate current model:\n",
      " Epoch: 11, Validation time: 0.61s \n",
      " Loss: 49.0804: \n",
      " Recall@20: 0.0654 \n",
      " NDCG@20: 0.2305\n",
      "Epoch: 12, Training time: 2.59s, Loss: 46.1354\n",
      "Evaluate current model:\n",
      " Epoch: 12, Validation time: 0.60s \n",
      " Loss: 46.1354: \n",
      " Recall@20: 0.0783 \n",
      " NDCG@20: 0.2420\n",
      "Epoch: 13, Training time: 2.62s, Loss: 43.5063\n",
      "Evaluate current model:\n",
      " Epoch: 13, Validation time: 0.61s \n",
      " Loss: 43.5063: \n",
      " Recall@20: 0.0883 \n",
      " NDCG@20: 0.2885\n",
      "Epoch: 14, Training time: 2.65s, Loss: 41.6688\n",
      "Evaluate current model:\n",
      " Epoch: 14, Validation time: 0.61s \n",
      " Loss: 41.6688: \n",
      " Recall@20: 0.0931 \n",
      " NDCG@20: 0.2887\n",
      "Epoch: 15, Training time: 2.63s, Loss: 40.4350\n",
      "Evaluate current model:\n",
      " Epoch: 15, Validation time: 0.61s \n",
      " Loss: 40.4350: \n",
      " Recall@20: 0.1025 \n",
      " NDCG@20: 0.3197\n",
      "Epoch: 16, Training time: 2.59s, Loss: 39.6296\n",
      "Evaluate current model:\n",
      " Epoch: 16, Validation time: 0.60s \n",
      " Loss: 39.6296: \n",
      " Recall@20: 0.1104 \n",
      " NDCG@20: 0.3280\n",
      "Epoch: 17, Training time: 2.58s, Loss: 38.9949\n",
      "Evaluate current model:\n",
      " Epoch: 17, Validation time: 0.60s \n",
      " Loss: 38.9949: \n",
      " Recall@20: 0.1170 \n",
      " NDCG@20: 0.3449\n",
      "Epoch: 18, Training time: 2.58s, Loss: 38.3855\n",
      "Evaluate current model:\n",
      " Epoch: 18, Validation time: 0.60s \n",
      " Loss: 38.3855: \n",
      " Recall@20: 0.1353 \n",
      " NDCG@20: 0.3655\n",
      "Epoch: 19, Training time: 2.58s, Loss: 37.8637\n",
      "Evaluate current model:\n",
      " Epoch: 19, Validation time: 0.60s \n",
      " Loss: 37.8637: \n",
      " Recall@20: 0.1389 \n",
      " NDCG@20: 0.3736\n",
      "Epoch: 20, Training time: 2.60s, Loss: 37.3879\n",
      "Evaluate current model:\n",
      " Epoch: 20, Validation time: 0.61s \n",
      " Loss: 37.3879: \n",
      " Recall@20: 0.1392 \n",
      " NDCG@20: 0.3808\n",
      "Epoch: 21, Training time: 2.64s, Loss: 37.0668\n",
      "Evaluate current model:\n",
      " Epoch: 21, Validation time: 0.61s \n",
      " Loss: 37.0668: \n",
      " Recall@20: 0.1437 \n",
      " NDCG@20: 0.3934\n",
      "Epoch: 22, Training time: 2.60s, Loss: 36.6849\n",
      "Evaluate current model:\n",
      " Epoch: 22, Validation time: 0.61s \n",
      " Loss: 36.6849: \n",
      " Recall@20: 0.1528 \n",
      " NDCG@20: 0.4107\n",
      "Epoch: 23, Training time: 2.60s, Loss: 36.3749\n",
      "Evaluate current model:\n",
      " Epoch: 23, Validation time: 0.61s \n",
      " Loss: 36.3749: \n",
      " Recall@20: 0.1670 \n",
      " NDCG@20: 0.4345\n",
      "Epoch: 24, Training time: 2.65s, Loss: 36.0381\n",
      "Evaluate current model:\n",
      " Epoch: 24, Validation time: 0.61s \n",
      " Loss: 36.0381: \n",
      " Recall@20: 0.1788 \n",
      " NDCG@20: 0.4459\n",
      "Epoch: 25, Training time: 2.62s, Loss: 35.6867\n",
      "Evaluate current model:\n",
      " Epoch: 25, Validation time: 0.61s \n",
      " Loss: 35.6867: \n",
      " Recall@20: 0.1682 \n",
      " NDCG@20: 0.4467\n",
      "Epoch: 26, Training time: 2.63s, Loss: 35.4345\n",
      "Evaluate current model:\n",
      " Epoch: 26, Validation time: 0.61s \n",
      " Loss: 35.4345: \n",
      " Recall@20: 0.1881 \n",
      " NDCG@20: 0.4639\n",
      "Epoch: 27, Training time: 2.63s, Loss: 35.0310\n",
      "Evaluate current model:\n",
      " Epoch: 27, Validation time: 0.61s \n",
      " Loss: 35.0310: \n",
      " Recall@20: 0.1916 \n",
      " NDCG@20: 0.4696\n",
      "Epoch: 28, Training time: 2.64s, Loss: 34.7272\n",
      "Evaluate current model:\n",
      " Epoch: 28, Validation time: 0.61s \n",
      " Loss: 34.7272: \n",
      " Recall@20: 0.2095 \n",
      " NDCG@20: 0.4813\n",
      "Epoch: 29, Training time: 2.64s, Loss: 34.1972\n",
      "Evaluate current model:\n",
      " Epoch: 29, Validation time: 0.61s \n",
      " Loss: 34.1972: \n",
      " Recall@20: 0.2125 \n",
      " NDCG@20: 0.5039\n",
      "Epoch: 30, Training time: 2.63s, Loss: 33.9594\n",
      "Evaluate current model:\n",
      " Epoch: 30, Validation time: 0.61s \n",
      " Loss: 33.9594: \n",
      " Recall@20: 0.2183 \n",
      " NDCG@20: 0.4950\n",
      "Epoch: 31, Training time: 2.63s, Loss: 33.5666\n",
      "Evaluate current model:\n",
      " Epoch: 31, Validation time: 0.61s \n",
      " Loss: 33.5666: \n",
      " Recall@20: 0.2268 \n",
      " NDCG@20: 0.5088\n",
      "Epoch: 32, Training time: 2.62s, Loss: 33.0558\n",
      "Evaluate current model:\n",
      " Epoch: 32, Validation time: 0.61s \n",
      " Loss: 33.0558: \n",
      " Recall@20: 0.2207 \n",
      " NDCG@20: 0.5162\n",
      "Epoch: 33, Training time: 2.62s, Loss: 32.6034\n",
      "Evaluate current model:\n",
      " Epoch: 33, Validation time: 0.61s \n",
      " Loss: 32.6034: \n",
      " Recall@20: 0.2398 \n",
      " NDCG@20: 0.5289\n",
      "Epoch: 34, Training time: 2.60s, Loss: 32.2411\n",
      "Evaluate current model:\n",
      " Epoch: 34, Validation time: 0.60s \n",
      " Loss: 32.2411: \n",
      " Recall@20: 0.2364 \n",
      " NDCG@20: 0.5363\n",
      "Epoch: 35, Training time: 2.60s, Loss: 31.7983\n",
      "Evaluate current model:\n",
      " Epoch: 35, Validation time: 0.60s \n",
      " Loss: 31.7983: \n",
      " Recall@20: 0.2437 \n",
      " NDCG@20: 0.5406\n",
      "Epoch: 36, Training time: 2.60s, Loss: 31.2774\n",
      "Evaluate current model:\n",
      " Epoch: 36, Validation time: 0.60s \n",
      " Loss: 31.2774: \n",
      " Recall@20: 0.2492 \n",
      " NDCG@20: 0.5531\n",
      "Epoch: 37, Training time: 2.59s, Loss: 30.9827\n",
      "Evaluate current model:\n",
      " Epoch: 37, Validation time: 0.60s \n",
      " Loss: 30.9827: \n",
      " Recall@20: 0.2502 \n",
      " NDCG@20: 0.5505\n",
      "Epoch: 38, Training time: 2.63s, Loss: 30.4886\n",
      "Evaluate current model:\n",
      " Epoch: 38, Validation time: 0.61s \n",
      " Loss: 30.4886: \n",
      " Recall@20: 0.2480 \n",
      " NDCG@20: 0.5529\n",
      "Epoch: 39, Training time: 2.61s, Loss: 30.0842\n",
      "Evaluate current model:\n",
      " Epoch: 39, Validation time: 0.61s \n",
      " Loss: 30.0842: \n",
      " Recall@20: 0.2569 \n",
      " NDCG@20: 0.5695\n",
      "Epoch: 40, Training time: 2.60s, Loss: 29.5070\n",
      "Evaluate current model:\n",
      " Epoch: 40, Validation time: 0.60s \n",
      " Loss: 29.5070: \n",
      " Recall@20: 0.2569 \n",
      " NDCG@20: 0.5712\n",
      "Epoch: 41, Training time: 2.59s, Loss: 29.0045\n",
      "Evaluate current model:\n",
      " Epoch: 41, Validation time: 0.61s \n",
      " Loss: 29.0045: \n",
      " Recall@20: 0.2585 \n",
      " NDCG@20: 0.5752\n",
      "Epoch: 42, Training time: 2.59s, Loss: 28.5776\n",
      "Evaluate current model:\n",
      " Epoch: 42, Validation time: 0.60s \n",
      " Loss: 28.5776: \n",
      " Recall@20: 0.2599 \n",
      " NDCG@20: 0.5657\n",
      "Epoch: 43, Training time: 2.59s, Loss: 28.1759\n",
      "Evaluate current model:\n",
      " Epoch: 43, Validation time: 0.60s \n",
      " Loss: 28.1759: \n",
      " Recall@20: 0.2627 \n",
      " NDCG@20: 0.5778\n",
      "Epoch: 44, Training time: 2.60s, Loss: 27.7364\n",
      "Evaluate current model:\n",
      " Epoch: 44, Validation time: 0.60s \n",
      " Loss: 27.7364: \n",
      " Recall@20: 0.2645 \n",
      " NDCG@20: 0.5836\n",
      "Epoch: 45, Training time: 2.59s, Loss: 27.3023\n",
      "Evaluate current model:\n",
      " Epoch: 45, Validation time: 0.60s \n",
      " Loss: 27.3023: \n",
      " Recall@20: 0.2662 \n",
      " NDCG@20: 0.5810\n",
      "Epoch: 46, Training time: 2.58s, Loss: 26.8739\n",
      "Evaluate current model:\n",
      " Epoch: 46, Validation time: 0.62s \n",
      " Loss: 26.8739: \n",
      " Recall@20: 0.2681 \n",
      " NDCG@20: 0.5789\n",
      "Epoch: 47, Training time: 2.59s, Loss: 26.4898\n",
      "Evaluate current model:\n",
      " Epoch: 47, Validation time: 0.61s \n",
      " Loss: 26.4898: \n",
      " Recall@20: 0.2642 \n",
      " NDCG@20: 0.5909\n",
      "Epoch: 48, Training time: 2.60s, Loss: 26.0474\n",
      "Evaluate current model:\n",
      " Epoch: 48, Validation time: 0.60s \n",
      " Loss: 26.0474: \n",
      " Recall@20: 0.2665 \n",
      " NDCG@20: 0.5829\n",
      "Epoch: 49, Training time: 2.59s, Loss: 25.5493\n",
      "Evaluate current model:\n",
      " Epoch: 49, Validation time: 0.61s \n",
      " Loss: 25.5493: \n",
      " Recall@20: 0.2643 \n",
      " NDCG@20: 0.5842\n",
      "Epoch: 50, Training time: 2.58s, Loss: 25.2512\n",
      "Evaluate current model:\n",
      " Epoch: 50, Validation time: 0.61s \n",
      " Loss: 25.2512: \n",
      " Recall@20: 0.2673 \n",
      " NDCG@20: 0.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Training time: 2.59s, Loss: 24.7827\n",
      "Evaluate current model:\n",
      " Epoch: 51, Validation time: 0.60s \n",
      " Loss: 24.7827: \n",
      " Recall@20: 0.2691 \n",
      " NDCG@20: 0.5908\n",
      "Epoch: 52, Training time: 2.58s, Loss: 24.4161\n",
      "Evaluate current model:\n",
      " Epoch: 52, Validation time: 0.60s \n",
      " Loss: 24.4161: \n",
      " Recall@20: 0.2691 \n",
      " NDCG@20: 0.5915\n",
      "Epoch: 53, Training time: 2.58s, Loss: 23.9449\n",
      "Evaluate current model:\n",
      " Epoch: 53, Validation time: 0.60s \n",
      " Loss: 23.9449: \n",
      " Recall@20: 0.2702 \n",
      " NDCG@20: 0.5884\n",
      "Epoch: 54, Training time: 2.59s, Loss: 23.6352\n",
      "Evaluate current model:\n",
      " Epoch: 54, Validation time: 0.60s \n",
      " Loss: 23.6352: \n",
      " Recall@20: 0.2713 \n",
      " NDCG@20: 0.5954\n",
      "Epoch: 55, Training time: 2.58s, Loss: 23.3452\n",
      "Evaluate current model:\n",
      " Epoch: 55, Validation time: 0.60s \n",
      " Loss: 23.3452: \n",
      " Recall@20: 0.2683 \n",
      " NDCG@20: 0.5957\n",
      "Epoch: 56, Training time: 2.59s, Loss: 23.0918\n",
      "Evaluate current model:\n",
      " Epoch: 56, Validation time: 0.60s \n",
      " Loss: 23.0918: \n",
      " Recall@20: 0.2723 \n",
      " NDCG@20: 0.5987\n",
      "Epoch: 57, Training time: 2.59s, Loss: 22.7331\n",
      "Evaluate current model:\n",
      " Epoch: 57, Validation time: 0.63s \n",
      " Loss: 22.7331: \n",
      " Recall@20: 0.2723 \n",
      " NDCG@20: 0.5967\n",
      "Epoch: 58, Training time: 2.60s, Loss: 22.4625\n",
      "Evaluate current model:\n",
      " Epoch: 58, Validation time: 0.60s \n",
      " Loss: 22.4625: \n",
      " Recall@20: 0.2757 \n",
      " NDCG@20: 0.6039\n",
      "Epoch: 59, Training time: 2.58s, Loss: 22.0910\n",
      "Evaluate current model:\n",
      " Epoch: 59, Validation time: 0.60s \n",
      " Loss: 22.0910: \n",
      " Recall@20: 0.2750 \n",
      " NDCG@20: 0.6007\n",
      "Epoch: 60, Training time: 2.60s, Loss: 21.7915\n",
      "Evaluate current model:\n",
      " Epoch: 60, Validation time: 0.60s \n",
      " Loss: 21.7915: \n",
      " Recall@20: 0.2771 \n",
      " NDCG@20: 0.6063\n",
      "Epoch: 61, Training time: 2.63s, Loss: 21.4667\n",
      "Evaluate current model:\n",
      " Epoch: 61, Validation time: 0.62s \n",
      " Loss: 21.4667: \n",
      " Recall@20: 0.2747 \n",
      " NDCG@20: 0.6068\n",
      "Epoch: 62, Training time: 2.59s, Loss: 21.2781\n",
      "Evaluate current model:\n",
      " Epoch: 62, Validation time: 0.60s \n",
      " Loss: 21.2781: \n",
      " Recall@20: 0.2776 \n",
      " NDCG@20: 0.6040\n",
      "Epoch: 63, Training time: 2.58s, Loss: 21.0353\n",
      "Evaluate current model:\n",
      " Epoch: 63, Validation time: 0.60s \n",
      " Loss: 21.0353: \n",
      " Recall@20: 0.2757 \n",
      " NDCG@20: 0.6110\n",
      "Epoch: 64, Training time: 2.57s, Loss: 20.6465\n",
      "Evaluate current model:\n",
      " Epoch: 64, Validation time: 0.60s \n",
      " Loss: 20.6465: \n",
      " Recall@20: 0.2777 \n",
      " NDCG@20: 0.6043\n",
      "Epoch: 65, Training time: 2.58s, Loss: 20.5382\n",
      "Evaluate current model:\n",
      " Epoch: 65, Validation time: 0.60s \n",
      " Loss: 20.5382: \n",
      " Recall@20: 0.2797 \n",
      " NDCG@20: 0.6097\n",
      "Epoch: 66, Training time: 2.58s, Loss: 20.4149\n",
      "Evaluate current model:\n",
      " Epoch: 66, Validation time: 0.60s \n",
      " Loss: 20.4149: \n",
      " Recall@20: 0.2777 \n",
      " NDCG@20: 0.6093\n",
      "Epoch: 67, Training time: 2.57s, Loss: 20.1009\n",
      "Evaluate current model:\n",
      " Epoch: 67, Validation time: 0.60s \n",
      " Loss: 20.1009: \n",
      " Recall@20: 0.2784 \n",
      " NDCG@20: 0.6120\n",
      "Epoch: 68, Training time: 2.58s, Loss: 20.0361\n",
      "Evaluate current model:\n",
      " Epoch: 68, Validation time: 0.60s \n",
      " Loss: 20.0361: \n",
      " Recall@20: 0.2780 \n",
      " NDCG@20: 0.6067\n",
      "Epoch: 69, Training time: 2.58s, Loss: 19.6957\n",
      "Evaluate current model:\n",
      " Epoch: 69, Validation time: 0.60s \n",
      " Loss: 19.6957: \n",
      " Recall@20: 0.2808 \n",
      " NDCG@20: 0.6100\n",
      "Epoch: 70, Training time: 2.58s, Loss: 19.4179\n",
      "Evaluate current model:\n",
      " Epoch: 70, Validation time: 0.60s \n",
      " Loss: 19.4179: \n",
      " Recall@20: 0.2831 \n",
      " NDCG@20: 0.6087\n",
      "Epoch: 71, Training time: 2.58s, Loss: 19.4536\n",
      "Evaluate current model:\n",
      " Epoch: 71, Validation time: 0.60s \n",
      " Loss: 19.4536: \n",
      " Recall@20: 0.2861 \n",
      " NDCG@20: 0.6123\n",
      "Epoch: 72, Training time: 2.57s, Loss: 19.0256\n",
      "Evaluate current model:\n",
      " Epoch: 72, Validation time: 0.60s \n",
      " Loss: 19.0256: \n",
      " Recall@20: 0.2859 \n",
      " NDCG@20: 0.6172\n",
      "Epoch: 73, Training time: 2.58s, Loss: 19.0870\n",
      "Evaluate current model:\n",
      " Epoch: 73, Validation time: 0.60s \n",
      " Loss: 19.0870: \n",
      " Recall@20: 0.2852 \n",
      " NDCG@20: 0.6207\n",
      "Epoch: 74, Training time: 2.60s, Loss: 18.9492\n",
      "Evaluate current model:\n",
      " Epoch: 74, Validation time: 0.60s \n",
      " Loss: 18.9492: \n",
      " Recall@20: 0.2883 \n",
      " NDCG@20: 0.6164\n",
      "Epoch: 75, Training time: 2.58s, Loss: 18.6029\n",
      "Evaluate current model:\n",
      " Epoch: 75, Validation time: 0.60s \n",
      " Loss: 18.6029: \n",
      " Recall@20: 0.2869 \n",
      " NDCG@20: 0.6137\n",
      "Epoch: 76, Training time: 2.62s, Loss: 18.6410\n",
      "Evaluate current model:\n",
      " Epoch: 76, Validation time: 0.61s \n",
      " Loss: 18.6410: \n",
      " Recall@20: 0.2875 \n",
      " NDCG@20: 0.6142\n",
      "Epoch: 77, Training time: 2.62s, Loss: 18.5620\n",
      "Evaluate current model:\n",
      " Epoch: 77, Validation time: 0.61s \n",
      " Loss: 18.5620: \n",
      " Recall@20: 0.2840 \n",
      " NDCG@20: 0.6176\n",
      "Epoch: 78, Training time: 2.64s, Loss: 18.6021\n",
      "Evaluate current model:\n",
      " Epoch: 78, Validation time: 0.61s \n",
      " Loss: 18.6021: \n",
      " Recall@20: 0.2886 \n",
      " NDCG@20: 0.6185\n",
      "Epoch: 79, Training time: 2.63s, Loss: 18.2976\n",
      "Evaluate current model:\n",
      " Epoch: 79, Validation time: 0.61s \n",
      " Loss: 18.2976: \n",
      " Recall@20: 0.2886 \n",
      " NDCG@20: 0.6157\n",
      "Epoch: 80, Training time: 2.63s, Loss: 17.9379\n",
      "Evaluate current model:\n",
      " Epoch: 80, Validation time: 0.61s \n",
      " Loss: 17.9379: \n",
      " Recall@20: 0.2880 \n",
      " NDCG@20: 0.6160\n",
      "Epoch: 81, Training time: 2.62s, Loss: 17.8759\n",
      "Evaluate current model:\n",
      " Epoch: 81, Validation time: 0.61s \n",
      " Loss: 17.8759: \n",
      " Recall@20: 0.2872 \n",
      " NDCG@20: 0.6172\n",
      "Epoch: 82, Training time: 2.63s, Loss: 17.8478\n",
      "Evaluate current model:\n",
      " Epoch: 82, Validation time: 0.61s \n",
      " Loss: 17.8478: \n",
      " Recall@20: 0.2853 \n",
      " NDCG@20: 0.6182\n",
      "Epoch: 83, Training time: 2.64s, Loss: 17.7637\n",
      "Evaluate current model:\n",
      " Epoch: 83, Validation time: 0.61s \n",
      " Loss: 17.7637: \n",
      " Recall@20: 0.2916 \n",
      " NDCG@20: 0.6185\n",
      "Epoch: 84, Training time: 2.64s, Loss: 17.6764\n",
      "Evaluate current model:\n",
      " Epoch: 84, Validation time: 0.61s \n",
      " Loss: 17.6764: \n",
      " Recall@20: 0.2880 \n",
      " NDCG@20: 0.6201\n",
      "Epoch: 85, Training time: 2.60s, Loss: 17.5105\n",
      "Evaluate current model:\n",
      " Epoch: 85, Validation time: 0.60s \n",
      " Loss: 17.5105: \n",
      " Recall@20: 0.2905 \n",
      " NDCG@20: 0.6190\n",
      "Epoch: 86, Training time: 2.59s, Loss: 17.2955\n",
      "Evaluate current model:\n",
      " Epoch: 86, Validation time: 0.60s \n",
      " Loss: 17.2955: \n",
      " Recall@20: 0.2889 \n",
      " NDCG@20: 0.6209\n",
      "Epoch: 87, Training time: 2.58s, Loss: 17.4031\n",
      "Evaluate current model:\n",
      " Epoch: 87, Validation time: 0.60s \n",
      " Loss: 17.4031: \n",
      " Recall@20: 0.2885 \n",
      " NDCG@20: 0.6213\n",
      "Epoch: 88, Training time: 2.57s, Loss: 17.3825\n",
      "Evaluate current model:\n",
      " Epoch: 88, Validation time: 0.60s \n",
      " Loss: 17.3825: \n",
      " Recall@20: 0.2893 \n",
      " NDCG@20: 0.6213\n",
      "Early stopping at step: 5 log:0.2892577350139618\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# current best metric\n",
    "cur_best_metric = 0\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Set values for early stopping\n",
    "cur_best_loss, stopping_step, should_stop = 1e3, 0, False\n",
    "today = datetime.now()\n",
    "\n",
    "print(\"Start at \" + str(today))\n",
    "print(\"Using \" + str(device) + \" for computations\")\n",
    "print(\"Params on CUDA: \" + str(next(model.parameters()).is_cuda))\n",
    "\n",
    "results = {\"Epoch\": [],\n",
    "               \"Loss\": [],\n",
    "               \"Recall\": [],\n",
    "               \"NDCG\": [],\n",
    "               \"Training Time\": []}\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    t1 = time()\n",
    "    loss = train(model, data_generator, optimizer)\n",
    "    training_time = time()-t1\n",
    "    print(\"Epoch: {}, Training time: {:.2f}s, Loss: {:.4f}\".\n",
    "            format(epoch, training_time, loss))\n",
    "    \n",
    "    # print test evaluation metrics every N epochs (provided by eval_N)\n",
    "    if epoch % eval_N  == (eval_N - 1):\n",
    "        with torch.no_grad():\n",
    "            t2 = time()\n",
    "            recall, ndcg = eval_model(model.u_g_embeddings.detach(),\n",
    "                                          model.i_g_embeddings.detach(),\n",
    "                                          data_generator.R_train,\n",
    "                                          data_generator.R_test,\n",
    "                                          k)\n",
    "        print(\n",
    "                \"Evaluate current model:\\n\",\n",
    "                \"Epoch: {}, Validation time: {:.2f}s\".format(epoch, time()-t2),\"\\n\",\n",
    "                \"Loss: {:.4f}:\".format(loss), \"\\n\",\n",
    "                \"Recall@{}: {:.4f}\".format(k, recall), \"\\n\",\n",
    "                \"NDCG@{}: {:.4f}\".format(k, ndcg)\n",
    "                )\n",
    "        cur_best_metric, stopping_step, should_stop = \\\n",
    "        early_stopping(recall, cur_best_metric, stopping_step, flag_step=5)\n",
    "        \n",
    "        # save results in dict\n",
    "        results['Epoch'].append(epoch)\n",
    "        results['Loss'].append(loss)\n",
    "        results['Recall'].append(recall.item())\n",
    "        results['NDCG'].append(ndcg.item())\n",
    "        results['Training Time'].append(training_time)\n",
    "    else:\n",
    "        # save results in dict\n",
    "        results['Epoch'].append(epoch)\n",
    "        results['Loss'].append(loss)\n",
    "        results['Recall'].append(None)\n",
    "        results['NDCG'].append(None)\n",
    "        results['Training Time'].append(training_time)\n",
    "    if should_stop == True: break\n",
    "\n",
    "        \n",
    "# save\n",
    "if save_results:\n",
    "    date = today.strftime(\"%d%m%Y_%H%M\") \n",
    "    \n",
    "    # save model as .pt file\n",
    "    if os.path.isdir(\"./models\"):\n",
    "        torch.save(model.state_dict(), \"./models/\" + str(date) + \"_\" + modelname + \"_\" + dataset + \".pt\")\n",
    "    else:\n",
    "        os.mkdir(\"./models\")\n",
    "        torch.save(model.state_dict(), \"./models/\" + str(date) + \"_\" + modelname + \"_\" + dataset + \".pt\")\n",
    "\n",
    "    # save results as pandas dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index('Epoch', inplace=True)\n",
    "    if os.path.isdir(\"./results\"):\n",
    "        results_df.to_csv(\"./results/\" + str(date) + \"_\" + modelname + \"_\" + dataset + \".csv\")\n",
    "    else:\n",
    "        os.mkdir(\"./results\")\n",
    "        results_df.to_csv(\"./results/\" + str(date) + \"_\" + modelname + \"_\" + dataset + \".csv\")\n",
    "    # plot loss\n",
    "    results_df['Loss'].plot(figsize=(12,8), title='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
