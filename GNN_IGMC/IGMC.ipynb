{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# Based on the paper: Inductive Matrix Completion Based on Graph Neural Networks\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import dgl \n",
    "from dgl.data.utils import download, extract_archive, get_download_dir\n",
    "from refex import extract_refex_feature\n",
    "import argparse\n",
    "\n",
    "import math \n",
    "import torch as th \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import MetricLogger, get_neighbor_nodes_labels, subgraph_extraction_labeling, load_official_trainvaltest_split\n",
    "\n",
    "from dgl.nn.pytorch import RelGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_official_trainvaltest_split(dataset, testing=False, rating_map=None, post_rating_map=None, ratio=1.0):\n",
    "    \"\"\"\n",
    "    Loads official train/test split and uses 10% of training samples for validaiton\n",
    "    For each split computes 1-of-num_classes labels. Also computes training\n",
    "    adjacency matrix. Assumes flattening happens everywhere in row-major fashion.\n",
    "    \"\"\"\n",
    "\n",
    "    sep = '\\t'\n",
    "\n",
    "    # Check if files exist and download otherwise\n",
    "    files = ['/u1.base', '/u1.test', '/u.item', '/u.user']\n",
    "    fname = dataset\n",
    "    data_dir = 'data/' + fname\n",
    "\n",
    "\n",
    "    dtypes = {\n",
    "        'u_nodes': np.int32, 'v_nodes': np.int32,\n",
    "        'ratings': np.float32, 'timestamp': np.float64}\n",
    "\n",
    "    filename_train = 'data/' + dataset + '/u1.base'\n",
    "    filename_test = 'data/' + dataset + '/u1.test'\n",
    "\n",
    "    data_train = pd.read_csv(\n",
    "        filename_train, sep=sep, header=None,\n",
    "        names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "    data_test = pd.read_csv(\n",
    "        filename_test, sep=sep, header=None,\n",
    "        names=['u_nodes', 'v_nodes', 'ratings', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "    data_array_train = data_train.values.tolist()\n",
    "    data_array_train = np.array(data_array_train)\n",
    "    data_array_test = data_test.values.tolist()\n",
    "    data_array_test = np.array(data_array_test)\n",
    "\n",
    "    if ratio < 1.0:\n",
    "        data_array_train = data_array_train[data_array_train[:, -1].argsort()[:int(ratio*len(data_array_train))]]\n",
    "\n",
    "    data_array = np.concatenate([data_array_train, data_array_test], axis=0)\n",
    "\n",
    "    u_nodes_ratings = data_array[:, 0].astype(dtypes['u_nodes'])\n",
    "    v_nodes_ratings = data_array[:, 1].astype(dtypes['v_nodes'])\n",
    "    ratings = data_array[:, 2].astype(dtypes['ratings'])\n",
    "    if rating_map is not None:\n",
    "        for i, x in enumerate(ratings):\n",
    "            ratings[i] = rating_map[x]\n",
    "\n",
    "    u_nodes_ratings, u_dict, num_users = map_data(u_nodes_ratings)\n",
    "    v_nodes_ratings, v_dict, num_items = map_data(v_nodes_ratings)\n",
    "\n",
    "    u_nodes_ratings, v_nodes_ratings = u_nodes_ratings.astype(np.int64), v_nodes_ratings.astype(np.int32)\n",
    "    ratings = ratings.astype(np.float64)\n",
    "\n",
    "    u_nodes = u_nodes_ratings\n",
    "    v_nodes = v_nodes_ratings\n",
    "\n",
    "    neutral_rating = -1  # int(np.ceil(np.float(num_classes)/2.)) - 1\n",
    "\n",
    "    # assumes that ratings_train contains at least one example of every rating type\n",
    "    rating_dict = {r: i for i, r in enumerate(np.sort(np.unique(ratings)).tolist())}\n",
    "\n",
    "    labels = np.full((num_users, num_items), neutral_rating, dtype=np.int32)\n",
    "    labels[u_nodes, v_nodes] = np.array([rating_dict[r] for r in ratings])\n",
    "\n",
    "    for i in range(len(u_nodes)):\n",
    "        assert(labels[u_nodes[i], v_nodes[i]] == rating_dict[ratings[i]])\n",
    "\n",
    "    labels = labels.reshape([-1])\n",
    "\n",
    "    # number of test and validation edges, see cf-nade code\n",
    "\n",
    "    num_train = data_array_train.shape[0]\n",
    "    num_test = data_array_test.shape[0]\n",
    "    num_val = int(np.ceil(num_train * 0.2))\n",
    "    num_train = num_train - num_val\n",
    "\n",
    "    pairs_nonzero = np.array([[u, v] for u, v in zip(u_nodes, v_nodes)])\n",
    "    idx_nonzero = np.array([u * num_items + v for u, v in pairs_nonzero])\n",
    "\n",
    "    for i in range(len(ratings)):\n",
    "        assert(labels[idx_nonzero[i]] == rating_dict[ratings[i]])\n",
    "\n",
    "    idx_nonzero_train = idx_nonzero[0:num_train+num_val]\n",
    "    idx_nonzero_test = idx_nonzero[num_train+num_val:]\n",
    "\n",
    "    pairs_nonzero_train = pairs_nonzero[0:num_train+num_val]\n",
    "    pairs_nonzero_test = pairs_nonzero[num_train+num_val:]\n",
    "\n",
    "    # Internally shuffle training set (before splitting off validation set)\n",
    "    rand_idx = list(range(len(idx_nonzero_train)))\n",
    "    np.random.seed(1234)\n",
    "    np.random.shuffle(rand_idx)\n",
    "    idx_nonzero_train = idx_nonzero_train[rand_idx]\n",
    "    pairs_nonzero_train = pairs_nonzero_train[rand_idx]\n",
    "\n",
    "    idx_nonzero = np.concatenate([idx_nonzero_train, idx_nonzero_test], axis=0)\n",
    "    pairs_nonzero = np.concatenate([pairs_nonzero_train, pairs_nonzero_test], axis=0)\n",
    "\n",
    "    val_idx = idx_nonzero[0:num_val]\n",
    "    train_idx = idx_nonzero[num_val:num_train + num_val]\n",
    "    test_idx = idx_nonzero[num_train + num_val:]\n",
    "\n",
    "    assert(len(test_idx) == num_test)\n",
    "\n",
    "    val_pairs_idx = pairs_nonzero[0:num_val]\n",
    "    train_pairs_idx = pairs_nonzero[num_val:num_train + num_val]\n",
    "    test_pairs_idx = pairs_nonzero[num_train + num_val:]\n",
    "\n",
    "    u_test_idx, v_test_idx = test_pairs_idx.transpose()\n",
    "    u_val_idx, v_val_idx = val_pairs_idx.transpose()\n",
    "    u_train_idx, v_train_idx = train_pairs_idx.transpose()\n",
    "\n",
    "    # create labels\n",
    "    train_labels = labels[train_idx]\n",
    "    val_labels = labels[val_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "\n",
    "    if testing:\n",
    "        u_train_idx = np.hstack([u_train_idx, u_val_idx])\n",
    "        v_train_idx = np.hstack([v_train_idx, v_val_idx])\n",
    "        train_labels = np.hstack([train_labels, val_labels])\n",
    "        # for adjacency matrix construction\n",
    "        train_idx = np.hstack([train_idx, val_idx])\n",
    "    \n",
    "    class_values = np.sort(np.unique(ratings))\n",
    "\n",
    "    # make training adjacency matrix\n",
    "    rating_mx_train = np.zeros(num_users * num_items, dtype=np.float32)\n",
    "    if post_rating_map is None:\n",
    "        rating_mx_train[train_idx] = labels[train_idx].astype(np.float32) + 1.\n",
    "    else:\n",
    "        rating_mx_train[train_idx] = np.array([post_rating_map[r] for r in class_values[labels[train_idx]]]) + 1.\n",
    "    rating_mx_train = sp.csr_matrix(rating_mx_train.reshape(num_users, num_items))\n",
    "\n",
    "    if dataset =='ml-100k':\n",
    "\n",
    "        # movie features (genres)\n",
    "        sep = r'|'\n",
    "        movie_file = 'data/' + dataset + '/u.item'\n",
    "        movie_headers = ['movie id', 'movie title', 'release date', 'video release date',\n",
    "                         'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "                         'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                         'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                         'Thriller', 'War', 'Western']\n",
    "        movie_df = pd.read_csv(movie_file, sep=sep, header=None,\n",
    "                               names=movie_headers, engine='python')\n",
    "\n",
    "        genre_headers = movie_df.columns.values[6:]\n",
    "        num_genres = genre_headers.shape[0]\n",
    "\n",
    "        v_features = np.zeros((num_items, num_genres), dtype=np.float32)\n",
    "        for movie_id, g_vec in zip(movie_df['movie id'].values.tolist(), movie_df[genre_headers].values.tolist()):\n",
    "            # check if movie_id was listed in ratings file and therefore in mapping dictionary\n",
    "            if movie_id in v_dict.keys():\n",
    "                v_features[v_dict[movie_id], :] = g_vec\n",
    "\n",
    "        # user features\n",
    "\n",
    "        sep = r'|'\n",
    "        users_file = 'data/' + dataset + '/u.user'\n",
    "        users_headers = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
    "        users_df = pd.read_csv(users_file, sep=sep, header=None,\n",
    "                               names=users_headers, engine='python')\n",
    "\n",
    "        occupation = set(users_df['occupation'].values.tolist())\n",
    "\n",
    "        age = users_df['age'].values\n",
    "        age_max = age.max()\n",
    "\n",
    "        gender_dict = {'M': 0., 'F': 1.}\n",
    "        occupation_dict = {f: i for i, f in enumerate(occupation, start=2)}\n",
    "\n",
    "        num_feats = 2 + len(occupation_dict)\n",
    "\n",
    "        u_features = np.zeros((num_users, num_feats), dtype=np.float32)\n",
    "        for _, row in users_df.iterrows():\n",
    "            u_id = row['user id']\n",
    "            if u_id in u_dict.keys():\n",
    "                # age\n",
    "                u_features[u_dict[u_id], 0] = row['age'] / np.float(age_max)\n",
    "                # gender\n",
    "                u_features[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
    "                # occupation\n",
    "                u_features[u_dict[u_id], occupation_dict[row['occupation']]] = 1.\n",
    "\n",
    "    \n",
    "\n",
    "    u_features = sp.csr_matrix(u_features)\n",
    "    v_features = sp.csr_matrix(v_features)\n",
    "\n",
    "    print(\"User features shape: \"+str(u_features.shape))\n",
    "    print(\"Item features shape: \"+str(v_features.shape))\n",
    "\n",
    "    return u_features, v_features, rating_mx_train, train_labels, u_train_idx, v_train_idx, \\\n",
    "        val_labels, u_val_idx, v_val_idx, test_labels, u_test_idx, v_test_idx, class_values     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data):\n",
    "    \"\"\"\n",
    "    Map data to proper indices in case they are not in a continues [0, N) range\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.int32 arrays\n",
    "    Returns\n",
    "    -------\n",
    "    mapped_data : np.int32 arrays\n",
    "    n : length of mapped_data\n",
    "    \"\"\"\n",
    "    uniq = list(set(data))\n",
    "\n",
    "    id_dict = {old: new for new, old in enumerate(sorted(uniq))}\n",
    "    data = np.array([id_dict[x] for x in data])\n",
    "    n = len(uniq)\n",
    "\n",
    "    return data, id_dict, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_movielens(data):\n",
    "    g_list, label_list = map(list, zip(*data))\n",
    "    g = dgl.batch(g_list)\n",
    "    g_label = th.stack(label_list)\n",
    "    return g, g_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens(object):\n",
    "    \"\"\"MovieLens dataset used by GCMC model\n",
    "    \"\"\"\n",
    "    def __init__(self, data_name, testing=False, \n",
    "                 test_ratio=0.1, valid_ratio=0.2):\n",
    "        (\n",
    "                u_features, v_features, adj_train, train_labels, train_u_indices, train_v_indices,\n",
    "                val_labels, val_u_indices, val_v_indices, test_labels, test_u_indices, \n",
    "                test_v_indices, class_values\n",
    "            ) = load_official_trainvaltest_split(\n",
    "                'ml-100k', testing, None, None, 1.0\n",
    "            )\n",
    "            \n",
    "        self._num_user = u_features.shape[0]\n",
    "        self._num_movie = v_features.shape[0]\n",
    "\n",
    "        # reindex u and v, v nodes start after u\n",
    "        train_v_indices += self.num_user\n",
    "        val_v_indices += self.num_user\n",
    "        test_v_indices += self.num_user\n",
    "\n",
    "        self.train_rating_pairs = (th.LongTensor(train_u_indices), th.LongTensor(train_v_indices))\n",
    "        self.valid_rating_pairs = (th.LongTensor(val_u_indices), th.LongTensor(val_v_indices))\n",
    "        self.test_rating_pairs = (th.LongTensor(test_u_indices), th.LongTensor(test_v_indices))\n",
    "        self.train_rating_values = th.FloatTensor(train_labels)\n",
    "        self.valid_rating_values = th.FloatTensor(val_labels)\n",
    "        self.test_rating_values = th.FloatTensor(test_labels)\n",
    "\n",
    "        print(\"\\tTrain rating pairs : {}\".format(len(train_labels)))\n",
    "        print(\"\\tValid rating pairs : {}\".format(len(val_labels)))\n",
    "        print(\"\\tTest rating pairs  : {}\".format(len(test_labels)))\n",
    "\n",
    "        # build dgl graph object, which is homogeneous and bidirectional and contains only training edges\n",
    "        self.train_graph = dgl.graph((th.cat([self.train_rating_pairs[0], self.train_rating_pairs[1]]), \n",
    "                                      th.cat([self.train_rating_pairs[1], self.train_rating_pairs[0]])))\n",
    "        self.train_graph.edata['etype'] = th.cat([self.train_rating_values, self.train_rating_values]).to(th.long)                    \n",
    "\n",
    "    @property\n",
    "    def num_rating(self):\n",
    "        return self._rating.size\n",
    "\n",
    "    @property\n",
    "    def num_user(self):\n",
    "        return self._num_user\n",
    "\n",
    "    @property\n",
    "    def num_movie(self):\n",
    "        return self._num_movie\n",
    "\n",
    "\n",
    "    def _generate_pair_value(self, rating_data):\n",
    "        rating_pairs = (np.array([self._global_user_id_map[ele] for ele in rating_data[\"user_id\"]],\n",
    "                                 dtype=np.int32),\n",
    "                        np.array([self._global_movie_id_map[ele] for ele in rating_data[\"movie_id\"]],\n",
    "                                 dtype=np.int32))\n",
    "        # label ranges from 0. to 4.\n",
    "        rating_values = rating_data[\"rating\"].values.astype(np.float32) - 1.\n",
    "        return rating_pairs[0], rating_pairs[1], rating_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, links, g_labels, graph, \n",
    "                hop=1, sample_ratio=1.0, max_nodes_per_hop=200):\n",
    "        self.links = links\n",
    "        self.g_labels = g_labels\n",
    "        self.graph = graph \n",
    "\n",
    "        self.hop = hop\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.max_nodes_per_hop = max_nodes_per_hop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.links[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u, v = self.links[0][idx], self.links[1][idx]\n",
    "        g_label = self.g_labels[idx]\n",
    "\n",
    "        subgraph = subgraph_extraction_labeling(\n",
    "            (u, v), self.graph, \n",
    "            hop=self.hop, sample_ratio=self.sample_ratio, max_nodes_per_hop=self.max_nodes_per_hop)\n",
    "\n",
    "        return subgraph, g_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features shape: (943, 23)\n",
      "Item features shape: (1682, 18)\n",
      "\tTrain rating pairs : 64000\n",
      "\tValid rating pairs : 16000\n",
      "\tTest rating pairs  : 20000\n"
     ]
    }
   ],
   "source": [
    "movielens = MovieLens(\"ml-100k\", testing=False)\n",
    "\n",
    "train_dataset = MovieLensDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        hop=1, sample_ratio=1.0, max_nodes_per_hop=200)\n",
    "train_loader = th.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, \n",
    "                            num_workers=8, collate_fn=collate_movielens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(size, tensor):\n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_drop(graph, edge_dropout=0.2, training=True):\n",
    "    assert edge_dropout >= 0.0 and edge_dropout <= 1.0, 'Invalid dropout rate.'\n",
    "\n",
    "    if not training:\n",
    "        return graph\n",
    "\n",
    "    # set edge mask to zero in directional mode\n",
    "    src, _ = graph.edges()\n",
    "    to_drop = src.new_full((graph.number_of_edges(), ), edge_dropout, dtype=th.float)\n",
    "    to_drop = th.bernoulli(to_drop).to(th.bool)\n",
    "    graph.edata['edge_mask'][to_drop] = 0\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGMC(nn.Module):\n",
    "    # The GNN model of Inductive Graph-based Matrix Completion. \n",
    "    # Use RGCN convolution + center-nodes readout.\n",
    "    \n",
    "    def __init__(self, in_feats, gconv=RelGraphConv, latent_dim=[32, 32, 32, 32], \n",
    "                num_relations=5, num_bases=2, regression=False, edge_dropout=0.2, \n",
    "                force_undirected=False, side_features=False, n_side_features=0, \n",
    "                multiply_by=1):\n",
    "        super(IGMC, self).__init__()\n",
    "\n",
    "        self.regression = regression\n",
    "        self.edge_dropout = edge_dropout\n",
    "        self.force_undirected = force_undirected\n",
    "        self.side_features = side_features\n",
    "        self.multiply_by = multiply_by\n",
    "\n",
    "        self.convs = th.nn.ModuleList()\n",
    "        self.convs.append(gconv(in_feats, latent_dim[0], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        for i in range(0, len(latent_dim)-1):\n",
    "            self.convs.append(gconv(latent_dim[i], latent_dim[i+1], num_relations, num_bases=num_bases, self_loop=True, low_mem=True))\n",
    "        \n",
    "        self.lin1 = nn.Linear(2 * sum(latent_dim), 128)\n",
    "        if side_features:\n",
    "            self.lin1 = nn.Linear(2 * sum(latent_dim) + n_side_features, 128)\n",
    "        if self.regression:\n",
    "            self.lin2 = nn.Linear(128, 1)\n",
    "        else:\n",
    "            assert False\n",
    "            # self.lin2 = nn.Linear(128, n_classes)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            size = conv.num_bases * conv.in_feat\n",
    "            uniform(size, conv.weight)\n",
    "            uniform(size, conv.w_comp)\n",
    "            uniform(size, conv.loop_weight)\n",
    "            uniform(size, conv.h_bias)\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    # @profile\n",
    "    def forward(self, block):\n",
    "        block = edge_drop(block, self.edge_dropout, self.training)\n",
    "\n",
    "        concat_states = []\n",
    "        x = block.ndata['x']\n",
    "        for conv in self.convs:\n",
    "            # edge mask zero denotes the edge dropped\n",
    "            x = th.tanh(conv(block, x, block.edata['etype'], \n",
    "                             norm=block.edata['edge_mask'].unsqueeze(1)))\n",
    "            concat_states.append(x)\n",
    "        concat_states = th.cat(concat_states, 1)\n",
    "        \n",
    "        users = block.ndata['nlabel'][:, 0] == 1\n",
    "        items = block.ndata['nlabel'][:, 1] == 1\n",
    "        x = th.cat([concat_states[users], concat_states[items]], 1)\n",
    "        # if self.side_features:\n",
    "        #     x = th.cat([x, data.u_feature, data.v_feature], 1)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        if self.regression:\n",
    "            return x[:, 0] * self.multiply_by\n",
    "        else:\n",
    "            assert False\n",
    "            # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    # Evaluate RMSE\n",
    "    model.eval()\n",
    "    mse = 0.\n",
    "    for batch in loader:\n",
    "        with th.no_grad():\n",
    "            preds = model(batch[0].to(device))\n",
    "        labels = batch[1].to(device)\n",
    "        mse += ((preds - labels) ** 2).sum().item()\n",
    "    mse /= len(loader.dataset)\n",
    "    return np.sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_rating_reg(model):\n",
    "    arr_loss = 0\n",
    "    for conv in model.convs:\n",
    "        weight = conv.weight.view(conv.num_bases, conv.in_feat * conv.out_feat)\n",
    "        weight = th.matmul(conv.w_comp, weight).view(conv.num_rels, conv.in_feat, conv.out_feat)\n",
    "        arr_loss += th.sum((weight[1:, :, :] - weight[:-1, :, :])**2)\n",
    "    return arr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loss_fn, optimizer, arr_lambda, loader, device, log_interval):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.\n",
    "    iter_loss = 0.\n",
    "    iter_mse = 0.\n",
    "    iter_cnt = 0\n",
    "    iter_dur = []\n",
    "\n",
    "    for iter_idx, batch in enumerate(loader, start=1):\n",
    "        t_start = time.time()\n",
    "\n",
    "        inputs = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, labels).mean() + arr_lambda * adj_rating_reg(model)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * preds.shape[0]\n",
    "        iter_loss += loss.item() * preds.shape[0]\n",
    "        iter_mse += ((preds - labels) ** 2).sum().item()\n",
    "        iter_cnt += preds.shape[0]\n",
    "        iter_dur.append(time.time() - t_start)\n",
    "\n",
    "        if iter_idx % log_interval == 0:\n",
    "            print(\"Iter={}, loss={:.4f}, rmse={:.4f}, time={:.4f}\".format(\n",
    "                iter_idx, iter_loss/iter_cnt, iter_mse/iter_cnt, np.average(iter_dur)))\n",
    "            iter_loss = 0.\n",
    "            iter_mse = 0.\n",
    "            iter_cnt = 0\n",
    "\n",
    "    return epoch_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    ### prepare data and set model\n",
    "    movielens = MovieLens(args.data_name, testing=args.testing,\n",
    "                            test_ratio=args.data_test_ratio, valid_ratio=args.data_valid_ratio)\n",
    "    if args.testing:\n",
    "        test_dataset = MovieLensDataset(\n",
    "            movielens.test_rating_pairs, movielens.test_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop) \n",
    "    else:\n",
    "        test_dataset = MovieLensDataset(\n",
    "            movielens.valid_rating_pairs, movielens.valid_rating_values, movielens.train_graph, \n",
    "            args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "    train_dataset = MovieLensDataset(\n",
    "        movielens.train_rating_pairs, movielens.train_rating_values, movielens.train_graph, \n",
    "        args.hop, args.sample_ratio, args.max_nodes_per_hop)\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "    test_loader = th.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, \n",
    "                            num_workers=args.num_workers, collate_fn=collate_movielens)\n",
    "\n",
    "    in_feats = (args.hop+1)*2 #+ movielens.train_graph.ndata['refex'].shape[1]\n",
    "    model = IGMC(in_feats=in_feats, \n",
    "                 latent_dim=[32, 32, 32, 32],\n",
    "                 num_relations=5, # movielens.num_rating, \n",
    "                 num_bases=4, \n",
    "                 regression=True, \n",
    "                 edge_dropout=args.edge_dropout,\n",
    "                #  side_features=args.use_features,\n",
    "                #  n_side_features=n_features,\n",
    "                #  multiply_by=args.multiply_by\n",
    "            ).to(args.device)\n",
    "    loss_fn = nn.MSELoss().to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.train_lr, weight_decay=0)\n",
    "    print(\"Loading network finished ...\\n\")\n",
    "\n",
    "    ### prepare the logger\n",
    "    logger = MetricLogger(args.save_dir, args.valid_log_interval)\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_rmse = np.inf\n",
    "    ### declare the loss information\n",
    "    print(\"Start training ...\")\n",
    "    for epoch_idx in range(1, args.train_epochs+1):\n",
    "        print ('Epoch', epoch_idx)\n",
    "    \n",
    "        train_loss = train_epoch(model, loss_fn, optimizer, args.arr_lambda, \n",
    "                                train_loader, args.device, args.train_log_interval)\n",
    "        test_rmse = evaluate(model, test_loader, args.device)\n",
    "        eval_info = {\n",
    "            'epoch': epoch_idx,\n",
    "            'train_loss': train_loss,\n",
    "            'test_rmse': test_rmse,\n",
    "        }\n",
    "        print('=== Epoch {}, train loss {:.6f}, test rmse {:.6f} ==='.format(*eval_info.values()))\n",
    "\n",
    "        if epoch_idx % args.train_lr_decay_step == 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = args.train_lr_decay_factor * param['lr']\n",
    "\n",
    "        logger.log(eval_info, model, optimizer)\n",
    "        if best_rmse > test_rmse:\n",
    "            best_rmse = test_rmse\n",
    "            best_epoch = epoch_idx\n",
    "    eval_info = \"Training ends. The best testing rmse is {:.6f} at epoch {}\".format(best_rmse, best_epoch)\n",
    "    print(eval_info)\n",
    "    with open(os.path.join(args.save_dir, 'log.txt'), 'a') as f:\n",
    "        f.write(eval_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    args = argparse.ArgumentParser(description='IGMC')\n",
    "    # general settings\n",
    "    args.testing = False\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    args.seed = 1234\n",
    "    args.data_name = 'ml-100k'\n",
    "    args.data_test_ratio = 0.1\n",
    "    args.num_workers = 0\n",
    "    args.data_valid_ratio = 0.2\n",
    "    args.train_log_interval = 100\n",
    "    args.valid_log_interval = 100\n",
    "    args.save_appendix = 'debug'\n",
    "    \n",
    "    # subgraph extraction settings\n",
    "    args.hop = 1\n",
    "    args.sample_ratio = 1.0\n",
    "    args.max_nodes_per_hop = 200\n",
    "    \n",
    "    # edge dropout settings\n",
    "    args.edge_dropout = 0.2\n",
    "    args.force_undirected = False\n",
    "    \n",
    "    # optimization settings\n",
    "    args.train_lr = 1e-3\n",
    "    args.train_min_lr = 1e-6\n",
    "    args.train_lr_decay_factor = 0.1\n",
    "    args.train_lr_decay_step = 50\n",
    "    args.train_epochs = 80\n",
    "    args.batch_size = 32\n",
    "    args.arr_lambda = 0.001\n",
    "    args.num_rgcn_bases = 4\n",
    "   \n",
    "    ## set save_dir according to localtime and test mode\n",
    "    file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "    val_test_appendix = 'testmode' if args.testing else 'valmode'\n",
    "    local_time = time.strftime('%y%m%d%H%M', time.localtime())\n",
    "    args.save_dir = os.path.join(\n",
    "        file_dir, 'log/{}_{}_{}_{}'.format(\n",
    "            args.data_name, args.save_appendix, val_test_appendix, local_time\n",
    "        )\n",
    "    )\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir) \n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features shape: (943, 23)\n",
      "Item features shape: (1682, 18)\n",
      "\tTrain rating pairs : 64000\n",
      "\tValid rating pairs : 16000\n",
      "\tTest rating pairs  : 20000\n",
      "Loading network finished ...\n",
      "\n",
      "Start training ...\n",
      "Epoch 1\n",
      "Iter=100, loss=1.4154, rmse=1.4127, time=0.0185\n",
      "Iter=200, loss=1.1457, rmse=1.1430, time=0.0180\n",
      "Iter=300, loss=1.0682, rmse=1.0656, time=0.0178\n",
      "Iter=400, loss=1.0655, rmse=1.0630, time=0.0177\n",
      "Iter=500, loss=1.0478, rmse=1.0454, time=0.0176\n",
      "Iter=600, loss=1.0775, rmse=1.0753, time=0.0174\n",
      "Iter=700, loss=1.0546, rmse=1.0524, time=0.0173\n",
      "Iter=800, loss=1.0397, rmse=1.0376, time=0.0172\n",
      "Iter=900, loss=1.0420, rmse=1.0400, time=0.0172\n",
      "Iter=1000, loss=1.0683, rmse=1.0663, time=0.0171\n",
      "Iter=1100, loss=1.0617, rmse=1.0598, time=0.0170\n",
      "Iter=1200, loss=1.0590, rmse=1.0572, time=0.0170\n",
      "Iter=1300, loss=1.0773, rmse=1.0756, time=0.0170\n",
      "Iter=1400, loss=0.9967, rmse=0.9951, time=0.0169\n",
      "Iter=1500, loss=1.0158, rmse=1.0142, time=0.0169\n",
      "Iter=1600, loss=1.0127, rmse=1.0112, time=0.0169\n",
      "Iter=1700, loss=1.0219, rmse=1.0204, time=0.0169\n",
      "Iter=1800, loss=1.0016, rmse=1.0002, time=0.0168\n",
      "Iter=1900, loss=1.0328, rmse=1.0314, time=0.0168\n",
      "Iter=2000, loss=0.9908, rmse=0.9894, time=0.0168\n",
      "=== Epoch 1, train loss 1.064753, test rmse 0.935208 ===\n",
      "Epoch 2\n",
      "Iter=100, loss=0.9978, rmse=0.9964, time=0.0167\n",
      "Iter=200, loss=1.0241, rmse=1.0227, time=0.0166\n",
      "Iter=300, loss=0.9761, rmse=0.9748, time=0.0166\n",
      "Iter=400, loss=1.0260, rmse=1.0247, time=0.0166\n",
      "Iter=500, loss=0.9676, rmse=0.9664, time=0.0166\n",
      "Iter=600, loss=0.9869, rmse=0.9856, time=0.0166\n",
      "Iter=700, loss=0.9522, rmse=0.9510, time=0.0166\n",
      "Iter=800, loss=0.9940, rmse=0.9928, time=0.0167\n",
      "Iter=900, loss=0.9883, rmse=0.9871, time=0.0167\n",
      "Iter=1000, loss=0.9516, rmse=0.9504, time=0.0167\n",
      "Iter=1100, loss=1.0315, rmse=1.0303, time=0.0167\n",
      "Iter=1200, loss=0.9846, rmse=0.9835, time=0.0167\n",
      "Iter=1300, loss=0.9957, rmse=0.9945, time=0.0167\n",
      "Iter=1400, loss=0.9848, rmse=0.9836, time=0.0167\n",
      "Iter=1500, loss=1.0347, rmse=1.0336, time=0.0167\n",
      "Iter=1600, loss=0.9877, rmse=0.9865, time=0.0167\n",
      "Iter=1700, loss=0.9790, rmse=0.9779, time=0.0167\n",
      "Iter=1800, loss=0.9568, rmse=0.9556, time=0.0167\n",
      "Iter=1900, loss=0.9683, rmse=0.9671, time=0.0167\n",
      "Iter=2000, loss=0.9784, rmse=0.9773, time=0.0166\n",
      "=== Epoch 2, train loss 0.988296, test rmse 0.935559 ===\n",
      "Epoch 3\n",
      "Iter=100, loss=0.9785, rmse=0.9774, time=0.0167\n",
      "Iter=200, loss=0.9372, rmse=0.9361, time=0.0167\n",
      "Iter=300, loss=0.9777, rmse=0.9765, time=0.0167\n",
      "Iter=400, loss=0.9390, rmse=0.9379, time=0.0167\n",
      "Iter=500, loss=0.9383, rmse=0.9372, time=0.0168\n",
      "Iter=600, loss=0.9490, rmse=0.9479, time=0.0168\n",
      "Iter=700, loss=0.9955, rmse=0.9945, time=0.0168\n",
      "Iter=800, loss=0.9834, rmse=0.9823, time=0.0168\n",
      "Iter=900, loss=0.9984, rmse=0.9973, time=0.0168\n",
      "Iter=1000, loss=0.9931, rmse=0.9920, time=0.0168\n",
      "Iter=1100, loss=0.9845, rmse=0.9834, time=0.0168\n",
      "Iter=1200, loss=0.9287, rmse=0.9276, time=0.0168\n",
      "Iter=1300, loss=0.9566, rmse=0.9556, time=0.0167\n",
      "Iter=1400, loss=0.9692, rmse=0.9682, time=0.0167\n",
      "Iter=1500, loss=0.9554, rmse=0.9544, time=0.0167\n",
      "Iter=1600, loss=0.9337, rmse=0.9326, time=0.0167\n",
      "Iter=1700, loss=0.9574, rmse=0.9562, time=0.0167\n",
      "Iter=1800, loss=0.9492, rmse=0.9480, time=0.0167\n",
      "Iter=1900, loss=0.9514, rmse=0.9503, time=0.0167\n",
      "Iter=2000, loss=0.8940, rmse=0.8929, time=0.0167\n",
      "=== Epoch 3, train loss 0.958503, test rmse 0.935119 ===\n",
      "Epoch 4\n",
      "Iter=100, loss=0.9434, rmse=0.9422, time=0.0166\n",
      "Iter=200, loss=0.9475, rmse=0.9464, time=0.0166\n",
      "Iter=300, loss=0.9374, rmse=0.9362, time=0.0167\n",
      "Iter=400, loss=0.9345, rmse=0.9334, time=0.0167\n",
      "Iter=500, loss=0.9490, rmse=0.9479, time=0.0168\n",
      "Iter=600, loss=1.0205, rmse=1.0193, time=0.0167\n",
      "Iter=700, loss=0.9362, rmse=0.9351, time=0.0167\n",
      "Iter=800, loss=0.9183, rmse=0.9172, time=0.0167\n",
      "Iter=900, loss=0.9236, rmse=0.9225, time=0.0167\n",
      "Iter=1000, loss=0.9219, rmse=0.9208, time=0.0167\n",
      "Iter=1100, loss=0.9252, rmse=0.9241, time=0.0167\n",
      "Iter=1200, loss=0.9441, rmse=0.9429, time=0.0167\n",
      "Iter=1300, loss=0.9273, rmse=0.9262, time=0.0167\n",
      "Iter=1400, loss=0.9401, rmse=0.9389, time=0.0167\n",
      "Iter=1500, loss=0.9364, rmse=0.9353, time=0.0167\n",
      "Iter=1600, loss=0.9638, rmse=0.9626, time=0.0167\n",
      "Iter=1700, loss=0.9491, rmse=0.9480, time=0.0167\n",
      "Iter=1800, loss=0.9542, rmse=0.9531, time=0.0168\n",
      "Iter=1900, loss=0.9675, rmse=0.9664, time=0.0168\n",
      "Iter=2000, loss=0.9025, rmse=0.9014, time=0.0168\n",
      "=== Epoch 4, train loss 0.942133, test rmse 0.934322 ===\n",
      "Epoch 5\n",
      "Iter=100, loss=0.9298, rmse=0.9287, time=0.0167\n",
      "Iter=200, loss=0.9251, rmse=0.9240, time=0.0167\n",
      "Iter=300, loss=0.9273, rmse=0.9262, time=0.0166\n",
      "Iter=400, loss=0.9159, rmse=0.9147, time=0.0166\n",
      "Iter=500, loss=0.9319, rmse=0.9307, time=0.0166\n",
      "Iter=600, loss=0.9380, rmse=0.9369, time=0.0166\n",
      "Iter=700, loss=0.9132, rmse=0.9121, time=0.0166\n",
      "Iter=800, loss=0.8992, rmse=0.8980, time=0.0166\n",
      "Iter=900, loss=0.9293, rmse=0.9281, time=0.0167\n",
      "Iter=1000, loss=0.9283, rmse=0.9272, time=0.0168\n",
      "Iter=1100, loss=0.9386, rmse=0.9374, time=0.0168\n",
      "Iter=1200, loss=0.8902, rmse=0.8889, time=0.0168\n",
      "Iter=1300, loss=0.9485, rmse=0.9472, time=0.0168\n",
      "Iter=1400, loss=0.9430, rmse=0.9418, time=0.0168\n",
      "Iter=1500, loss=0.8648, rmse=0.8636, time=0.0168\n",
      "Iter=1600, loss=0.9343, rmse=0.9330, time=0.0168\n",
      "Iter=1700, loss=0.9002, rmse=0.8990, time=0.0168\n",
      "Iter=1800, loss=0.9214, rmse=0.9202, time=0.0168\n",
      "Iter=1900, loss=0.9264, rmse=0.9251, time=0.0168\n",
      "Iter=2000, loss=0.9659, rmse=0.9646, time=0.0168\n",
      "=== Epoch 5, train loss 0.923563, test rmse 0.927308 ===\n",
      "Epoch 6\n",
      "Iter=100, loss=0.9039, rmse=0.9026, time=0.0168\n",
      "Iter=200, loss=0.8940, rmse=0.8927, time=0.0168\n",
      "Iter=300, loss=0.9323, rmse=0.9310, time=0.0168\n",
      "Iter=400, loss=0.8852, rmse=0.8839, time=0.0168\n",
      "Iter=500, loss=0.9203, rmse=0.9190, time=0.0167\n",
      "Iter=600, loss=0.9147, rmse=0.9134, time=0.0167\n",
      "Iter=700, loss=0.9096, rmse=0.9083, time=0.0167\n",
      "Iter=800, loss=0.9185, rmse=0.9173, time=0.0167\n",
      "Iter=900, loss=0.9227, rmse=0.9214, time=0.0167\n",
      "Iter=1000, loss=0.9114, rmse=0.9102, time=0.0166\n",
      "Iter=1100, loss=0.9645, rmse=0.9632, time=0.0167\n",
      "Iter=1200, loss=0.9007, rmse=0.8994, time=0.0167\n",
      "Iter=1300, loss=0.8989, rmse=0.8976, time=0.0167\n",
      "Iter=1400, loss=0.9225, rmse=0.9211, time=0.0167\n",
      "Iter=1500, loss=0.8908, rmse=0.8894, time=0.0167\n",
      "Iter=1600, loss=0.9075, rmse=0.9061, time=0.0167\n",
      "Iter=1700, loss=0.9145, rmse=0.9131, time=0.0167\n",
      "Iter=1800, loss=0.9679, rmse=0.9665, time=0.0167\n",
      "Iter=1900, loss=0.8975, rmse=0.8960, time=0.0167\n",
      "Iter=2000, loss=0.9049, rmse=0.9035, time=0.0167\n",
      "=== Epoch 6, train loss 0.914131, test rmse 0.928566 ===\n",
      "Epoch 7\n",
      "Iter=100, loss=0.8972, rmse=0.8957, time=0.0171\n",
      "Iter=200, loss=0.9384, rmse=0.9368, time=0.0172\n",
      "Iter=300, loss=0.9222, rmse=0.9207, time=0.0170\n",
      "Iter=400, loss=0.9025, rmse=0.9010, time=0.0169\n",
      "Iter=500, loss=0.9401, rmse=0.9386, time=0.0168\n",
      "Iter=600, loss=0.9308, rmse=0.9292, time=0.0168\n",
      "Iter=700, loss=0.8983, rmse=0.8968, time=0.0167\n",
      "Iter=800, loss=0.9145, rmse=0.9129, time=0.0167\n",
      "Iter=900, loss=0.9000, rmse=0.8984, time=0.0167\n",
      "Iter=1000, loss=0.9027, rmse=0.9010, time=0.0167\n",
      "Iter=1100, loss=0.8894, rmse=0.8877, time=0.0167\n",
      "Iter=1200, loss=0.9002, rmse=0.8987, time=0.0167\n",
      "Iter=1300, loss=0.9406, rmse=0.9390, time=0.0167\n",
      "Iter=1400, loss=0.9416, rmse=0.9400, time=0.0167\n",
      "Iter=1500, loss=0.8664, rmse=0.8648, time=0.0167\n",
      "Iter=1600, loss=0.8712, rmse=0.8696, time=0.0167\n",
      "Iter=1700, loss=0.9284, rmse=0.9267, time=0.0166\n",
      "Iter=1800, loss=0.8514, rmse=0.8498, time=0.0167\n",
      "Iter=1900, loss=0.9080, rmse=0.9063, time=0.0167\n",
      "Iter=2000, loss=0.9110, rmse=0.9093, time=0.0167\n",
      "=== Epoch 7, train loss 0.907736, test rmse 0.946965 ===\n",
      "Epoch 8\n",
      "Iter=100, loss=0.9293, rmse=0.9277, time=0.0166\n",
      "Iter=200, loss=0.9054, rmse=0.9038, time=0.0166\n",
      "Iter=300, loss=0.9634, rmse=0.9617, time=0.0166\n",
      "Iter=400, loss=0.8954, rmse=0.8938, time=0.0166\n",
      "Iter=500, loss=0.8925, rmse=0.8908, time=0.0166\n",
      "Iter=600, loss=0.8456, rmse=0.8440, time=0.0167\n",
      "Iter=700, loss=0.8836, rmse=0.8820, time=0.0167\n",
      "Iter=800, loss=0.8758, rmse=0.8741, time=0.0167\n",
      "Iter=900, loss=0.8746, rmse=0.8728, time=0.0167\n",
      "Iter=1000, loss=0.9352, rmse=0.9334, time=0.0167\n",
      "Iter=1100, loss=0.9017, rmse=0.8998, time=0.0167\n",
      "Iter=1200, loss=0.8605, rmse=0.8587, time=0.0167\n",
      "Iter=1300, loss=0.8875, rmse=0.8857, time=0.0167\n",
      "Iter=1400, loss=0.9263, rmse=0.9243, time=0.0167\n",
      "Iter=1500, loss=0.8872, rmse=0.8853, time=0.0167\n",
      "Iter=1600, loss=0.9102, rmse=0.9082, time=0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=1700, loss=0.8953, rmse=0.8933, time=0.0167\n",
      "Iter=1800, loss=0.9154, rmse=0.9134, time=0.0167\n",
      "Iter=1900, loss=0.9218, rmse=0.9198, time=0.0167\n",
      "Iter=2000, loss=0.9359, rmse=0.9339, time=0.0167\n",
      "=== Epoch 8, train loss 0.902128, test rmse 0.922923 ===\n",
      "Epoch 9\n",
      "Iter=100, loss=0.8758, rmse=0.8738, time=0.0166\n",
      "Iter=200, loss=0.9145, rmse=0.9125, time=0.0167\n",
      "Iter=300, loss=0.8669, rmse=0.8648, time=0.0167\n",
      "Iter=400, loss=0.9255, rmse=0.9234, time=0.0167\n",
      "Iter=500, loss=0.9174, rmse=0.9153, time=0.0167\n",
      "Iter=600, loss=0.8560, rmse=0.8539, time=0.0167\n",
      "Iter=700, loss=0.8963, rmse=0.8942, time=0.0167\n",
      "Iter=800, loss=0.9220, rmse=0.9199, time=0.0167\n",
      "Iter=900, loss=0.9091, rmse=0.9070, time=0.0167\n",
      "Iter=1000, loss=0.9117, rmse=0.9095, time=0.0167\n",
      "Iter=1100, loss=0.8949, rmse=0.8927, time=0.0167\n",
      "Iter=1200, loss=0.8657, rmse=0.8633, time=0.0167\n",
      "Iter=1300, loss=0.8933, rmse=0.8911, time=0.0167\n",
      "Iter=1400, loss=0.8962, rmse=0.8938, time=0.0167\n",
      "Iter=1500, loss=0.9146, rmse=0.9121, time=0.0167\n",
      "Iter=1600, loss=0.9059, rmse=0.9035, time=0.0167\n",
      "Iter=1700, loss=0.8528, rmse=0.8505, time=0.0167\n",
      "Iter=1800, loss=0.8882, rmse=0.8858, time=0.0167\n",
      "Iter=1900, loss=0.9650, rmse=0.9626, time=0.0167\n",
      "Iter=2000, loss=0.8954, rmse=0.8929, time=0.0167\n",
      "=== Epoch 9, train loss 0.898364, test rmse 0.934168 ===\n",
      "Epoch 10\n",
      "Iter=100, loss=0.9061, rmse=0.9036, time=0.0167\n",
      "Iter=200, loss=0.8778, rmse=0.8754, time=0.0167\n",
      "Iter=300, loss=0.8827, rmse=0.8802, time=0.0167\n",
      "Iter=400, loss=0.9057, rmse=0.9033, time=0.0166\n",
      "Iter=500, loss=0.8843, rmse=0.8819, time=0.0166\n",
      "Iter=600, loss=0.9077, rmse=0.9053, time=0.0166\n",
      "Iter=700, loss=0.9268, rmse=0.9243, time=0.0166\n",
      "Iter=800, loss=0.8855, rmse=0.8830, time=0.0167\n",
      "Iter=900, loss=0.8729, rmse=0.8704, time=0.0167\n",
      "Iter=1000, loss=0.9142, rmse=0.9118, time=0.0167\n",
      "Iter=1100, loss=0.8707, rmse=0.8683, time=0.0167\n",
      "Iter=1200, loss=0.8625, rmse=0.8600, time=0.0168\n",
      "Iter=1300, loss=0.8860, rmse=0.8836, time=0.0168\n",
      "Iter=1400, loss=0.8801, rmse=0.8777, time=0.0168\n",
      "Iter=1500, loss=0.8596, rmse=0.8571, time=0.0168\n",
      "Iter=1600, loss=0.8743, rmse=0.8718, time=0.0169\n",
      "Iter=1700, loss=0.9384, rmse=0.9360, time=0.0169\n",
      "Iter=1800, loss=0.9032, rmse=0.9006, time=0.0168\n",
      "Iter=1900, loss=0.9118, rmse=0.9093, time=0.0168\n",
      "Iter=2000, loss=0.8781, rmse=0.8756, time=0.0168\n",
      "=== Epoch 10, train loss 0.891414, test rmse 0.921741 ===\n",
      "Epoch 11\n",
      "Iter=100, loss=0.8673, rmse=0.8648, time=0.0171\n",
      "Iter=200, loss=0.8668, rmse=0.8643, time=0.0170\n",
      "Iter=300, loss=0.8889, rmse=0.8863, time=0.0168\n",
      "Iter=400, loss=0.8919, rmse=0.8894, time=0.0168\n",
      "Iter=500, loss=0.8977, rmse=0.8952, time=0.0167\n",
      "Iter=600, loss=0.8850, rmse=0.8825, time=0.0167\n",
      "Iter=700, loss=0.9088, rmse=0.9063, time=0.0166\n",
      "Iter=800, loss=0.8915, rmse=0.8890, time=0.0166\n",
      "Iter=900, loss=0.8582, rmse=0.8556, time=0.0166\n",
      "Iter=1000, loss=0.9111, rmse=0.9085, time=0.0166\n",
      "Iter=1100, loss=0.9050, rmse=0.9023, time=0.0166\n",
      "Iter=1200, loss=0.8528, rmse=0.8502, time=0.0166\n",
      "Iter=1300, loss=0.8389, rmse=0.8363, time=0.0166\n",
      "Iter=1400, loss=0.8702, rmse=0.8677, time=0.0166\n",
      "Iter=1500, loss=0.8876, rmse=0.8851, time=0.0166\n",
      "Iter=1600, loss=0.9174, rmse=0.9149, time=0.0166\n",
      "Iter=1700, loss=0.9218, rmse=0.9192, time=0.0166\n",
      "Iter=1800, loss=0.8788, rmse=0.8761, time=0.0166\n",
      "Iter=1900, loss=0.9012, rmse=0.8986, time=0.0166\n",
      "Iter=2000, loss=0.9168, rmse=0.9142, time=0.0166\n",
      "=== Epoch 11, train loss 0.887879, test rmse 0.925373 ===\n",
      "Epoch 12\n",
      "Iter=100, loss=0.8772, rmse=0.8747, time=0.0166\n",
      "Iter=200, loss=0.8984, rmse=0.8958, time=0.0166\n",
      "Iter=300, loss=0.8992, rmse=0.8967, time=0.0166\n",
      "Iter=400, loss=0.8941, rmse=0.8915, time=0.0166\n",
      "Iter=500, loss=0.9069, rmse=0.9042, time=0.0167\n",
      "Iter=600, loss=0.9196, rmse=0.9170, time=0.0167\n",
      "Iter=700, loss=0.8588, rmse=0.8563, time=0.0167\n",
      "Iter=800, loss=0.9258, rmse=0.9233, time=0.0167\n",
      "Iter=900, loss=0.8950, rmse=0.8925, time=0.0166\n",
      "Iter=1000, loss=0.8620, rmse=0.8596, time=0.0166\n",
      "Iter=1100, loss=0.8837, rmse=0.8813, time=0.0167\n",
      "Iter=1200, loss=0.8851, rmse=0.8826, time=0.0167\n",
      "Iter=1300, loss=0.8441, rmse=0.8416, time=0.0167\n",
      "Iter=1400, loss=0.8503, rmse=0.8477, time=0.0167\n",
      "Iter=1500, loss=0.8959, rmse=0.8933, time=0.0167\n",
      "Iter=1600, loss=0.9044, rmse=0.9017, time=0.0167\n",
      "Iter=1700, loss=0.8869, rmse=0.8842, time=0.0167\n",
      "Iter=1800, loss=0.8839, rmse=0.8814, time=0.0167\n",
      "Iter=1900, loss=0.8681, rmse=0.8656, time=0.0167\n",
      "Iter=2000, loss=0.9104, rmse=0.9078, time=0.0167\n",
      "=== Epoch 12, train loss 0.887493, test rmse 0.933226 ===\n",
      "Epoch 13\n",
      "Iter=100, loss=0.8836, rmse=0.8809, time=0.0166\n",
      "Iter=200, loss=0.8866, rmse=0.8840, time=0.0166\n",
      "Iter=300, loss=0.8731, rmse=0.8704, time=0.0166\n",
      "Iter=400, loss=0.9144, rmse=0.9118, time=0.0166\n",
      "Iter=500, loss=0.8342, rmse=0.8316, time=0.0167\n",
      "Iter=600, loss=0.8688, rmse=0.8661, time=0.0166\n",
      "Iter=700, loss=0.8825, rmse=0.8799, time=0.0166\n",
      "Iter=800, loss=0.8805, rmse=0.8779, time=0.0166\n",
      "Iter=900, loss=0.8659, rmse=0.8634, time=0.0166\n",
      "Iter=1000, loss=0.9004, rmse=0.8979, time=0.0166\n",
      "Iter=1100, loss=0.9067, rmse=0.9041, time=0.0166\n",
      "Iter=1200, loss=0.8967, rmse=0.8940, time=0.0166\n",
      "Iter=1300, loss=0.8753, rmse=0.8725, time=0.0166\n",
      "Iter=1400, loss=0.9096, rmse=0.9069, time=0.0166\n",
      "Iter=1500, loss=0.8926, rmse=0.8899, time=0.0166\n",
      "Iter=1600, loss=0.9271, rmse=0.9245, time=0.0166\n",
      "Iter=1700, loss=0.9292, rmse=0.9267, time=0.0166\n",
      "Iter=1800, loss=0.8915, rmse=0.8890, time=0.0166\n",
      "Iter=1900, loss=0.8361, rmse=0.8336, time=0.0166\n",
      "Iter=2000, loss=0.8850, rmse=0.8825, time=0.0166\n",
      "=== Epoch 13, train loss 0.886993, test rmse 0.918627 ===\n",
      "Epoch 14\n",
      "Iter=100, loss=0.8877, rmse=0.8851, time=0.0167\n",
      "Iter=200, loss=0.8655, rmse=0.8629, time=0.0167\n",
      "Iter=300, loss=0.9188, rmse=0.9162, time=0.0166\n",
      "Iter=400, loss=0.8761, rmse=0.8735, time=0.0167\n",
      "Iter=500, loss=0.8904, rmse=0.8878, time=0.0167\n",
      "Iter=600, loss=0.8810, rmse=0.8785, time=0.0167\n",
      "Iter=700, loss=0.9149, rmse=0.9125, time=0.0167\n",
      "Iter=800, loss=0.9059, rmse=0.9034, time=0.0167\n",
      "Iter=900, loss=0.9186, rmse=0.9161, time=0.0167\n",
      "Iter=1000, loss=0.8508, rmse=0.8482, time=0.0167\n",
      "Iter=1100, loss=0.8609, rmse=0.8583, time=0.0167\n",
      "Iter=1200, loss=0.8458, rmse=0.8432, time=0.0167\n",
      "Iter=1300, loss=0.8428, rmse=0.8401, time=0.0167\n",
      "Iter=1400, loss=0.8652, rmse=0.8626, time=0.0167\n",
      "Iter=1500, loss=0.9119, rmse=0.9094, time=0.0167\n",
      "Iter=1600, loss=0.9151, rmse=0.9125, time=0.0167\n",
      "Iter=1700, loss=0.8943, rmse=0.8918, time=0.0167\n",
      "Iter=1800, loss=0.8688, rmse=0.8662, time=0.0167\n",
      "Iter=1900, loss=0.9014, rmse=0.8988, time=0.0167\n",
      "Iter=2000, loss=0.8907, rmse=0.8881, time=0.0167\n",
      "=== Epoch 14, train loss 0.885329, test rmse 0.927820 ===\n",
      "Epoch 15\n",
      "Iter=100, loss=0.9217, rmse=0.9190, time=0.0165\n",
      "Iter=200, loss=0.8477, rmse=0.8451, time=0.0166\n",
      "Iter=300, loss=0.8795, rmse=0.8769, time=0.0166\n",
      "Iter=400, loss=0.8431, rmse=0.8406, time=0.0166\n",
      "Iter=500, loss=0.8922, rmse=0.8898, time=0.0166\n",
      "Iter=600, loss=0.9300, rmse=0.9276, time=0.0166\n",
      "Iter=700, loss=0.8307, rmse=0.8282, time=0.0166\n",
      "Iter=800, loss=0.8747, rmse=0.8722, time=0.0166\n",
      "Iter=900, loss=0.8714, rmse=0.8690, time=0.0166\n",
      "Iter=1000, loss=0.8987, rmse=0.8962, time=0.0166\n",
      "Iter=1100, loss=0.9002, rmse=0.8976, time=0.0166\n",
      "Iter=1200, loss=0.8748, rmse=0.8722, time=0.0166\n",
      "Iter=1300, loss=0.8707, rmse=0.8681, time=0.0166\n",
      "Iter=1400, loss=0.8453, rmse=0.8425, time=0.0166\n",
      "Iter=1500, loss=0.9078, rmse=0.9050, time=0.0166\n",
      "Iter=1600, loss=0.9162, rmse=0.9134, time=0.0166\n",
      "Iter=1700, loss=0.8981, rmse=0.8955, time=0.0166\n",
      "Iter=1800, loss=0.8520, rmse=0.8494, time=0.0166\n",
      "Iter=1900, loss=0.8899, rmse=0.8872, time=0.0166\n",
      "Iter=2000, loss=0.8634, rmse=0.8608, time=0.0166\n",
      "=== Epoch 15, train loss 0.880398, test rmse 0.916851 ===\n",
      "Epoch 16\n",
      "Iter=100, loss=0.9263, rmse=0.9237, time=0.0166\n",
      "Iter=200, loss=0.8482, rmse=0.8455, time=0.0166\n",
      "Iter=300, loss=0.8362, rmse=0.8335, time=0.0166\n",
      "Iter=400, loss=0.8743, rmse=0.8717, time=0.0166\n",
      "Iter=500, loss=0.8862, rmse=0.8837, time=0.0166\n",
      "Iter=600, loss=0.8930, rmse=0.8904, time=0.0166\n",
      "Iter=700, loss=0.9105, rmse=0.9079, time=0.0166\n",
      "Iter=800, loss=0.9132, rmse=0.9106, time=0.0166\n",
      "Iter=900, loss=0.8644, rmse=0.8618, time=0.0166\n",
      "Iter=1000, loss=0.8695, rmse=0.8669, time=0.0166\n",
      "Iter=1100, loss=0.8971, rmse=0.8944, time=0.0166\n",
      "Iter=1200, loss=0.8685, rmse=0.8659, time=0.0166\n",
      "Iter=1300, loss=0.8882, rmse=0.8856, time=0.0166\n",
      "Iter=1400, loss=0.9017, rmse=0.8990, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=1500, loss=0.8537, rmse=0.8509, time=0.0166\n",
      "Iter=1600, loss=0.8745, rmse=0.8718, time=0.0166\n",
      "Iter=1700, loss=0.8634, rmse=0.8607, time=0.0166\n",
      "Iter=1800, loss=0.9121, rmse=0.9094, time=0.0166\n",
      "Iter=1900, loss=0.8723, rmse=0.8696, time=0.0166\n",
      "Iter=2000, loss=0.8635, rmse=0.8609, time=0.0166\n",
      "=== Epoch 16, train loss 0.880841, test rmse 0.916412 ===\n",
      "Epoch 17\n",
      "Iter=100, loss=0.8399, rmse=0.8371, time=0.0167\n",
      "Iter=200, loss=0.8658, rmse=0.8631, time=0.0168\n",
      "Iter=300, loss=0.9193, rmse=0.9165, time=0.0167\n",
      "Iter=400, loss=0.8625, rmse=0.8597, time=0.0167\n",
      "Iter=500, loss=0.8747, rmse=0.8719, time=0.0167\n",
      "Iter=600, loss=0.8958, rmse=0.8930, time=0.0167\n",
      "Iter=700, loss=0.9304, rmse=0.9277, time=0.0167\n",
      "Iter=800, loss=0.8792, rmse=0.8765, time=0.0167\n",
      "Iter=900, loss=0.8521, rmse=0.8494, time=0.0167\n",
      "Iter=1000, loss=0.8528, rmse=0.8501, time=0.0167\n",
      "Iter=1100, loss=0.8706, rmse=0.8678, time=0.0167\n",
      "Iter=1200, loss=0.8929, rmse=0.8901, time=0.0167\n",
      "Iter=1300, loss=0.8988, rmse=0.8960, time=0.0167\n",
      "Iter=1400, loss=0.9167, rmse=0.9139, time=0.0167\n",
      "Iter=1500, loss=0.9011, rmse=0.8984, time=0.0167\n",
      "Iter=1600, loss=0.8620, rmse=0.8592, time=0.0167\n",
      "Iter=1700, loss=0.8518, rmse=0.8491, time=0.0167\n",
      "Iter=1800, loss=0.9206, rmse=0.9179, time=0.0167\n",
      "Iter=1900, loss=0.8455, rmse=0.8428, time=0.0167\n",
      "Iter=2000, loss=0.8807, rmse=0.8781, time=0.0167\n",
      "=== Epoch 17, train loss 0.880666, test rmse 0.915903 ===\n",
      "Epoch 18\n",
      "Iter=100, loss=0.8887, rmse=0.8862, time=0.0167\n",
      "Iter=200, loss=0.8537, rmse=0.8512, time=0.0167\n",
      "Iter=300, loss=0.8508, rmse=0.8482, time=0.0168\n",
      "Iter=400, loss=0.8577, rmse=0.8551, time=0.0168\n",
      "Iter=500, loss=0.8694, rmse=0.8667, time=0.0168\n",
      "Iter=600, loss=0.8888, rmse=0.8861, time=0.0167\n",
      "Iter=700, loss=0.8734, rmse=0.8707, time=0.0167\n",
      "Iter=800, loss=0.9505, rmse=0.9477, time=0.0167\n",
      "Iter=900, loss=0.9189, rmse=0.9162, time=0.0167\n",
      "Iter=1000, loss=0.8859, rmse=0.8831, time=0.0167\n",
      "Iter=1100, loss=0.8492, rmse=0.8465, time=0.0167\n",
      "Iter=1200, loss=0.8709, rmse=0.8683, time=0.0167\n",
      "Iter=1300, loss=0.8679, rmse=0.8653, time=0.0167\n",
      "Iter=1400, loss=0.9059, rmse=0.9034, time=0.0167\n",
      "Iter=1500, loss=0.9006, rmse=0.8979, time=0.0167\n",
      "Iter=1600, loss=0.8775, rmse=0.8747, time=0.0167\n",
      "Iter=1700, loss=0.8797, rmse=0.8769, time=0.0167\n",
      "Iter=1800, loss=0.8806, rmse=0.8778, time=0.0167\n",
      "Iter=1900, loss=0.8900, rmse=0.8873, time=0.0167\n",
      "Iter=2000, loss=0.8567, rmse=0.8539, time=0.0167\n",
      "=== Epoch 18, train loss 0.880842, test rmse 0.912866 ===\n",
      "Epoch 19\n",
      "Iter=100, loss=0.8453, rmse=0.8427, time=0.0168\n",
      "Iter=200, loss=0.8812, rmse=0.8785, time=0.0167\n",
      "Iter=300, loss=0.8864, rmse=0.8836, time=0.0167\n",
      "Iter=400, loss=0.9108, rmse=0.9080, time=0.0167\n",
      "Iter=500, loss=0.8638, rmse=0.8610, time=0.0167\n",
      "Iter=600, loss=0.8995, rmse=0.8968, time=0.0168\n",
      "Iter=700, loss=0.8797, rmse=0.8770, time=0.0168\n",
      "Iter=800, loss=0.8771, rmse=0.8744, time=0.0168\n",
      "Iter=900, loss=0.8830, rmse=0.8803, time=0.0168\n",
      "Iter=1000, loss=0.8721, rmse=0.8694, time=0.0168\n",
      "Iter=1100, loss=0.8585, rmse=0.8559, time=0.0168\n",
      "Iter=1200, loss=0.9049, rmse=0.9022, time=0.0168\n",
      "Iter=1300, loss=0.8934, rmse=0.8908, time=0.0168\n",
      "Iter=1400, loss=0.8830, rmse=0.8804, time=0.0168\n",
      "Iter=1500, loss=0.8691, rmse=0.8665, time=0.0168\n",
      "Iter=1600, loss=0.8735, rmse=0.8710, time=0.0168\n",
      "Iter=1700, loss=0.9177, rmse=0.9152, time=0.0168\n",
      "Iter=1800, loss=0.8776, rmse=0.8749, time=0.0168\n",
      "Iter=1900, loss=0.8921, rmse=0.8895, time=0.0168\n",
      "Iter=2000, loss=0.8357, rmse=0.8330, time=0.0168\n",
      "=== Epoch 19, train loss 0.880226, test rmse 0.936271 ===\n",
      "Epoch 20\n",
      "Iter=100, loss=0.8684, rmse=0.8656, time=0.0168\n",
      "Iter=200, loss=0.8796, rmse=0.8769, time=0.0168\n",
      "Iter=300, loss=0.8656, rmse=0.8629, time=0.0168\n",
      "Iter=400, loss=0.8802, rmse=0.8775, time=0.0168\n",
      "Iter=500, loss=0.8829, rmse=0.8803, time=0.0168\n",
      "Iter=600, loss=0.8926, rmse=0.8899, time=0.0168\n",
      "Iter=700, loss=0.8756, rmse=0.8730, time=0.0168\n",
      "Iter=800, loss=0.9232, rmse=0.9206, time=0.0168\n",
      "Iter=900, loss=0.8511, rmse=0.8485, time=0.0168\n",
      "Iter=1000, loss=0.8799, rmse=0.8773, time=0.0168\n",
      "Iter=1100, loss=0.8461, rmse=0.8435, time=0.0168\n",
      "Iter=1200, loss=0.8885, rmse=0.8860, time=0.0168\n",
      "Iter=1300, loss=0.8490, rmse=0.8464, time=0.0168\n",
      "Iter=1400, loss=0.8812, rmse=0.8785, time=0.0168\n",
      "Iter=1500, loss=0.8618, rmse=0.8591, time=0.0168\n",
      "Iter=1600, loss=0.8815, rmse=0.8788, time=0.0168\n",
      "Iter=1700, loss=0.8692, rmse=0.8664, time=0.0168\n",
      "Iter=1800, loss=0.8758, rmse=0.8730, time=0.0168\n",
      "Iter=1900, loss=0.9112, rmse=0.9084, time=0.0168\n",
      "Iter=2000, loss=0.8947, rmse=0.8919, time=0.0168\n",
      "=== Epoch 20, train loss 0.877894, test rmse 0.916196 ===\n",
      "Epoch 21\n",
      "Iter=100, loss=0.8728, rmse=0.8701, time=0.0169\n",
      "Iter=200, loss=0.8403, rmse=0.8376, time=0.0169\n",
      "Iter=300, loss=0.9135, rmse=0.9109, time=0.0169\n",
      "Iter=400, loss=0.8967, rmse=0.8939, time=0.0169\n",
      "Iter=500, loss=0.9228, rmse=0.9201, time=0.0169\n",
      "Iter=600, loss=0.8373, rmse=0.8347, time=0.0169\n",
      "Iter=700, loss=0.8710, rmse=0.8685, time=0.0169\n",
      "Iter=800, loss=0.8850, rmse=0.8824, time=0.0169\n",
      "Iter=900, loss=0.8918, rmse=0.8892, time=0.0169\n",
      "Iter=1000, loss=0.8727, rmse=0.8701, time=0.0169\n",
      "Iter=1100, loss=0.8702, rmse=0.8675, time=0.0169\n",
      "Iter=1200, loss=0.9023, rmse=0.8996, time=0.0169\n",
      "Iter=1300, loss=0.8776, rmse=0.8749, time=0.0169\n",
      "Iter=1400, loss=0.8901, rmse=0.8874, time=0.0169\n",
      "Iter=1500, loss=0.9009, rmse=0.8983, time=0.0169\n",
      "Iter=1600, loss=0.8476, rmse=0.8449, time=0.0169\n",
      "Iter=1700, loss=0.8501, rmse=0.8473, time=0.0169\n",
      "Iter=1800, loss=0.8793, rmse=0.8766, time=0.0169\n",
      "Iter=1900, loss=0.8854, rmse=0.8826, time=0.0169\n",
      "Iter=2000, loss=0.8588, rmse=0.8562, time=0.0169\n",
      "=== Epoch 21, train loss 0.878309, test rmse 0.914531 ===\n",
      "Epoch 22\n",
      "Iter=100, loss=0.8934, rmse=0.8906, time=0.0169\n",
      "Iter=200, loss=0.8923, rmse=0.8896, time=0.0169\n",
      "Iter=300, loss=0.8944, rmse=0.8917, time=0.0169\n",
      "Iter=400, loss=0.8531, rmse=0.8504, time=0.0169\n",
      "Iter=500, loss=0.8987, rmse=0.8960, time=0.0169\n",
      "Iter=600, loss=0.8859, rmse=0.8832, time=0.0169\n",
      "Iter=700, loss=0.8745, rmse=0.8718, time=0.0169\n",
      "Iter=800, loss=0.8892, rmse=0.8865, time=0.0169\n",
      "Iter=900, loss=0.8629, rmse=0.8602, time=0.0169\n",
      "Iter=1000, loss=0.8906, rmse=0.8878, time=0.0169\n",
      "Iter=1100, loss=0.8539, rmse=0.8511, time=0.0169\n",
      "Iter=1200, loss=0.9051, rmse=0.9023, time=0.0169\n",
      "Iter=1300, loss=0.8852, rmse=0.8823, time=0.0169\n",
      "Iter=1400, loss=0.8211, rmse=0.8183, time=0.0169\n",
      "Iter=1500, loss=0.8886, rmse=0.8859, time=0.0169\n",
      "Iter=1600, loss=0.9042, rmse=0.9015, time=0.0169\n",
      "Iter=1700, loss=0.8899, rmse=0.8871, time=0.0169\n",
      "Iter=1800, loss=0.8733, rmse=0.8705, time=0.0169\n",
      "Iter=1900, loss=0.8455, rmse=0.8426, time=0.0169\n",
      "Iter=2000, loss=0.8715, rmse=0.8688, time=0.0169\n",
      "=== Epoch 22, train loss 0.878662, test rmse 0.913469 ===\n",
      "Epoch 23\n",
      "Iter=100, loss=0.8654, rmse=0.8626, time=0.0168\n",
      "Iter=200, loss=0.8996, rmse=0.8968, time=0.0168\n",
      "Iter=300, loss=0.8966, rmse=0.8938, time=0.0167\n",
      "Iter=400, loss=0.8666, rmse=0.8638, time=0.0167\n",
      "Iter=500, loss=0.8888, rmse=0.8860, time=0.0166\n",
      "Iter=600, loss=0.8985, rmse=0.8956, time=0.0166\n",
      "Iter=700, loss=0.8723, rmse=0.8695, time=0.0166\n",
      "Iter=800, loss=0.8586, rmse=0.8558, time=0.0166\n",
      "Iter=900, loss=0.8469, rmse=0.8441, time=0.0166\n",
      "Iter=1000, loss=0.8458, rmse=0.8431, time=0.0166\n",
      "Iter=1100, loss=0.8541, rmse=0.8514, time=0.0166\n",
      "Iter=1200, loss=0.8470, rmse=0.8442, time=0.0166\n",
      "Iter=1300, loss=0.8320, rmse=0.8292, time=0.0166\n",
      "Iter=1400, loss=0.8859, rmse=0.8831, time=0.0166\n",
      "Iter=1500, loss=0.9111, rmse=0.9082, time=0.0166\n",
      "Iter=1600, loss=0.8902, rmse=0.8873, time=0.0166\n",
      "Iter=1700, loss=0.8643, rmse=0.8615, time=0.0166\n",
      "Iter=1800, loss=0.8867, rmse=0.8838, time=0.0166\n",
      "Iter=1900, loss=0.8960, rmse=0.8931, time=0.0166\n",
      "Iter=2000, loss=0.8931, rmse=0.8903, time=0.0166\n",
      "=== Epoch 23, train loss 0.874975, test rmse 0.919440 ===\n",
      "Epoch 24\n",
      "Iter=100, loss=0.8771, rmse=0.8744, time=0.0166\n",
      "Iter=200, loss=0.8558, rmse=0.8531, time=0.0167\n",
      "Iter=300, loss=0.9011, rmse=0.8984, time=0.0166\n",
      "Iter=400, loss=0.8888, rmse=0.8860, time=0.0166\n",
      "Iter=500, loss=0.9230, rmse=0.9201, time=0.0166\n",
      "Iter=600, loss=0.8386, rmse=0.8357, time=0.0166\n",
      "Iter=700, loss=0.8670, rmse=0.8640, time=0.0166\n",
      "Iter=800, loss=0.8785, rmse=0.8756, time=0.0165\n",
      "Iter=900, loss=0.8834, rmse=0.8804, time=0.0166\n",
      "Iter=1000, loss=0.9257, rmse=0.9226, time=0.0166\n",
      "Iter=1100, loss=0.8549, rmse=0.8519, time=0.0166\n",
      "Iter=1200, loss=0.8922, rmse=0.8893, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=1300, loss=0.8967, rmse=0.8938, time=0.0166\n",
      "Iter=1400, loss=0.8547, rmse=0.8518, time=0.0166\n",
      "Iter=1500, loss=0.8814, rmse=0.8787, time=0.0166\n",
      "Iter=1600, loss=0.8716, rmse=0.8689, time=0.0166\n",
      "Iter=1700, loss=0.8948, rmse=0.8921, time=0.0166\n",
      "Iter=1800, loss=0.8630, rmse=0.8602, time=0.0166\n",
      "Iter=1900, loss=0.8318, rmse=0.8290, time=0.0166\n",
      "Iter=2000, loss=0.9251, rmse=0.9224, time=0.0166\n",
      "=== Epoch 24, train loss 0.880270, test rmse 0.918339 ===\n",
      "Epoch 25\n",
      "Iter=100, loss=0.8657, rmse=0.8630, time=0.0167\n",
      "Iter=200, loss=0.8447, rmse=0.8418, time=0.0167\n",
      "Iter=300, loss=0.8725, rmse=0.8698, time=0.0167\n",
      "Iter=400, loss=0.8631, rmse=0.8602, time=0.0167\n",
      "Iter=500, loss=0.8754, rmse=0.8726, time=0.0167\n",
      "Iter=600, loss=0.8929, rmse=0.8900, time=0.0166\n",
      "Iter=700, loss=0.8446, rmse=0.8417, time=0.0166\n",
      "Iter=800, loss=0.8605, rmse=0.8576, time=0.0166\n",
      "Iter=900, loss=0.8682, rmse=0.8653, time=0.0166\n",
      "Iter=1000, loss=0.8836, rmse=0.8806, time=0.0167\n",
      "Iter=1100, loss=0.8980, rmse=0.8950, time=0.0167\n",
      "Iter=1200, loss=0.8794, rmse=0.8765, time=0.0166\n",
      "Iter=1300, loss=0.8369, rmse=0.8339, time=0.0166\n",
      "Iter=1400, loss=0.9256, rmse=0.9227, time=0.0166\n",
      "Iter=1500, loss=0.8975, rmse=0.8946, time=0.0166\n",
      "Iter=1600, loss=0.8659, rmse=0.8631, time=0.0166\n",
      "Iter=1700, loss=0.8667, rmse=0.8639, time=0.0166\n",
      "Iter=1800, loss=0.9079, rmse=0.9050, time=0.0166\n",
      "Iter=1900, loss=0.8781, rmse=0.8753, time=0.0166\n",
      "Iter=2000, loss=0.8713, rmse=0.8686, time=0.0166\n",
      "=== Epoch 25, train loss 0.874919, test rmse 0.914404 ===\n",
      "Epoch 26\n",
      "Iter=100, loss=0.8692, rmse=0.8663, time=0.0167\n",
      "Iter=200, loss=0.8907, rmse=0.8878, time=0.0167\n",
      "Iter=300, loss=0.8973, rmse=0.8945, time=0.0167\n",
      "Iter=400, loss=0.8791, rmse=0.8763, time=0.0167\n",
      "Iter=500, loss=0.8849, rmse=0.8821, time=0.0167\n",
      "Iter=600, loss=0.8777, rmse=0.8750, time=0.0167\n",
      "Iter=700, loss=0.8378, rmse=0.8351, time=0.0166\n",
      "Iter=800, loss=0.8767, rmse=0.8738, time=0.0166\n",
      "Iter=900, loss=0.8568, rmse=0.8540, time=0.0166\n",
      "Iter=1000, loss=0.8644, rmse=0.8615, time=0.0166\n",
      "Iter=1100, loss=0.9026, rmse=0.8997, time=0.0167\n",
      "Iter=1200, loss=0.8532, rmse=0.8503, time=0.0166\n",
      "Iter=1300, loss=0.8996, rmse=0.8966, time=0.0166\n",
      "Iter=1400, loss=0.9280, rmse=0.9251, time=0.0166\n",
      "Iter=1500, loss=0.8982, rmse=0.8952, time=0.0166\n",
      "Iter=1600, loss=0.8621, rmse=0.8592, time=0.0166\n",
      "Iter=1700, loss=0.8616, rmse=0.8587, time=0.0166\n",
      "Iter=1800, loss=0.8650, rmse=0.8621, time=0.0166\n",
      "Iter=1900, loss=0.8393, rmse=0.8364, time=0.0167\n",
      "Iter=2000, loss=0.8870, rmse=0.8842, time=0.0167\n",
      "=== Epoch 26, train loss 0.876551, test rmse 0.919740 ===\n",
      "Epoch 27\n",
      "Iter=100, loss=0.8853, rmse=0.8823, time=0.0169\n",
      "Iter=200, loss=0.8538, rmse=0.8509, time=0.0168\n",
      "Iter=300, loss=0.8949, rmse=0.8919, time=0.0168\n",
      "Iter=400, loss=0.8485, rmse=0.8456, time=0.0168\n",
      "Iter=500, loss=0.9126, rmse=0.9097, time=0.0168\n",
      "Iter=600, loss=0.8982, rmse=0.8954, time=0.0168\n",
      "Iter=700, loss=0.8830, rmse=0.8802, time=0.0168\n",
      "Iter=800, loss=0.8914, rmse=0.8887, time=0.0168\n",
      "Iter=900, loss=0.8695, rmse=0.8668, time=0.0168\n",
      "Iter=1000, loss=0.8689, rmse=0.8662, time=0.0168\n",
      "Iter=1100, loss=0.8961, rmse=0.8933, time=0.0168\n",
      "Iter=1200, loss=0.8913, rmse=0.8884, time=0.0168\n",
      "Iter=1300, loss=0.8691, rmse=0.8662, time=0.0168\n",
      "Iter=1400, loss=0.8766, rmse=0.8738, time=0.0168\n",
      "Iter=1500, loss=0.8583, rmse=0.8555, time=0.0167\n",
      "Iter=1600, loss=0.8536, rmse=0.8508, time=0.0167\n",
      "Iter=1700, loss=0.8468, rmse=0.8441, time=0.0167\n",
      "Iter=1800, loss=0.8660, rmse=0.8633, time=0.0167\n",
      "Iter=1900, loss=0.8537, rmse=0.8510, time=0.0167\n",
      "Iter=2000, loss=0.8888, rmse=0.8860, time=0.0167\n",
      "=== Epoch 27, train loss 0.875332, test rmse 0.914416 ===\n",
      "Epoch 28\n",
      "Iter=100, loss=0.9034, rmse=0.9007, time=0.0165\n",
      "Iter=200, loss=0.8676, rmse=0.8648, time=0.0165\n",
      "Iter=300, loss=0.8932, rmse=0.8903, time=0.0165\n",
      "Iter=400, loss=0.8832, rmse=0.8803, time=0.0165\n",
      "Iter=500, loss=0.8542, rmse=0.8513, time=0.0165\n",
      "Iter=600, loss=0.8735, rmse=0.8706, time=0.0165\n",
      "Iter=700, loss=0.8793, rmse=0.8764, time=0.0165\n",
      "Iter=800, loss=0.8861, rmse=0.8833, time=0.0165\n",
      "Iter=900, loss=0.8863, rmse=0.8834, time=0.0165\n",
      "Iter=1000, loss=0.8215, rmse=0.8187, time=0.0166\n",
      "Iter=1100, loss=0.8272, rmse=0.8243, time=0.0166\n",
      "Iter=1200, loss=0.8979, rmse=0.8952, time=0.0166\n",
      "Iter=1300, loss=0.8472, rmse=0.8445, time=0.0166\n",
      "Iter=1400, loss=0.8730, rmse=0.8703, time=0.0166\n",
      "Iter=1500, loss=0.8723, rmse=0.8695, time=0.0166\n",
      "Iter=1600, loss=0.8620, rmse=0.8592, time=0.0166\n",
      "Iter=1700, loss=0.8882, rmse=0.8854, time=0.0166\n",
      "Iter=1800, loss=0.9232, rmse=0.9205, time=0.0166\n",
      "Iter=1900, loss=0.8984, rmse=0.8956, time=0.0166\n",
      "Iter=2000, loss=0.8602, rmse=0.8574, time=0.0166\n",
      "=== Epoch 28, train loss 0.874895, test rmse 0.913772 ===\n",
      "Epoch 29\n",
      "Iter=100, loss=0.8816, rmse=0.8787, time=0.0167\n",
      "Iter=200, loss=0.8709, rmse=0.8679, time=0.0166\n",
      "Iter=300, loss=0.8834, rmse=0.8805, time=0.0168\n",
      "Iter=400, loss=0.8662, rmse=0.8633, time=0.0168\n",
      "Iter=500, loss=0.8721, rmse=0.8692, time=0.0168\n",
      "Iter=600, loss=0.8898, rmse=0.8868, time=0.0168\n",
      "Iter=700, loss=0.8864, rmse=0.8833, time=0.0168\n",
      "Iter=800, loss=0.8935, rmse=0.8904, time=0.0168\n",
      "Iter=900, loss=0.9006, rmse=0.8976, time=0.0168\n",
      "Iter=1000, loss=0.8404, rmse=0.8373, time=0.0168\n",
      "Iter=1100, loss=0.8634, rmse=0.8604, time=0.0168\n",
      "Iter=1200, loss=0.8897, rmse=0.8869, time=0.0168\n",
      "Iter=1300, loss=0.8832, rmse=0.8804, time=0.0168\n",
      "Iter=1400, loss=0.8861, rmse=0.8832, time=0.0168\n",
      "Iter=1500, loss=0.8896, rmse=0.8866, time=0.0167\n",
      "Iter=1600, loss=0.8468, rmse=0.8440, time=0.0167\n",
      "Iter=1700, loss=0.8447, rmse=0.8418, time=0.0168\n",
      "Iter=1800, loss=0.8747, rmse=0.8718, time=0.0168\n",
      "Iter=1900, loss=0.8691, rmse=0.8663, time=0.0168\n",
      "Iter=2000, loss=0.8618, rmse=0.8590, time=0.0167\n",
      "=== Epoch 29, train loss 0.874697, test rmse 0.925709 ===\n",
      "Epoch 30\n",
      "Iter=100, loss=0.8900, rmse=0.8871, time=0.0167\n",
      "Iter=200, loss=0.8529, rmse=0.8501, time=0.0167\n",
      "Iter=300, loss=0.8945, rmse=0.8917, time=0.0167\n",
      "Iter=400, loss=0.8860, rmse=0.8831, time=0.0167\n",
      "Iter=500, loss=0.8760, rmse=0.8731, time=0.0167\n",
      "Iter=600, loss=0.8731, rmse=0.8703, time=0.0167\n",
      "Iter=700, loss=0.8723, rmse=0.8695, time=0.0167\n",
      "Iter=800, loss=0.8725, rmse=0.8696, time=0.0167\n",
      "Iter=900, loss=0.8818, rmse=0.8789, time=0.0167\n",
      "Iter=1000, loss=0.9103, rmse=0.9073, time=0.0167\n",
      "Iter=1100, loss=0.8802, rmse=0.8772, time=0.0167\n",
      "Iter=1200, loss=0.8557, rmse=0.8528, time=0.0167\n",
      "Iter=1300, loss=0.8476, rmse=0.8447, time=0.0167\n",
      "Iter=1400, loss=0.9052, rmse=0.9024, time=0.0167\n",
      "Iter=1500, loss=0.8735, rmse=0.8706, time=0.0167\n",
      "Iter=1600, loss=0.8900, rmse=0.8873, time=0.0167\n",
      "Iter=1700, loss=0.8769, rmse=0.8741, time=0.0167\n",
      "Iter=1800, loss=0.8190, rmse=0.8161, time=0.0167\n",
      "Iter=1900, loss=0.8492, rmse=0.8463, time=0.0167\n",
      "Iter=2000, loss=0.8557, rmse=0.8528, time=0.0166\n",
      "=== Epoch 30, train loss 0.873111, test rmse 0.918270 ===\n",
      "Epoch 31\n",
      "Iter=100, loss=0.8244, rmse=0.8217, time=0.0164\n",
      "Iter=200, loss=0.8781, rmse=0.8755, time=0.0165\n",
      "Iter=300, loss=0.8692, rmse=0.8664, time=0.0165\n",
      "Iter=400, loss=0.8487, rmse=0.8458, time=0.0165\n",
      "Iter=500, loss=0.8723, rmse=0.8693, time=0.0165\n",
      "Iter=600, loss=0.8937, rmse=0.8906, time=0.0165\n",
      "Iter=700, loss=0.8447, rmse=0.8415, time=0.0165\n",
      "Iter=800, loss=0.8837, rmse=0.8806, time=0.0165\n",
      "Iter=900, loss=0.8917, rmse=0.8888, time=0.0165\n",
      "Iter=1000, loss=0.8834, rmse=0.8805, time=0.0165\n",
      "Iter=1100, loss=0.9174, rmse=0.9145, time=0.0165\n",
      "Iter=1200, loss=0.8928, rmse=0.8901, time=0.0165\n",
      "Iter=1300, loss=0.8427, rmse=0.8400, time=0.0165\n",
      "Iter=1400, loss=0.8652, rmse=0.8624, time=0.0165\n",
      "Iter=1500, loss=0.8703, rmse=0.8674, time=0.0165\n",
      "Iter=1600, loss=0.8914, rmse=0.8885, time=0.0165\n",
      "Iter=1700, loss=0.8929, rmse=0.8899, time=0.0165\n",
      "Iter=1800, loss=0.8517, rmse=0.8486, time=0.0165\n",
      "Iter=1900, loss=0.9095, rmse=0.9064, time=0.0165\n",
      "Iter=2000, loss=0.8561, rmse=0.8529, time=0.0165\n",
      "=== Epoch 31, train loss 0.874002, test rmse 0.915513 ===\n",
      "Epoch 32\n",
      "Iter=100, loss=0.9030, rmse=0.9000, time=0.0166\n",
      "Iter=200, loss=0.9157, rmse=0.9128, time=0.0165\n",
      "Iter=300, loss=0.8431, rmse=0.8401, time=0.0166\n",
      "Iter=400, loss=0.8873, rmse=0.8844, time=0.0166\n",
      "Iter=500, loss=0.8896, rmse=0.8868, time=0.0166\n",
      "Iter=600, loss=0.8471, rmse=0.8444, time=0.0166\n",
      "Iter=700, loss=0.8456, rmse=0.8428, time=0.0166\n",
      "Iter=800, loss=0.8604, rmse=0.8575, time=0.0166\n",
      "Iter=900, loss=0.8450, rmse=0.8421, time=0.0166\n",
      "Iter=1000, loss=0.8185, rmse=0.8157, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=1100, loss=0.8581, rmse=0.8551, time=0.0166\n",
      "Iter=1200, loss=0.8956, rmse=0.8927, time=0.0166\n",
      "Iter=1300, loss=0.8770, rmse=0.8740, time=0.0166\n",
      "Iter=1400, loss=0.8505, rmse=0.8476, time=0.0166\n",
      "Iter=1500, loss=0.8617, rmse=0.8590, time=0.0167\n",
      "Iter=1600, loss=0.8996, rmse=0.8968, time=0.0167\n",
      "Iter=1700, loss=0.8848, rmse=0.8819, time=0.0167\n",
      "Iter=1800, loss=0.9025, rmse=0.8996, time=0.0167\n",
      "Iter=1900, loss=0.8809, rmse=0.8780, time=0.0167\n",
      "Iter=2000, loss=0.8836, rmse=0.8807, time=0.0167\n",
      "=== Epoch 32, train loss 0.872481, test rmse 0.917430 ===\n",
      "Epoch 33\n",
      "Iter=100, loss=0.8657, rmse=0.8628, time=0.0169\n",
      "Iter=200, loss=0.8548, rmse=0.8519, time=0.0168\n",
      "Iter=300, loss=0.8686, rmse=0.8657, time=0.0168\n",
      "Iter=400, loss=0.8676, rmse=0.8648, time=0.0168\n",
      "Iter=500, loss=0.8608, rmse=0.8580, time=0.0167\n",
      "Iter=600, loss=0.8745, rmse=0.8717, time=0.0167\n",
      "Iter=700, loss=0.8600, rmse=0.8571, time=0.0167\n",
      "Iter=800, loss=0.8771, rmse=0.8742, time=0.0167\n",
      "Iter=900, loss=0.8832, rmse=0.8803, time=0.0167\n",
      "Iter=1000, loss=0.9009, rmse=0.8979, time=0.0167\n",
      "Iter=1100, loss=0.8928, rmse=0.8898, time=0.0167\n",
      "Iter=1200, loss=0.8315, rmse=0.8286, time=0.0167\n",
      "Iter=1300, loss=0.8993, rmse=0.8964, time=0.0166\n",
      "Iter=1400, loss=0.8883, rmse=0.8855, time=0.0166\n",
      "Iter=1500, loss=0.8828, rmse=0.8801, time=0.0166\n",
      "Iter=1600, loss=0.8499, rmse=0.8471, time=0.0166\n",
      "Iter=1700, loss=0.9034, rmse=0.9006, time=0.0166\n",
      "Iter=1800, loss=0.8586, rmse=0.8556, time=0.0166\n",
      "Iter=1900, loss=0.8770, rmse=0.8740, time=0.0166\n",
      "Iter=2000, loss=0.9035, rmse=0.9004, time=0.0166\n",
      "=== Epoch 33, train loss 0.875035, test rmse 0.917967 ===\n",
      "Epoch 34\n",
      "Iter=100, loss=0.8810, rmse=0.8780, time=0.0165\n",
      "Iter=200, loss=0.8388, rmse=0.8358, time=0.0166\n",
      "Iter=300, loss=0.8951, rmse=0.8921, time=0.0166\n",
      "Iter=400, loss=0.8834, rmse=0.8805, time=0.0166\n",
      "Iter=500, loss=0.8742, rmse=0.8713, time=0.0166\n",
      "Iter=600, loss=0.8733, rmse=0.8704, time=0.0166\n",
      "Iter=700, loss=0.8693, rmse=0.8664, time=0.0166\n",
      "Iter=800, loss=0.8698, rmse=0.8670, time=0.0166\n",
      "Iter=900, loss=0.8703, rmse=0.8675, time=0.0166\n",
      "Iter=1000, loss=0.8812, rmse=0.8785, time=0.0166\n",
      "Iter=1100, loss=0.8571, rmse=0.8542, time=0.0166\n",
      "Iter=1200, loss=0.8898, rmse=0.8868, time=0.0166\n",
      "Iter=1300, loss=0.8733, rmse=0.8702, time=0.0166\n",
      "Iter=1400, loss=0.8992, rmse=0.8961, time=0.0166\n",
      "Iter=1500, loss=0.8739, rmse=0.8708, time=0.0166\n",
      "Iter=1600, loss=0.9158, rmse=0.9128, time=0.0166\n",
      "Iter=1700, loss=0.9058, rmse=0.9029, time=0.0166\n",
      "Iter=1800, loss=0.8948, rmse=0.8917, time=0.0166\n",
      "Iter=1900, loss=0.8420, rmse=0.8388, time=0.0166\n",
      "Iter=2000, loss=0.8192, rmse=0.8161, time=0.0166\n",
      "=== Epoch 34, train loss 0.875361, test rmse 0.910451 ===\n",
      "Epoch 35\n",
      "Iter=100, loss=0.8579, rmse=0.8548, time=0.0164\n",
      "Iter=200, loss=0.8541, rmse=0.8510, time=0.0165\n",
      "Iter=300, loss=0.8719, rmse=0.8689, time=0.0165\n",
      "Iter=400, loss=0.9384, rmse=0.9353, time=0.0165\n",
      "Iter=500, loss=0.8773, rmse=0.8742, time=0.0165\n",
      "Iter=600, loss=0.8905, rmse=0.8874, time=0.0165\n",
      "Iter=700, loss=0.8718, rmse=0.8686, time=0.0165\n",
      "Iter=800, loss=0.8483, rmse=0.8452, time=0.0165\n",
      "Iter=900, loss=0.8803, rmse=0.8772, time=0.0165\n",
      "Iter=1000, loss=0.8488, rmse=0.8458, time=0.0165\n",
      "Iter=1100, loss=0.9240, rmse=0.9209, time=0.0165\n",
      "Iter=1200, loss=0.9093, rmse=0.9063, time=0.0165\n",
      "Iter=1300, loss=0.8564, rmse=0.8534, time=0.0165\n",
      "Iter=1400, loss=0.8392, rmse=0.8361, time=0.0166\n",
      "Iter=1500, loss=0.8994, rmse=0.8964, time=0.0166\n",
      "Iter=1600, loss=0.8888, rmse=0.8856, time=0.0166\n",
      "Iter=1700, loss=0.8765, rmse=0.8735, time=0.0166\n",
      "Iter=1800, loss=0.8617, rmse=0.8587, time=0.0166\n",
      "Iter=1900, loss=0.8482, rmse=0.8452, time=0.0166\n",
      "Iter=2000, loss=0.8622, rmse=0.8594, time=0.0166\n",
      "=== Epoch 35, train loss 0.875253, test rmse 0.920510 ===\n",
      "Epoch 36\n",
      "Iter=100, loss=0.9011, rmse=0.8983, time=0.0167\n",
      "Iter=200, loss=0.8743, rmse=0.8715, time=0.0166\n",
      "Iter=300, loss=0.9027, rmse=0.8998, time=0.0166\n",
      "Iter=400, loss=0.8666, rmse=0.8637, time=0.0166\n",
      "Iter=500, loss=0.8222, rmse=0.8192, time=0.0166\n",
      "Iter=600, loss=0.8914, rmse=0.8883, time=0.0167\n",
      "Iter=700, loss=0.8461, rmse=0.8430, time=0.0167\n",
      "Iter=800, loss=0.8580, rmse=0.8549, time=0.0167\n",
      "Iter=900, loss=0.8999, rmse=0.8967, time=0.0167\n",
      "Iter=1000, loss=0.8666, rmse=0.8633, time=0.0167\n",
      "Iter=1100, loss=0.9119, rmse=0.9087, time=0.0167\n",
      "Iter=1200, loss=0.8737, rmse=0.8707, time=0.0167\n",
      "Iter=1300, loss=0.8862, rmse=0.8832, time=0.0167\n",
      "Iter=1400, loss=0.9021, rmse=0.8991, time=0.0167\n",
      "Iter=1500, loss=0.8862, rmse=0.8833, time=0.0167\n",
      "Iter=1600, loss=0.8527, rmse=0.8497, time=0.0167\n",
      "Iter=1700, loss=0.8581, rmse=0.8551, time=0.0167\n",
      "Iter=1800, loss=0.8848, rmse=0.8817, time=0.0167\n",
      "Iter=1900, loss=0.8842, rmse=0.8811, time=0.0166\n",
      "Iter=2000, loss=0.8292, rmse=0.8260, time=0.0166\n",
      "=== Epoch 36, train loss 0.874897, test rmse 0.921182 ===\n",
      "Epoch 37\n",
      "Iter=100, loss=0.8760, rmse=0.8727, time=0.0167\n",
      "Iter=200, loss=0.9027, rmse=0.8994, time=0.0167\n",
      "Iter=300, loss=0.8530, rmse=0.8498, time=0.0167\n",
      "Iter=400, loss=0.8570, rmse=0.8537, time=0.0166\n",
      "Iter=500, loss=0.8244, rmse=0.8211, time=0.0166\n",
      "Iter=600, loss=0.8864, rmse=0.8831, time=0.0166\n",
      "Iter=700, loss=0.8636, rmse=0.8603, time=0.0166\n",
      "Iter=800, loss=0.8526, rmse=0.8494, time=0.0166\n",
      "Iter=900, loss=0.8834, rmse=0.8802, time=0.0166\n",
      "Iter=1000, loss=0.8833, rmse=0.8801, time=0.0166\n",
      "Iter=1100, loss=0.8806, rmse=0.8775, time=0.0166\n",
      "Iter=1200, loss=0.8462, rmse=0.8432, time=0.0166\n",
      "Iter=1300, loss=0.8436, rmse=0.8406, time=0.0166\n",
      "Iter=1400, loss=0.9008, rmse=0.8978, time=0.0166\n",
      "Iter=1500, loss=0.9080, rmse=0.9051, time=0.0166\n",
      "Iter=1600, loss=0.8839, rmse=0.8810, time=0.0166\n",
      "Iter=1700, loss=0.8668, rmse=0.8639, time=0.0166\n",
      "Iter=1800, loss=0.8611, rmse=0.8582, time=0.0166\n",
      "Iter=1900, loss=0.8846, rmse=0.8816, time=0.0166\n",
      "Iter=2000, loss=0.8846, rmse=0.8817, time=0.0166\n",
      "=== Epoch 37, train loss 0.872125, test rmse 0.910592 ===\n",
      "Epoch 38\n",
      "Iter=100, loss=0.8388, rmse=0.8359, time=0.0167\n",
      "Iter=200, loss=0.8881, rmse=0.8851, time=0.0167\n",
      "Iter=300, loss=0.8803, rmse=0.8774, time=0.0167\n",
      "Iter=400, loss=0.8868, rmse=0.8839, time=0.0168\n",
      "Iter=500, loss=0.8825, rmse=0.8796, time=0.0168\n",
      "Iter=600, loss=0.8836, rmse=0.8807, time=0.0168\n",
      "Iter=700, loss=0.8638, rmse=0.8606, time=0.0168\n",
      "Iter=800, loss=0.8459, rmse=0.8428, time=0.0168\n",
      "Iter=900, loss=0.8692, rmse=0.8661, time=0.0168\n",
      "Iter=1000, loss=0.8644, rmse=0.8614, time=0.0168\n",
      "Iter=1100, loss=0.8329, rmse=0.8300, time=0.0168\n",
      "Iter=1200, loss=0.8798, rmse=0.8768, time=0.0168\n",
      "Iter=1300, loss=0.8957, rmse=0.8927, time=0.0168\n",
      "Iter=1400, loss=0.8653, rmse=0.8624, time=0.0168\n",
      "Iter=1500, loss=0.8627, rmse=0.8598, time=0.0168\n",
      "Iter=1600, loss=0.8784, rmse=0.8756, time=0.0168\n",
      "Iter=1700, loss=0.8667, rmse=0.8638, time=0.0168\n",
      "Iter=1800, loss=0.9126, rmse=0.9096, time=0.0168\n",
      "Iter=1900, loss=0.8496, rmse=0.8466, time=0.0168\n",
      "Iter=2000, loss=0.8904, rmse=0.8873, time=0.0168\n",
      "=== Epoch 38, train loss 0.871878, test rmse 0.921408 ===\n",
      "Epoch 39\n",
      "Iter=100, loss=0.9090, rmse=0.9061, time=0.0168\n",
      "Iter=200, loss=0.8817, rmse=0.8787, time=0.0168\n",
      "Iter=300, loss=0.8875, rmse=0.8845, time=0.0168\n",
      "Iter=400, loss=0.8493, rmse=0.8463, time=0.0168\n",
      "Iter=500, loss=0.8835, rmse=0.8804, time=0.0168\n",
      "Iter=600, loss=0.8537, rmse=0.8506, time=0.0167\n",
      "Iter=700, loss=0.8981, rmse=0.8950, time=0.0167\n",
      "Iter=800, loss=0.8869, rmse=0.8837, time=0.0167\n",
      "Iter=900, loss=0.8724, rmse=0.8693, time=0.0167\n",
      "Iter=1000, loss=0.8837, rmse=0.8805, time=0.0167\n",
      "Iter=1100, loss=0.8979, rmse=0.8947, time=0.0168\n",
      "Iter=1200, loss=0.8753, rmse=0.8721, time=0.0168\n",
      "Iter=1300, loss=0.8511, rmse=0.8480, time=0.0168\n",
      "Iter=1400, loss=0.8747, rmse=0.8716, time=0.0168\n",
      "Iter=1500, loss=0.8529, rmse=0.8498, time=0.0167\n",
      "Iter=1600, loss=0.9073, rmse=0.9041, time=0.0167\n",
      "Iter=1700, loss=0.8646, rmse=0.8615, time=0.0167\n",
      "Iter=1800, loss=0.8532, rmse=0.8501, time=0.0167\n",
      "Iter=1900, loss=0.8538, rmse=0.8506, time=0.0167\n",
      "Iter=2000, loss=0.8843, rmse=0.8812, time=0.0167\n",
      "=== Epoch 39, train loss 0.876050, test rmse 0.910034 ===\n",
      "Epoch 40\n",
      "Iter=100, loss=0.8427, rmse=0.8396, time=0.0166\n",
      "Iter=200, loss=0.9066, rmse=0.9034, time=0.0166\n",
      "Iter=300, loss=0.8443, rmse=0.8413, time=0.0166\n",
      "Iter=400, loss=0.8564, rmse=0.8535, time=0.0166\n",
      "Iter=500, loss=0.8598, rmse=0.8568, time=0.0166\n",
      "Iter=600, loss=0.8570, rmse=0.8537, time=0.0166\n",
      "Iter=700, loss=0.8630, rmse=0.8598, time=0.0166\n",
      "Iter=800, loss=0.8529, rmse=0.8497, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=900, loss=0.8830, rmse=0.8798, time=0.0166\n",
      "Iter=1000, loss=0.8911, rmse=0.8880, time=0.0165\n",
      "Iter=1100, loss=0.8780, rmse=0.8749, time=0.0165\n",
      "Iter=1200, loss=0.8586, rmse=0.8555, time=0.0165\n",
      "Iter=1300, loss=0.9013, rmse=0.8981, time=0.0165\n",
      "Iter=1400, loss=0.8570, rmse=0.8540, time=0.0165\n",
      "Iter=1500, loss=0.8728, rmse=0.8699, time=0.0165\n",
      "Iter=1600, loss=0.8848, rmse=0.8818, time=0.0165\n",
      "Iter=1700, loss=0.8635, rmse=0.8605, time=0.0165\n",
      "Iter=1800, loss=0.9086, rmse=0.9055, time=0.0165\n",
      "Iter=1900, loss=0.8106, rmse=0.8077, time=0.0166\n",
      "Iter=2000, loss=0.8855, rmse=0.8825, time=0.0165\n",
      "=== Epoch 40, train loss 0.868882, test rmse 0.922117 ===\n",
      "Epoch 41\n",
      "Iter=100, loss=0.8767, rmse=0.8737, time=0.0166\n",
      "Iter=200, loss=0.8803, rmse=0.8773, time=0.0167\n",
      "Iter=300, loss=0.8901, rmse=0.8870, time=0.0167\n",
      "Iter=400, loss=0.8509, rmse=0.8479, time=0.0167\n",
      "Iter=500, loss=0.8618, rmse=0.8587, time=0.0167\n",
      "Iter=600, loss=0.8667, rmse=0.8637, time=0.0167\n",
      "Iter=700, loss=0.8743, rmse=0.8712, time=0.0167\n",
      "Iter=800, loss=0.8193, rmse=0.8163, time=0.0166\n",
      "Iter=900, loss=0.8535, rmse=0.8504, time=0.0166\n",
      "Iter=1000, loss=0.8508, rmse=0.8477, time=0.0166\n",
      "Iter=1100, loss=0.8409, rmse=0.8379, time=0.0166\n",
      "Iter=1200, loss=0.8833, rmse=0.8803, time=0.0166\n",
      "Iter=1300, loss=0.8982, rmse=0.8951, time=0.0166\n",
      "Iter=1400, loss=0.8695, rmse=0.8665, time=0.0166\n",
      "Iter=1500, loss=0.8739, rmse=0.8709, time=0.0166\n",
      "Iter=1600, loss=0.8735, rmse=0.8705, time=0.0166\n",
      "Iter=1700, loss=0.8906, rmse=0.8875, time=0.0166\n",
      "Iter=1800, loss=0.8994, rmse=0.8964, time=0.0166\n",
      "Iter=1900, loss=0.8705, rmse=0.8675, time=0.0166\n",
      "Iter=2000, loss=0.8645, rmse=0.8615, time=0.0166\n",
      "=== Epoch 41, train loss 0.869429, test rmse 0.915585 ===\n",
      "Epoch 42\n",
      "Iter=100, loss=0.8643, rmse=0.8614, time=0.0165\n",
      "Iter=200, loss=0.8937, rmse=0.8907, time=0.0165\n",
      "Iter=300, loss=0.8898, rmse=0.8867, time=0.0165\n",
      "Iter=400, loss=0.8532, rmse=0.8500, time=0.0165\n",
      "Iter=500, loss=0.9253, rmse=0.9221, time=0.0165\n",
      "Iter=600, loss=0.8297, rmse=0.8265, time=0.0165\n",
      "Iter=700, loss=0.9267, rmse=0.9235, time=0.0165\n",
      "Iter=800, loss=0.8617, rmse=0.8584, time=0.0165\n",
      "Iter=900, loss=0.8675, rmse=0.8643, time=0.0165\n",
      "Iter=1000, loss=0.8434, rmse=0.8402, time=0.0165\n",
      "Iter=1100, loss=0.8551, rmse=0.8519, time=0.0165\n",
      "Iter=1200, loss=0.8340, rmse=0.8308, time=0.0165\n",
      "Iter=1300, loss=0.8953, rmse=0.8921, time=0.0165\n",
      "Iter=1400, loss=0.8824, rmse=0.8791, time=0.0165\n",
      "Iter=1500, loss=0.8450, rmse=0.8419, time=0.0165\n",
      "Iter=1600, loss=0.8878, rmse=0.8848, time=0.0165\n",
      "Iter=1700, loss=0.8587, rmse=0.8557, time=0.0165\n",
      "Iter=1800, loss=0.8983, rmse=0.8953, time=0.0165\n",
      "Iter=1900, loss=0.9037, rmse=0.9009, time=0.0165\n",
      "Iter=2000, loss=0.8014, rmse=0.7986, time=0.0165\n",
      "=== Epoch 42, train loss 0.870865, test rmse 0.914475 ===\n",
      "Epoch 43\n",
      "Iter=100, loss=0.8659, rmse=0.8630, time=0.0165\n",
      "Iter=200, loss=0.8575, rmse=0.8546, time=0.0165\n",
      "Iter=300, loss=0.8853, rmse=0.8824, time=0.0165\n",
      "Iter=400, loss=0.8523, rmse=0.8491, time=0.0165\n",
      "Iter=500, loss=0.8945, rmse=0.8913, time=0.0165\n",
      "Iter=600, loss=0.8877, rmse=0.8845, time=0.0165\n",
      "Iter=700, loss=0.9027, rmse=0.8995, time=0.0165\n",
      "Iter=800, loss=0.8658, rmse=0.8626, time=0.0166\n",
      "Iter=900, loss=0.8793, rmse=0.8761, time=0.0166\n",
      "Iter=1000, loss=0.8907, rmse=0.8877, time=0.0166\n",
      "Iter=1100, loss=0.8443, rmse=0.8412, time=0.0166\n",
      "Iter=1200, loss=0.8633, rmse=0.8603, time=0.0166\n",
      "Iter=1300, loss=0.9101, rmse=0.9072, time=0.0167\n",
      "Iter=1400, loss=0.8643, rmse=0.8613, time=0.0167\n",
      "Iter=1500, loss=0.8335, rmse=0.8304, time=0.0167\n",
      "Iter=1600, loss=0.8589, rmse=0.8558, time=0.0167\n",
      "Iter=1700, loss=0.8972, rmse=0.8943, time=0.0167\n",
      "Iter=1800, loss=0.8282, rmse=0.8252, time=0.0167\n",
      "Iter=1900, loss=0.8928, rmse=0.8898, time=0.0167\n",
      "Iter=2000, loss=0.8564, rmse=0.8534, time=0.0167\n",
      "=== Epoch 43, train loss 0.871539, test rmse 0.916466 ===\n",
      "Epoch 44\n",
      "Iter=100, loss=0.9298, rmse=0.9268, time=0.0168\n",
      "Iter=200, loss=0.8225, rmse=0.8195, time=0.0167\n",
      "Iter=300, loss=0.8833, rmse=0.8802, time=0.0167\n",
      "Iter=400, loss=0.8678, rmse=0.8647, time=0.0168\n",
      "Iter=500, loss=0.8548, rmse=0.8517, time=0.0168\n",
      "Iter=600, loss=0.8702, rmse=0.8672, time=0.0167\n",
      "Iter=700, loss=0.8677, rmse=0.8645, time=0.0167\n",
      "Iter=800, loss=0.8741, rmse=0.8710, time=0.0167\n",
      "Iter=900, loss=0.8865, rmse=0.8833, time=0.0167\n",
      "Iter=1000, loss=0.8565, rmse=0.8534, time=0.0167\n",
      "Iter=1100, loss=0.8564, rmse=0.8534, time=0.0167\n",
      "Iter=1200, loss=0.8889, rmse=0.8860, time=0.0167\n",
      "Iter=1300, loss=0.8528, rmse=0.8498, time=0.0167\n",
      "Iter=1400, loss=0.8941, rmse=0.8910, time=0.0167\n",
      "Iter=1500, loss=0.8804, rmse=0.8772, time=0.0167\n",
      "Iter=1600, loss=0.8917, rmse=0.8886, time=0.0167\n",
      "Iter=1700, loss=0.8475, rmse=0.8444, time=0.0167\n",
      "Iter=1800, loss=0.8787, rmse=0.8754, time=0.0167\n",
      "Iter=1900, loss=0.8702, rmse=0.8669, time=0.0167\n",
      "Iter=2000, loss=0.8582, rmse=0.8548, time=0.0167\n",
      "=== Epoch 44, train loss 0.871615, test rmse 0.917964 ===\n",
      "Epoch 45\n",
      "Iter=100, loss=0.8887, rmse=0.8854, time=0.0167\n",
      "Iter=200, loss=0.8697, rmse=0.8665, time=0.0166\n",
      "Iter=300, loss=0.8553, rmse=0.8521, time=0.0166\n",
      "Iter=400, loss=0.8827, rmse=0.8795, time=0.0166\n",
      "Iter=500, loss=0.8871, rmse=0.8838, time=0.0166\n",
      "Iter=600, loss=0.8176, rmse=0.8143, time=0.0166\n",
      "Iter=700, loss=0.8881, rmse=0.8848, time=0.0166\n",
      "Iter=800, loss=0.8677, rmse=0.8645, time=0.0166\n",
      "Iter=900, loss=0.8433, rmse=0.8401, time=0.0166\n",
      "Iter=1000, loss=0.8432, rmse=0.8400, time=0.0166\n",
      "Iter=1100, loss=0.8724, rmse=0.8691, time=0.0166\n",
      "Iter=1200, loss=0.8626, rmse=0.8594, time=0.0166\n",
      "Iter=1300, loss=0.8846, rmse=0.8816, time=0.0166\n",
      "Iter=1400, loss=0.8964, rmse=0.8935, time=0.0166\n",
      "Iter=1500, loss=0.8478, rmse=0.8449, time=0.0166\n",
      "Iter=1600, loss=0.8815, rmse=0.8787, time=0.0166\n",
      "Iter=1700, loss=0.8925, rmse=0.8896, time=0.0166\n",
      "Iter=1800, loss=0.8846, rmse=0.8816, time=0.0166\n",
      "Iter=1900, loss=0.8782, rmse=0.8751, time=0.0166\n",
      "Iter=2000, loss=0.8566, rmse=0.8535, time=0.0166\n",
      "=== Epoch 45, train loss 0.870034, test rmse 0.918243 ===\n",
      "Epoch 46\n",
      "Iter=100, loss=0.8416, rmse=0.8385, time=0.0167\n",
      "Iter=200, loss=0.8278, rmse=0.8247, time=0.0166\n",
      "Iter=300, loss=0.8252, rmse=0.8220, time=0.0165\n",
      "Iter=400, loss=0.8914, rmse=0.8881, time=0.0165\n",
      "Iter=500, loss=0.8645, rmse=0.8611, time=0.0165\n",
      "Iter=600, loss=0.8842, rmse=0.8809, time=0.0165\n",
      "Iter=700, loss=0.8786, rmse=0.8754, time=0.0165\n",
      "Iter=800, loss=0.8488, rmse=0.8456, time=0.0165\n",
      "Iter=900, loss=0.9093, rmse=0.9062, time=0.0165\n",
      "Iter=1000, loss=0.8881, rmse=0.8849, time=0.0165\n",
      "Iter=1100, loss=0.8847, rmse=0.8813, time=0.0165\n",
      "Iter=1200, loss=0.8505, rmse=0.8472, time=0.0165\n",
      "Iter=1300, loss=0.9055, rmse=0.9022, time=0.0165\n",
      "Iter=1400, loss=0.8865, rmse=0.8832, time=0.0165\n",
      "Iter=1500, loss=0.8162, rmse=0.8129, time=0.0165\n",
      "Iter=1600, loss=0.8733, rmse=0.8701, time=0.0165\n",
      "Iter=1700, loss=0.9076, rmse=0.9044, time=0.0165\n",
      "Iter=1800, loss=0.9051, rmse=0.9020, time=0.0165\n",
      "Iter=1900, loss=0.8465, rmse=0.8435, time=0.0165\n",
      "Iter=2000, loss=0.8665, rmse=0.8636, time=0.0165\n",
      "=== Epoch 46, train loss 0.870093, test rmse 0.911805 ===\n",
      "Epoch 47\n",
      "Iter=100, loss=0.8710, rmse=0.8683, time=0.0165\n",
      "Iter=200, loss=0.8590, rmse=0.8562, time=0.0165\n",
      "Iter=300, loss=0.8491, rmse=0.8462, time=0.0165\n",
      "Iter=400, loss=0.8431, rmse=0.8402, time=0.0165\n",
      "Iter=500, loss=0.8931, rmse=0.8901, time=0.0165\n",
      "Iter=600, loss=0.8899, rmse=0.8870, time=0.0165\n",
      "Iter=700, loss=0.8734, rmse=0.8704, time=0.0165\n",
      "Iter=800, loss=0.8863, rmse=0.8833, time=0.0165\n",
      "Iter=900, loss=0.8795, rmse=0.8767, time=0.0165\n",
      "Iter=1000, loss=0.8791, rmse=0.8763, time=0.0165\n",
      "Iter=1100, loss=0.8726, rmse=0.8697, time=0.0165\n",
      "Iter=1200, loss=0.8804, rmse=0.8775, time=0.0165\n",
      "Iter=1300, loss=0.8606, rmse=0.8576, time=0.0165\n",
      "Iter=1400, loss=0.8942, rmse=0.8912, time=0.0165\n",
      "Iter=1500, loss=0.8606, rmse=0.8575, time=0.0165\n",
      "Iter=1600, loss=0.8626, rmse=0.8596, time=0.0166\n",
      "Iter=1700, loss=0.9123, rmse=0.9093, time=0.0166\n",
      "Iter=1800, loss=0.8487, rmse=0.8457, time=0.0166\n",
      "Iter=1900, loss=0.8618, rmse=0.8589, time=0.0166\n",
      "Iter=2000, loss=0.8601, rmse=0.8572, time=0.0166\n",
      "=== Epoch 47, train loss 0.871873, test rmse 0.911478 ===\n",
      "Epoch 48\n",
      "Iter=100, loss=0.8283, rmse=0.8254, time=0.0168\n",
      "Iter=200, loss=0.8491, rmse=0.8461, time=0.0167\n",
      "Iter=300, loss=0.8448, rmse=0.8419, time=0.0167\n",
      "Iter=400, loss=0.8410, rmse=0.8380, time=0.0167\n",
      "Iter=500, loss=0.8692, rmse=0.8662, time=0.0167\n",
      "Iter=600, loss=0.8364, rmse=0.8334, time=0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=700, loss=0.8572, rmse=0.8541, time=0.0168\n",
      "Iter=800, loss=0.8634, rmse=0.8600, time=0.0168\n",
      "Iter=900, loss=0.8854, rmse=0.8821, time=0.0168\n",
      "Iter=1000, loss=0.8756, rmse=0.8725, time=0.0168\n",
      "Iter=1100, loss=0.8958, rmse=0.8928, time=0.0168\n",
      "Iter=1200, loss=0.9132, rmse=0.9101, time=0.0168\n",
      "Iter=1300, loss=0.8715, rmse=0.8684, time=0.0168\n",
      "Iter=1400, loss=0.8836, rmse=0.8804, time=0.0168\n",
      "Iter=1500, loss=0.8842, rmse=0.8811, time=0.0168\n",
      "Iter=1600, loss=0.9026, rmse=0.8995, time=0.0168\n",
      "Iter=1700, loss=0.8736, rmse=0.8706, time=0.0168\n",
      "Iter=1800, loss=0.8974, rmse=0.8943, time=0.0168\n",
      "Iter=1900, loss=0.8599, rmse=0.8568, time=0.0168\n",
      "Iter=2000, loss=0.8974, rmse=0.8944, time=0.0168\n",
      "=== Epoch 48, train loss 0.871480, test rmse 0.911461 ===\n",
      "Epoch 49\n",
      "Iter=100, loss=0.8532, rmse=0.8504, time=0.0166\n",
      "Iter=200, loss=0.8823, rmse=0.8793, time=0.0165\n",
      "Iter=300, loss=0.8556, rmse=0.8524, time=0.0165\n",
      "Iter=400, loss=0.8713, rmse=0.8682, time=0.0165\n",
      "Iter=500, loss=0.8826, rmse=0.8795, time=0.0165\n",
      "Iter=600, loss=0.8477, rmse=0.8446, time=0.0165\n",
      "Iter=700, loss=0.8518, rmse=0.8488, time=0.0165\n",
      "Iter=800, loss=0.9061, rmse=0.9030, time=0.0165\n",
      "Iter=900, loss=0.8284, rmse=0.8252, time=0.0165\n",
      "Iter=1000, loss=0.8655, rmse=0.8624, time=0.0165\n",
      "Iter=1100, loss=0.8768, rmse=0.8736, time=0.0165\n",
      "Iter=1200, loss=0.8770, rmse=0.8737, time=0.0165\n",
      "Iter=1300, loss=0.8211, rmse=0.8179, time=0.0165\n",
      "Iter=1400, loss=0.8399, rmse=0.8367, time=0.0165\n",
      "Iter=1500, loss=0.8744, rmse=0.8712, time=0.0165\n",
      "Iter=1600, loss=0.8724, rmse=0.8693, time=0.0165\n",
      "Iter=1700, loss=0.8780, rmse=0.8749, time=0.0165\n",
      "Iter=1800, loss=0.9193, rmse=0.9163, time=0.0165\n",
      "Iter=1900, loss=0.8903, rmse=0.8874, time=0.0165\n",
      "Iter=2000, loss=0.8829, rmse=0.8799, time=0.0165\n",
      "=== Epoch 49, train loss 0.868832, test rmse 0.912668 ===\n",
      "Epoch 50\n",
      "Iter=100, loss=0.8544, rmse=0.8513, time=0.0165\n",
      "Iter=200, loss=0.8477, rmse=0.8447, time=0.0165\n",
      "Iter=300, loss=0.8626, rmse=0.8595, time=0.0165\n",
      "Iter=400, loss=0.8686, rmse=0.8656, time=0.0165\n",
      "Iter=500, loss=0.8390, rmse=0.8360, time=0.0165\n",
      "Iter=600, loss=0.8547, rmse=0.8516, time=0.0165\n",
      "Iter=700, loss=0.8627, rmse=0.8596, time=0.0165\n",
      "Iter=800, loss=0.8918, rmse=0.8887, time=0.0165\n",
      "Iter=900, loss=0.9015, rmse=0.8983, time=0.0165\n",
      "Iter=1000, loss=0.8947, rmse=0.8916, time=0.0165\n",
      "Iter=1100, loss=0.9139, rmse=0.9108, time=0.0165\n",
      "Iter=1200, loss=0.8574, rmse=0.8543, time=0.0165\n",
      "Iter=1300, loss=0.8954, rmse=0.8922, time=0.0165\n",
      "Iter=1400, loss=0.8485, rmse=0.8452, time=0.0165\n",
      "Iter=1500, loss=0.8521, rmse=0.8489, time=0.0165\n",
      "Iter=1600, loss=0.8927, rmse=0.8896, time=0.0165\n",
      "Iter=1700, loss=0.8698, rmse=0.8667, time=0.0165\n",
      "Iter=1800, loss=0.8773, rmse=0.8742, time=0.0165\n",
      "Iter=1900, loss=0.8688, rmse=0.8658, time=0.0165\n",
      "Iter=2000, loss=0.8869, rmse=0.8838, time=0.0165\n",
      "=== Epoch 50, train loss 0.872027, test rmse 0.914596 ===\n",
      "Epoch 51\n",
      "Iter=100, loss=0.8530, rmse=0.8498, time=0.0166\n",
      "Iter=200, loss=0.8575, rmse=0.8543, time=0.0167\n",
      "Iter=300, loss=0.8668, rmse=0.8636, time=0.0166\n",
      "Iter=400, loss=0.8780, rmse=0.8748, time=0.0165\n",
      "Iter=500, loss=0.8565, rmse=0.8533, time=0.0165\n",
      "Iter=600, loss=0.8051, rmse=0.8019, time=0.0165\n",
      "Iter=700, loss=0.8513, rmse=0.8481, time=0.0166\n",
      "Iter=800, loss=0.8527, rmse=0.8496, time=0.0166\n",
      "Iter=900, loss=0.8532, rmse=0.8501, time=0.0166\n",
      "Iter=1000, loss=0.8511, rmse=0.8480, time=0.0166\n",
      "Iter=1100, loss=0.8556, rmse=0.8525, time=0.0166\n",
      "Iter=1200, loss=0.8160, rmse=0.8130, time=0.0166\n",
      "Iter=1300, loss=0.8197, rmse=0.8166, time=0.0166\n",
      "Iter=1400, loss=0.9130, rmse=0.9099, time=0.0166\n",
      "Iter=1500, loss=0.8631, rmse=0.8600, time=0.0166\n",
      "Iter=1600, loss=0.8114, rmse=0.8084, time=0.0166\n",
      "Iter=1700, loss=0.8303, rmse=0.8273, time=0.0166\n",
      "Iter=1800, loss=0.8820, rmse=0.8789, time=0.0167\n",
      "Iter=1900, loss=0.8445, rmse=0.8415, time=0.0167\n",
      "Iter=2000, loss=0.8808, rmse=0.8777, time=0.0167\n",
      "=== Epoch 51, train loss 0.852082, test rmse 0.906757 ===\n",
      "Epoch 52\n",
      "Iter=100, loss=0.8159, rmse=0.8129, time=0.0170\n",
      "Iter=200, loss=0.8324, rmse=0.8293, time=0.0170\n",
      "Iter=300, loss=0.8850, rmse=0.8820, time=0.0170\n",
      "Iter=400, loss=0.8181, rmse=0.8151, time=0.0170\n",
      "Iter=500, loss=0.8363, rmse=0.8332, time=0.0169\n",
      "Iter=600, loss=0.8328, rmse=0.8298, time=0.0169\n",
      "Iter=700, loss=0.8653, rmse=0.8623, time=0.0168\n",
      "Iter=800, loss=0.8378, rmse=0.8347, time=0.0168\n",
      "Iter=900, loss=0.8318, rmse=0.8288, time=0.0167\n",
      "Iter=1000, loss=0.8335, rmse=0.8305, time=0.0167\n",
      "Iter=1100, loss=0.8471, rmse=0.8441, time=0.0167\n",
      "Iter=1200, loss=0.8637, rmse=0.8607, time=0.0167\n",
      "Iter=1300, loss=0.8253, rmse=0.8222, time=0.0167\n",
      "Iter=1400, loss=0.8742, rmse=0.8711, time=0.0167\n",
      "Iter=1500, loss=0.8788, rmse=0.8758, time=0.0167\n",
      "Iter=1600, loss=0.8233, rmse=0.8203, time=0.0167\n",
      "Iter=1700, loss=0.8640, rmse=0.8610, time=0.0167\n",
      "Iter=1800, loss=0.8770, rmse=0.8740, time=0.0167\n",
      "Iter=1900, loss=0.8335, rmse=0.8305, time=0.0167\n",
      "Iter=2000, loss=0.8527, rmse=0.8498, time=0.0167\n",
      "=== Epoch 52, train loss 0.846433, test rmse 0.907780 ===\n",
      "Epoch 53\n",
      "Iter=100, loss=0.8486, rmse=0.8456, time=0.0165\n",
      "Iter=200, loss=0.8586, rmse=0.8556, time=0.0166\n",
      "Iter=300, loss=0.8806, rmse=0.8776, time=0.0166\n",
      "Iter=400, loss=0.8229, rmse=0.8199, time=0.0166\n",
      "Iter=500, loss=0.8753, rmse=0.8723, time=0.0166\n",
      "Iter=600, loss=0.8295, rmse=0.8265, time=0.0166\n",
      "Iter=700, loss=0.8187, rmse=0.8157, time=0.0166\n",
      "Iter=800, loss=0.8212, rmse=0.8181, time=0.0166\n",
      "Iter=900, loss=0.8721, rmse=0.8691, time=0.0166\n",
      "Iter=1000, loss=0.8379, rmse=0.8349, time=0.0166\n",
      "Iter=1100, loss=0.8162, rmse=0.8132, time=0.0166\n",
      "Iter=1200, loss=0.8300, rmse=0.8270, time=0.0166\n",
      "Iter=1300, loss=0.8000, rmse=0.7970, time=0.0165\n",
      "Iter=1400, loss=0.8610, rmse=0.8580, time=0.0165\n",
      "Iter=1500, loss=0.8408, rmse=0.8378, time=0.0165\n",
      "Iter=1600, loss=0.8809, rmse=0.8779, time=0.0165\n",
      "Iter=1700, loss=0.8557, rmse=0.8527, time=0.0165\n",
      "Iter=1800, loss=0.8836, rmse=0.8806, time=0.0165\n",
      "Iter=1900, loss=0.8598, rmse=0.8569, time=0.0165\n",
      "Iter=2000, loss=0.8338, rmse=0.8309, time=0.0165\n",
      "=== Epoch 53, train loss 0.846366, test rmse 0.907737 ===\n",
      "Epoch 54\n",
      "Iter=100, loss=0.8359, rmse=0.8330, time=0.0168\n",
      "Iter=200, loss=0.8539, rmse=0.8510, time=0.0168\n",
      "Iter=300, loss=0.8383, rmse=0.8354, time=0.0168\n",
      "Iter=400, loss=0.8167, rmse=0.8138, time=0.0168\n",
      "Iter=500, loss=0.8751, rmse=0.8722, time=0.0167\n",
      "Iter=600, loss=0.8678, rmse=0.8649, time=0.0168\n",
      "Iter=700, loss=0.8545, rmse=0.8516, time=0.0168\n",
      "Iter=800, loss=0.8229, rmse=0.8200, time=0.0168\n",
      "Iter=900, loss=0.8535, rmse=0.8506, time=0.0168\n",
      "Iter=1000, loss=0.8374, rmse=0.8345, time=0.0168\n",
      "Iter=1100, loss=0.8482, rmse=0.8452, time=0.0168\n",
      "Iter=1200, loss=0.8227, rmse=0.8198, time=0.0168\n",
      "Iter=1300, loss=0.8713, rmse=0.8684, time=0.0168\n",
      "Iter=1400, loss=0.8383, rmse=0.8354, time=0.0168\n",
      "Iter=1500, loss=0.8676, rmse=0.8647, time=0.0168\n",
      "Iter=1600, loss=0.8289, rmse=0.8260, time=0.0167\n",
      "Iter=1700, loss=0.8499, rmse=0.8470, time=0.0167\n",
      "Iter=1800, loss=0.8488, rmse=0.8458, time=0.0167\n",
      "Iter=1900, loss=0.8364, rmse=0.8335, time=0.0167\n",
      "Iter=2000, loss=0.8288, rmse=0.8259, time=0.0167\n",
      "=== Epoch 54, train loss 0.844852, test rmse 0.905409 ===\n",
      "Epoch 55\n",
      "Iter=100, loss=0.8800, rmse=0.8771, time=0.0165\n",
      "Iter=200, loss=0.8425, rmse=0.8396, time=0.0166\n",
      "Iter=300, loss=0.8114, rmse=0.8084, time=0.0166\n",
      "Iter=400, loss=0.8338, rmse=0.8308, time=0.0166\n",
      "Iter=500, loss=0.8608, rmse=0.8578, time=0.0166\n",
      "Iter=600, loss=0.8279, rmse=0.8249, time=0.0166\n",
      "Iter=700, loss=0.8084, rmse=0.8054, time=0.0166\n",
      "Iter=800, loss=0.8893, rmse=0.8864, time=0.0166\n",
      "Iter=900, loss=0.8250, rmse=0.8221, time=0.0166\n",
      "Iter=1000, loss=0.8550, rmse=0.8521, time=0.0166\n",
      "Iter=1100, loss=0.8156, rmse=0.8127, time=0.0166\n",
      "Iter=1200, loss=0.8542, rmse=0.8513, time=0.0166\n",
      "Iter=1300, loss=0.8184, rmse=0.8155, time=0.0166\n",
      "Iter=1400, loss=0.8787, rmse=0.8758, time=0.0166\n",
      "Iter=1500, loss=0.8286, rmse=0.8257, time=0.0166\n",
      "Iter=1600, loss=0.8614, rmse=0.8585, time=0.0166\n",
      "Iter=1700, loss=0.8475, rmse=0.8446, time=0.0166\n",
      "Iter=1800, loss=0.8189, rmse=0.8160, time=0.0166\n",
      "Iter=1900, loss=0.8535, rmse=0.8506, time=0.0166\n",
      "Iter=2000, loss=0.8536, rmse=0.8507, time=0.0166\n",
      "=== Epoch 55, train loss 0.843219, test rmse 0.908113 ===\n",
      "Epoch 56\n",
      "Iter=100, loss=0.8257, rmse=0.8228, time=0.0165\n",
      "Iter=200, loss=0.8136, rmse=0.8106, time=0.0166\n",
      "Iter=300, loss=0.8337, rmse=0.8308, time=0.0166\n",
      "Iter=400, loss=0.8572, rmse=0.8542, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=500, loss=0.8241, rmse=0.8212, time=0.0166\n",
      "Iter=600, loss=0.8443, rmse=0.8414, time=0.0165\n",
      "Iter=700, loss=0.8589, rmse=0.8560, time=0.0166\n",
      "Iter=800, loss=0.8653, rmse=0.8624, time=0.0166\n",
      "Iter=900, loss=0.8456, rmse=0.8426, time=0.0166\n",
      "Iter=1000, loss=0.8432, rmse=0.8403, time=0.0166\n",
      "Iter=1100, loss=0.8327, rmse=0.8298, time=0.0166\n",
      "Iter=1200, loss=0.8468, rmse=0.8439, time=0.0166\n",
      "Iter=1300, loss=0.8489, rmse=0.8461, time=0.0166\n",
      "Iter=1400, loss=0.8682, rmse=0.8653, time=0.0166\n",
      "Iter=1500, loss=0.8529, rmse=0.8501, time=0.0166\n",
      "Iter=1600, loss=0.8406, rmse=0.8378, time=0.0166\n",
      "Iter=1700, loss=0.8593, rmse=0.8564, time=0.0166\n",
      "Iter=1800, loss=0.8313, rmse=0.8285, time=0.0166\n",
      "Iter=1900, loss=0.8660, rmse=0.8632, time=0.0166\n",
      "Iter=2000, loss=0.8441, rmse=0.8412, time=0.0166\n",
      "=== Epoch 56, train loss 0.845122, test rmse 0.906003 ===\n",
      "Epoch 57\n",
      "Iter=100, loss=0.8064, rmse=0.8035, time=0.0169\n",
      "Iter=200, loss=0.8259, rmse=0.8230, time=0.0169\n",
      "Iter=300, loss=0.8851, rmse=0.8822, time=0.0169\n",
      "Iter=400, loss=0.8433, rmse=0.8405, time=0.0169\n",
      "Iter=500, loss=0.8222, rmse=0.8193, time=0.0169\n",
      "Iter=600, loss=0.8552, rmse=0.8523, time=0.0169\n",
      "Iter=700, loss=0.8348, rmse=0.8320, time=0.0169\n",
      "Iter=800, loss=0.8888, rmse=0.8859, time=0.0169\n",
      "Iter=900, loss=0.8159, rmse=0.8130, time=0.0169\n",
      "Iter=1000, loss=0.8545, rmse=0.8517, time=0.0169\n",
      "Iter=1100, loss=0.8638, rmse=0.8609, time=0.0169\n",
      "Iter=1200, loss=0.8665, rmse=0.8637, time=0.0169\n",
      "Iter=1300, loss=0.8568, rmse=0.8539, time=0.0169\n",
      "Iter=1400, loss=0.8399, rmse=0.8371, time=0.0169\n",
      "Iter=1500, loss=0.8317, rmse=0.8288, time=0.0169\n",
      "Iter=1600, loss=0.8241, rmse=0.8212, time=0.0169\n",
      "Iter=1700, loss=0.8308, rmse=0.8279, time=0.0169\n",
      "Iter=1800, loss=0.8542, rmse=0.8513, time=0.0169\n",
      "Iter=1900, loss=0.8279, rmse=0.8250, time=0.0169\n",
      "Iter=2000, loss=0.8332, rmse=0.8303, time=0.0169\n",
      "=== Epoch 57, train loss 0.843040, test rmse 0.905118 ===\n",
      "Epoch 58\n",
      "Iter=100, loss=0.8188, rmse=0.8159, time=0.0168\n",
      "Iter=200, loss=0.8437, rmse=0.8408, time=0.0168\n",
      "Iter=300, loss=0.8641, rmse=0.8612, time=0.0168\n",
      "Iter=400, loss=0.8094, rmse=0.8065, time=0.0168\n",
      "Iter=500, loss=0.8584, rmse=0.8555, time=0.0168\n",
      "Iter=600, loss=0.8419, rmse=0.8390, time=0.0168\n",
      "Iter=700, loss=0.8214, rmse=0.8185, time=0.0168\n",
      "Iter=800, loss=0.8399, rmse=0.8370, time=0.0168\n",
      "Iter=900, loss=0.8386, rmse=0.8358, time=0.0168\n",
      "Iter=1000, loss=0.8418, rmse=0.8389, time=0.0168\n",
      "Iter=1100, loss=0.8303, rmse=0.8274, time=0.0168\n",
      "Iter=1200, loss=0.8564, rmse=0.8535, time=0.0168\n",
      "Iter=1300, loss=0.8384, rmse=0.8355, time=0.0168\n",
      "Iter=1400, loss=0.8541, rmse=0.8512, time=0.0168\n",
      "Iter=1500, loss=0.8277, rmse=0.8248, time=0.0168\n",
      "Iter=1600, loss=0.8577, rmse=0.8548, time=0.0168\n",
      "Iter=1700, loss=0.8830, rmse=0.8802, time=0.0168\n",
      "Iter=1800, loss=0.8731, rmse=0.8702, time=0.0168\n",
      "Iter=1900, loss=0.8297, rmse=0.8269, time=0.0168\n",
      "Iter=2000, loss=0.8271, rmse=0.8242, time=0.0168\n",
      "=== Epoch 58, train loss 0.842773, test rmse 0.905558 ===\n",
      "Epoch 59\n",
      "Iter=100, loss=0.8337, rmse=0.8308, time=0.0165\n",
      "Iter=200, loss=0.8710, rmse=0.8681, time=0.0167\n",
      "Iter=300, loss=0.8535, rmse=0.8506, time=0.0167\n",
      "Iter=400, loss=0.8140, rmse=0.8111, time=0.0167\n",
      "Iter=500, loss=0.8457, rmse=0.8429, time=0.0167\n",
      "Iter=600, loss=0.8153, rmse=0.8124, time=0.0167\n",
      "Iter=700, loss=0.8356, rmse=0.8327, time=0.0167\n",
      "Iter=800, loss=0.8434, rmse=0.8405, time=0.0167\n",
      "Iter=900, loss=0.8641, rmse=0.8613, time=0.0167\n",
      "Iter=1000, loss=0.8604, rmse=0.8575, time=0.0167\n",
      "Iter=1100, loss=0.8541, rmse=0.8512, time=0.0167\n",
      "Iter=1200, loss=0.8642, rmse=0.8613, time=0.0167\n",
      "Iter=1300, loss=0.8597, rmse=0.8568, time=0.0167\n",
      "Iter=1400, loss=0.8553, rmse=0.8524, time=0.0167\n",
      "Iter=1500, loss=0.8383, rmse=0.8354, time=0.0167\n",
      "Iter=1600, loss=0.8428, rmse=0.8399, time=0.0167\n",
      "Iter=1700, loss=0.8043, rmse=0.8014, time=0.0167\n",
      "Iter=1800, loss=0.8355, rmse=0.8325, time=0.0167\n",
      "Iter=1900, loss=0.8178, rmse=0.8149, time=0.0167\n",
      "Iter=2000, loss=0.7828, rmse=0.7799, time=0.0167\n",
      "=== Epoch 59, train loss 0.839575, test rmse 0.908599 ===\n",
      "Epoch 60\n",
      "Iter=100, loss=0.8166, rmse=0.8137, time=0.0168\n",
      "Iter=200, loss=0.8186, rmse=0.8157, time=0.0168\n",
      "Iter=300, loss=0.8874, rmse=0.8845, time=0.0168\n",
      "Iter=400, loss=0.8254, rmse=0.8225, time=0.0168\n",
      "Iter=500, loss=0.8098, rmse=0.8069, time=0.0168\n",
      "Iter=600, loss=0.8399, rmse=0.8370, time=0.0168\n",
      "Iter=700, loss=0.8493, rmse=0.8464, time=0.0168\n",
      "Iter=800, loss=0.8499, rmse=0.8470, time=0.0168\n",
      "Iter=900, loss=0.8312, rmse=0.8283, time=0.0168\n",
      "Iter=1000, loss=0.8358, rmse=0.8329, time=0.0167\n",
      "Iter=1100, loss=0.8352, rmse=0.8323, time=0.0168\n",
      "Iter=1200, loss=0.8412, rmse=0.8383, time=0.0168\n",
      "Iter=1300, loss=0.8821, rmse=0.8792, time=0.0168\n",
      "Iter=1400, loss=0.8010, rmse=0.7981, time=0.0168\n",
      "Iter=1500, loss=0.7943, rmse=0.7914, time=0.0167\n",
      "Iter=1600, loss=0.8804, rmse=0.8775, time=0.0167\n",
      "Iter=1700, loss=0.8671, rmse=0.8642, time=0.0167\n",
      "Iter=1800, loss=0.8435, rmse=0.8407, time=0.0167\n",
      "Iter=1900, loss=0.8317, rmse=0.8288, time=0.0167\n",
      "Iter=2000, loss=0.8422, rmse=0.8393, time=0.0167\n",
      "=== Epoch 60, train loss 0.839129, test rmse 0.906432 ===\n",
      "Epoch 61\n",
      "Iter=100, loss=0.8343, rmse=0.8314, time=0.0167\n",
      "Iter=200, loss=0.8447, rmse=0.8418, time=0.0167\n",
      "Iter=300, loss=0.8272, rmse=0.8243, time=0.0167\n",
      "Iter=400, loss=0.8450, rmse=0.8421, time=0.0167\n",
      "Iter=500, loss=0.8625, rmse=0.8596, time=0.0167\n",
      "Iter=600, loss=0.8554, rmse=0.8525, time=0.0167\n",
      "Iter=700, loss=0.8447, rmse=0.8417, time=0.0167\n",
      "Iter=800, loss=0.8806, rmse=0.8777, time=0.0167\n",
      "Iter=900, loss=0.8336, rmse=0.8307, time=0.0167\n",
      "Iter=1000, loss=0.8324, rmse=0.8295, time=0.0167\n",
      "Iter=1100, loss=0.8592, rmse=0.8562, time=0.0167\n",
      "Iter=1200, loss=0.8059, rmse=0.8030, time=0.0167\n",
      "Iter=1300, loss=0.8222, rmse=0.8193, time=0.0167\n",
      "Iter=1400, loss=0.8091, rmse=0.8062, time=0.0167\n",
      "Iter=1500, loss=0.8698, rmse=0.8669, time=0.0167\n",
      "Iter=1600, loss=0.8540, rmse=0.8511, time=0.0167\n",
      "Iter=1700, loss=0.8515, rmse=0.8486, time=0.0167\n",
      "Iter=1800, loss=0.8349, rmse=0.8320, time=0.0167\n",
      "Iter=1900, loss=0.8509, rmse=0.8480, time=0.0167\n",
      "Iter=2000, loss=0.8628, rmse=0.8599, time=0.0167\n",
      "=== Epoch 61, train loss 0.844026, test rmse 0.906166 ===\n",
      "Epoch 62\n",
      "Iter=100, loss=0.8234, rmse=0.8206, time=0.0166\n",
      "Iter=200, loss=0.8153, rmse=0.8125, time=0.0166\n",
      "Iter=300, loss=0.8295, rmse=0.8266, time=0.0166\n",
      "Iter=400, loss=0.8072, rmse=0.8043, time=0.0166\n",
      "Iter=500, loss=0.7959, rmse=0.7930, time=0.0167\n",
      "Iter=600, loss=0.8791, rmse=0.8762, time=0.0167\n",
      "Iter=700, loss=0.8563, rmse=0.8534, time=0.0166\n",
      "Iter=800, loss=0.8255, rmse=0.8226, time=0.0167\n",
      "Iter=900, loss=0.8408, rmse=0.8379, time=0.0167\n",
      "Iter=1000, loss=0.8656, rmse=0.8627, time=0.0167\n",
      "Iter=1100, loss=0.8546, rmse=0.8517, time=0.0167\n",
      "Iter=1200, loss=0.8888, rmse=0.8859, time=0.0167\n",
      "Iter=1300, loss=0.8698, rmse=0.8670, time=0.0167\n",
      "Iter=1400, loss=0.8204, rmse=0.8175, time=0.0167\n",
      "Iter=1500, loss=0.8697, rmse=0.8668, time=0.0167\n",
      "Iter=1600, loss=0.8080, rmse=0.8051, time=0.0167\n",
      "Iter=1700, loss=0.8379, rmse=0.8351, time=0.0167\n",
      "Iter=1800, loss=0.8446, rmse=0.8418, time=0.0167\n",
      "Iter=1900, loss=0.8402, rmse=0.8373, time=0.0167\n",
      "Iter=2000, loss=0.8436, rmse=0.8407, time=0.0167\n",
      "=== Epoch 62, train loss 0.840809, test rmse 0.906201 ===\n",
      "Epoch 63\n",
      "Iter=100, loss=0.8016, rmse=0.7987, time=0.0167\n",
      "Iter=200, loss=0.8567, rmse=0.8539, time=0.0168\n",
      "Iter=300, loss=0.8155, rmse=0.8127, time=0.0168\n",
      "Iter=400, loss=0.8671, rmse=0.8642, time=0.0168\n",
      "Iter=500, loss=0.8397, rmse=0.8369, time=0.0168\n",
      "Iter=600, loss=0.8470, rmse=0.8441, time=0.0168\n",
      "Iter=700, loss=0.8086, rmse=0.8057, time=0.0168\n",
      "Iter=800, loss=0.8096, rmse=0.8068, time=0.0168\n",
      "Iter=900, loss=0.8589, rmse=0.8560, time=0.0168\n",
      "Iter=1000, loss=0.8798, rmse=0.8769, time=0.0168\n",
      "Iter=1100, loss=0.8429, rmse=0.8400, time=0.0168\n",
      "Iter=1200, loss=0.8395, rmse=0.8367, time=0.0168\n",
      "Iter=1300, loss=0.8472, rmse=0.8443, time=0.0168\n",
      "Iter=1400, loss=0.8471, rmse=0.8443, time=0.0168\n",
      "Iter=1500, loss=0.8082, rmse=0.8053, time=0.0168\n",
      "Iter=1600, loss=0.8475, rmse=0.8446, time=0.0168\n",
      "Iter=1700, loss=0.8212, rmse=0.8183, time=0.0168\n",
      "Iter=1800, loss=0.8930, rmse=0.8902, time=0.0167\n",
      "Iter=1900, loss=0.8112, rmse=0.8083, time=0.0167\n",
      "Iter=2000, loss=0.8838, rmse=0.8810, time=0.0167\n",
      "=== Epoch 63, train loss 0.841299, test rmse 0.906308 ===\n",
      "Epoch 64\n",
      "Iter=100, loss=0.8558, rmse=0.8530, time=0.0168\n",
      "Iter=200, loss=0.8111, rmse=0.8083, time=0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=300, loss=0.8759, rmse=0.8730, time=0.0167\n",
      "Iter=400, loss=0.8090, rmse=0.8062, time=0.0167\n",
      "Iter=500, loss=0.8469, rmse=0.8440, time=0.0167\n",
      "Iter=600, loss=0.8204, rmse=0.8176, time=0.0167\n",
      "Iter=700, loss=0.8844, rmse=0.8815, time=0.0167\n",
      "Iter=800, loss=0.8488, rmse=0.8459, time=0.0167\n",
      "Iter=900, loss=0.8575, rmse=0.8546, time=0.0167\n",
      "Iter=1000, loss=0.8355, rmse=0.8326, time=0.0167\n",
      "Iter=1100, loss=0.8431, rmse=0.8403, time=0.0167\n",
      "Iter=1200, loss=0.8461, rmse=0.8432, time=0.0167\n",
      "Iter=1300, loss=0.8616, rmse=0.8587, time=0.0167\n",
      "Iter=1400, loss=0.8503, rmse=0.8474, time=0.0167\n",
      "Iter=1500, loss=0.8499, rmse=0.8471, time=0.0167\n",
      "Iter=1600, loss=0.8196, rmse=0.8167, time=0.0167\n",
      "Iter=1700, loss=0.8285, rmse=0.8256, time=0.0167\n",
      "Iter=1800, loss=0.8348, rmse=0.8319, time=0.0167\n",
      "Iter=1900, loss=0.8167, rmse=0.8139, time=0.0167\n",
      "Iter=2000, loss=0.8301, rmse=0.8272, time=0.0167\n",
      "=== Epoch 64, train loss 0.841301, test rmse 0.905209 ===\n",
      "Epoch 65\n",
      "Iter=100, loss=0.8554, rmse=0.8525, time=0.0169\n",
      "Iter=200, loss=0.8315, rmse=0.8286, time=0.0168\n",
      "Iter=300, loss=0.8551, rmse=0.8522, time=0.0167\n",
      "Iter=400, loss=0.8427, rmse=0.8398, time=0.0167\n",
      "Iter=500, loss=0.8798, rmse=0.8770, time=0.0166\n",
      "Iter=600, loss=0.8166, rmse=0.8138, time=0.0166\n",
      "Iter=700, loss=0.8344, rmse=0.8316, time=0.0166\n",
      "Iter=800, loss=0.8345, rmse=0.8316, time=0.0166\n",
      "Iter=900, loss=0.8629, rmse=0.8600, time=0.0166\n",
      "Iter=1000, loss=0.8325, rmse=0.8297, time=0.0166\n",
      "Iter=1100, loss=0.8400, rmse=0.8371, time=0.0166\n",
      "Iter=1200, loss=0.8341, rmse=0.8312, time=0.0165\n",
      "Iter=1300, loss=0.8374, rmse=0.8346, time=0.0166\n",
      "Iter=1400, loss=0.8035, rmse=0.8007, time=0.0166\n",
      "Iter=1500, loss=0.8592, rmse=0.8564, time=0.0166\n",
      "Iter=1600, loss=0.8524, rmse=0.8495, time=0.0165\n",
      "Iter=1700, loss=0.8654, rmse=0.8626, time=0.0165\n",
      "Iter=1800, loss=0.8227, rmse=0.8198, time=0.0165\n",
      "Iter=1900, loss=0.8483, rmse=0.8454, time=0.0165\n",
      "Iter=2000, loss=0.8119, rmse=0.8090, time=0.0165\n",
      "=== Epoch 65, train loss 0.841021, test rmse 0.906029 ===\n",
      "Epoch 66\n",
      "Iter=100, loss=0.8220, rmse=0.8191, time=0.0164\n",
      "Iter=200, loss=0.8490, rmse=0.8462, time=0.0165\n",
      "Iter=300, loss=0.8558, rmse=0.8529, time=0.0165\n",
      "Iter=400, loss=0.8415, rmse=0.8386, time=0.0165\n",
      "Iter=500, loss=0.8869, rmse=0.8840, time=0.0165\n",
      "Iter=600, loss=0.8773, rmse=0.8744, time=0.0165\n",
      "Iter=700, loss=0.8385, rmse=0.8356, time=0.0165\n",
      "Iter=800, loss=0.8441, rmse=0.8412, time=0.0166\n",
      "Iter=900, loss=0.8263, rmse=0.8234, time=0.0166\n",
      "Iter=1000, loss=0.8736, rmse=0.8707, time=0.0166\n",
      "Iter=1100, loss=0.8266, rmse=0.8238, time=0.0166\n",
      "Iter=1200, loss=0.8292, rmse=0.8263, time=0.0166\n",
      "Iter=1300, loss=0.8171, rmse=0.8142, time=0.0166\n",
      "Iter=1400, loss=0.8754, rmse=0.8725, time=0.0167\n",
      "Iter=1500, loss=0.8190, rmse=0.8161, time=0.0167\n",
      "Iter=1600, loss=0.8419, rmse=0.8391, time=0.0167\n",
      "Iter=1700, loss=0.8309, rmse=0.8280, time=0.0167\n",
      "Iter=1800, loss=0.8572, rmse=0.8543, time=0.0167\n",
      "Iter=1900, loss=0.8164, rmse=0.8135, time=0.0167\n",
      "Iter=2000, loss=0.8006, rmse=0.7977, time=0.0167\n",
      "=== Epoch 66, train loss 0.841461, test rmse 0.904926 ===\n",
      "Epoch 67\n",
      "Iter=100, loss=0.8567, rmse=0.8538, time=0.0169\n",
      "Iter=200, loss=0.8204, rmse=0.8176, time=0.0168\n",
      "Iter=300, loss=0.8140, rmse=0.8111, time=0.0168\n",
      "Iter=400, loss=0.8484, rmse=0.8456, time=0.0168\n",
      "Iter=500, loss=0.8222, rmse=0.8193, time=0.0168\n",
      "Iter=600, loss=0.8193, rmse=0.8165, time=0.0168\n",
      "Iter=700, loss=0.8613, rmse=0.8584, time=0.0168\n",
      "Iter=800, loss=0.8429, rmse=0.8400, time=0.0168\n",
      "Iter=900, loss=0.8413, rmse=0.8384, time=0.0168\n",
      "Iter=1000, loss=0.8408, rmse=0.8380, time=0.0168\n",
      "Iter=1100, loss=0.8803, rmse=0.8774, time=0.0168\n",
      "Iter=1200, loss=0.8499, rmse=0.8470, time=0.0168\n",
      "Iter=1300, loss=0.8610, rmse=0.8582, time=0.0168\n",
      "Iter=1400, loss=0.8667, rmse=0.8639, time=0.0168\n",
      "Iter=1500, loss=0.8138, rmse=0.8109, time=0.0168\n",
      "Iter=1600, loss=0.8611, rmse=0.8582, time=0.0168\n",
      "Iter=1700, loss=0.8229, rmse=0.8201, time=0.0168\n",
      "Iter=1800, loss=0.8511, rmse=0.8482, time=0.0168\n",
      "Iter=1900, loss=0.8297, rmse=0.8269, time=0.0168\n",
      "Iter=2000, loss=0.8263, rmse=0.8235, time=0.0168\n",
      "=== Epoch 67, train loss 0.841517, test rmse 0.905760 ===\n",
      "Epoch 68\n",
      "Iter=100, loss=0.8486, rmse=0.8458, time=0.0167\n",
      "Iter=200, loss=0.8448, rmse=0.8419, time=0.0168\n",
      "Iter=300, loss=0.8784, rmse=0.8755, time=0.0168\n",
      "Iter=400, loss=0.8201, rmse=0.8172, time=0.0167\n",
      "Iter=500, loss=0.8577, rmse=0.8548, time=0.0167\n",
      "Iter=600, loss=0.7972, rmse=0.7943, time=0.0166\n",
      "Iter=700, loss=0.8183, rmse=0.8154, time=0.0166\n",
      "Iter=800, loss=0.8506, rmse=0.8477, time=0.0166\n",
      "Iter=900, loss=0.8137, rmse=0.8108, time=0.0166\n",
      "Iter=1000, loss=0.8368, rmse=0.8339, time=0.0166\n",
      "Iter=1100, loss=0.8615, rmse=0.8586, time=0.0166\n",
      "Iter=1200, loss=0.8191, rmse=0.8162, time=0.0166\n",
      "Iter=1300, loss=0.8569, rmse=0.8540, time=0.0166\n",
      "Iter=1400, loss=0.8884, rmse=0.8856, time=0.0166\n",
      "Iter=1500, loss=0.8454, rmse=0.8426, time=0.0166\n",
      "Iter=1600, loss=0.8240, rmse=0.8212, time=0.0166\n",
      "Iter=1700, loss=0.8554, rmse=0.8525, time=0.0166\n",
      "Iter=1800, loss=0.8440, rmse=0.8411, time=0.0166\n",
      "Iter=1900, loss=0.8358, rmse=0.8329, time=0.0166\n",
      "Iter=2000, loss=0.7952, rmse=0.7923, time=0.0166\n",
      "=== Epoch 68, train loss 0.839592, test rmse 0.906088 ===\n",
      "Epoch 69\n",
      "Iter=100, loss=0.8787, rmse=0.8758, time=0.0163\n",
      "Iter=200, loss=0.8425, rmse=0.8396, time=0.0164\n",
      "Iter=300, loss=0.8213, rmse=0.8184, time=0.0165\n",
      "Iter=400, loss=0.8279, rmse=0.8250, time=0.0165\n",
      "Iter=500, loss=0.8446, rmse=0.8417, time=0.0165\n",
      "Iter=600, loss=0.8649, rmse=0.8620, time=0.0165\n",
      "Iter=700, loss=0.8530, rmse=0.8501, time=0.0165\n",
      "Iter=800, loss=0.8368, rmse=0.8339, time=0.0165\n",
      "Iter=900, loss=0.8420, rmse=0.8391, time=0.0165\n",
      "Iter=1000, loss=0.8451, rmse=0.8422, time=0.0165\n",
      "Iter=1100, loss=0.8575, rmse=0.8546, time=0.0165\n",
      "Iter=1200, loss=0.8384, rmse=0.8355, time=0.0165\n",
      "Iter=1300, loss=0.8331, rmse=0.8302, time=0.0165\n",
      "Iter=1400, loss=0.8631, rmse=0.8602, time=0.0165\n",
      "Iter=1500, loss=0.8154, rmse=0.8125, time=0.0165\n",
      "Iter=1600, loss=0.8362, rmse=0.8333, time=0.0165\n",
      "Iter=1700, loss=0.8296, rmse=0.8267, time=0.0165\n",
      "Iter=1800, loss=0.8222, rmse=0.8193, time=0.0165\n",
      "Iter=1900, loss=0.8577, rmse=0.8548, time=0.0165\n",
      "Iter=2000, loss=0.7866, rmse=0.7837, time=0.0165\n",
      "=== Epoch 69, train loss 0.839831, test rmse 0.904091 ===\n",
      "Epoch 70\n",
      "Iter=100, loss=0.8486, rmse=0.8457, time=0.0166\n",
      "Iter=200, loss=0.8091, rmse=0.8062, time=0.0167\n",
      "Iter=300, loss=0.8520, rmse=0.8490, time=0.0167\n",
      "Iter=400, loss=0.8402, rmse=0.8372, time=0.0167\n",
      "Iter=500, loss=0.8397, rmse=0.8368, time=0.0167\n",
      "Iter=600, loss=0.8618, rmse=0.8589, time=0.0167\n",
      "Iter=700, loss=0.8101, rmse=0.8072, time=0.0167\n",
      "Iter=800, loss=0.8463, rmse=0.8434, time=0.0167\n",
      "Iter=900, loss=0.8219, rmse=0.8190, time=0.0167\n",
      "Iter=1000, loss=0.8144, rmse=0.8115, time=0.0167\n",
      "Iter=1100, loss=0.8453, rmse=0.8424, time=0.0167\n",
      "Iter=1200, loss=0.8626, rmse=0.8597, time=0.0167\n",
      "Iter=1300, loss=0.8400, rmse=0.8371, time=0.0167\n",
      "Iter=1400, loss=0.8355, rmse=0.8326, time=0.0167\n",
      "Iter=1500, loss=0.8200, rmse=0.8171, time=0.0167\n",
      "Iter=1600, loss=0.8489, rmse=0.8460, time=0.0167\n",
      "Iter=1700, loss=0.8280, rmse=0.8251, time=0.0167\n",
      "Iter=1800, loss=0.8367, rmse=0.8338, time=0.0167\n",
      "Iter=1900, loss=0.8684, rmse=0.8655, time=0.0167\n",
      "Iter=2000, loss=0.8451, rmse=0.8422, time=0.0167\n",
      "=== Epoch 70, train loss 0.838730, test rmse 0.906839 ===\n",
      "Epoch 71\n",
      "Iter=100, loss=0.8316, rmse=0.8286, time=0.0167\n",
      "Iter=200, loss=0.8458, rmse=0.8429, time=0.0167\n",
      "Iter=300, loss=0.8459, rmse=0.8430, time=0.0167\n",
      "Iter=400, loss=0.8369, rmse=0.8340, time=0.0167\n",
      "Iter=500, loss=0.8153, rmse=0.8124, time=0.0167\n",
      "Iter=600, loss=0.8183, rmse=0.8154, time=0.0167\n",
      "Iter=700, loss=0.8374, rmse=0.8345, time=0.0167\n",
      "Iter=800, loss=0.8451, rmse=0.8422, time=0.0167\n",
      "Iter=900, loss=0.8755, rmse=0.8726, time=0.0167\n",
      "Iter=1000, loss=0.8370, rmse=0.8340, time=0.0167\n",
      "Iter=1100, loss=0.8416, rmse=0.8387, time=0.0167\n",
      "Iter=1200, loss=0.8616, rmse=0.8587, time=0.0167\n",
      "Iter=1300, loss=0.8094, rmse=0.8065, time=0.0167\n",
      "Iter=1400, loss=0.8317, rmse=0.8288, time=0.0167\n",
      "Iter=1500, loss=0.8733, rmse=0.8704, time=0.0167\n",
      "Iter=1600, loss=0.8265, rmse=0.8236, time=0.0166\n",
      "Iter=1700, loss=0.8595, rmse=0.8566, time=0.0166\n",
      "Iter=1800, loss=0.8197, rmse=0.8168, time=0.0166\n",
      "Iter=1900, loss=0.8668, rmse=0.8639, time=0.0166\n",
      "Iter=2000, loss=0.8256, rmse=0.8227, time=0.0166\n",
      "=== Epoch 71, train loss 0.840221, test rmse 0.906265 ===\n",
      "Epoch 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=100, loss=0.8369, rmse=0.8340, time=0.0167\n",
      "Iter=200, loss=0.8181, rmse=0.8152, time=0.0167\n",
      "Iter=300, loss=0.8301, rmse=0.8272, time=0.0167\n",
      "Iter=400, loss=0.8522, rmse=0.8493, time=0.0167\n",
      "Iter=500, loss=0.8444, rmse=0.8415, time=0.0167\n",
      "Iter=600, loss=0.8322, rmse=0.8293, time=0.0167\n",
      "Iter=700, loss=0.8569, rmse=0.8540, time=0.0167\n",
      "Iter=800, loss=0.8505, rmse=0.8476, time=0.0167\n",
      "Iter=900, loss=0.8508, rmse=0.8479, time=0.0167\n",
      "Iter=1000, loss=0.8664, rmse=0.8635, time=0.0167\n",
      "Iter=1100, loss=0.8209, rmse=0.8179, time=0.0167\n",
      "Iter=1200, loss=0.8761, rmse=0.8732, time=0.0167\n",
      "Iter=1300, loss=0.8401, rmse=0.8372, time=0.0167\n",
      "Iter=1400, loss=0.8182, rmse=0.8153, time=0.0167\n",
      "Iter=1500, loss=0.8164, rmse=0.8136, time=0.0167\n",
      "Iter=1600, loss=0.8522, rmse=0.8493, time=0.0167\n",
      "Iter=1700, loss=0.8199, rmse=0.8170, time=0.0167\n",
      "Iter=1800, loss=0.8305, rmse=0.8276, time=0.0167\n",
      "Iter=1900, loss=0.7980, rmse=0.7951, time=0.0167\n",
      "Iter=2000, loss=0.8791, rmse=0.8762, time=0.0167\n",
      "=== Epoch 72, train loss 0.839507, test rmse 0.906567 ===\n",
      "Epoch 73\n",
      "Iter=100, loss=0.8366, rmse=0.8337, time=0.0167\n",
      "Iter=200, loss=0.8339, rmse=0.8310, time=0.0166\n",
      "Iter=300, loss=0.8618, rmse=0.8589, time=0.0167\n",
      "Iter=400, loss=0.8612, rmse=0.8583, time=0.0167\n",
      "Iter=500, loss=0.8113, rmse=0.8084, time=0.0167\n",
      "Iter=600, loss=0.8108, rmse=0.8079, time=0.0167\n",
      "Iter=700, loss=0.8499, rmse=0.8470, time=0.0166\n",
      "Iter=800, loss=0.8463, rmse=0.8434, time=0.0166\n",
      "Iter=900, loss=0.8586, rmse=0.8556, time=0.0166\n",
      "Iter=1000, loss=0.8589, rmse=0.8559, time=0.0166\n",
      "Iter=1100, loss=0.8200, rmse=0.8170, time=0.0166\n",
      "Iter=1200, loss=0.8119, rmse=0.8090, time=0.0166\n",
      "Iter=1300, loss=0.8717, rmse=0.8688, time=0.0166\n",
      "Iter=1400, loss=0.8233, rmse=0.8204, time=0.0166\n",
      "Iter=1500, loss=0.8386, rmse=0.8357, time=0.0166\n",
      "Iter=1600, loss=0.8440, rmse=0.8411, time=0.0166\n",
      "Iter=1700, loss=0.8302, rmse=0.8273, time=0.0166\n",
      "Iter=1800, loss=0.8520, rmse=0.8491, time=0.0166\n",
      "Iter=1900, loss=0.8395, rmse=0.8366, time=0.0165\n",
      "Iter=2000, loss=0.8340, rmse=0.8311, time=0.0165\n",
      "=== Epoch 73, train loss 0.839724, test rmse 0.905910 ===\n",
      "Epoch 74\n",
      "Iter=100, loss=0.8532, rmse=0.8503, time=0.0165\n",
      "Iter=200, loss=0.8408, rmse=0.8379, time=0.0166\n",
      "Iter=300, loss=0.8532, rmse=0.8502, time=0.0166\n",
      "Iter=400, loss=0.8285, rmse=0.8256, time=0.0166\n",
      "Iter=500, loss=0.8286, rmse=0.8257, time=0.0167\n",
      "Iter=600, loss=0.8263, rmse=0.8234, time=0.0166\n",
      "Iter=700, loss=0.8233, rmse=0.8204, time=0.0166\n",
      "Iter=800, loss=0.8154, rmse=0.8125, time=0.0166\n",
      "Iter=900, loss=0.7919, rmse=0.7890, time=0.0166\n",
      "Iter=1000, loss=0.8535, rmse=0.8506, time=0.0166\n",
      "Iter=1100, loss=0.8597, rmse=0.8568, time=0.0166\n",
      "Iter=1200, loss=0.8507, rmse=0.8478, time=0.0166\n",
      "Iter=1300, loss=0.8319, rmse=0.8290, time=0.0166\n",
      "Iter=1400, loss=0.8869, rmse=0.8840, time=0.0166\n",
      "Iter=1500, loss=0.8362, rmse=0.8333, time=0.0166\n",
      "Iter=1600, loss=0.8068, rmse=0.8039, time=0.0166\n",
      "Iter=1700, loss=0.8285, rmse=0.8256, time=0.0166\n",
      "Iter=1800, loss=0.8543, rmse=0.8514, time=0.0166\n",
      "Iter=1900, loss=0.8567, rmse=0.8538, time=0.0166\n",
      "Iter=2000, loss=0.8505, rmse=0.8476, time=0.0166\n",
      "=== Epoch 74, train loss 0.838854, test rmse 0.904860 ===\n",
      "Epoch 75\n",
      "Iter=100, loss=0.8753, rmse=0.8725, time=0.0168\n",
      "Iter=200, loss=0.8494, rmse=0.8466, time=0.0167\n",
      "Iter=300, loss=0.8170, rmse=0.8141, time=0.0167\n",
      "Iter=400, loss=0.8458, rmse=0.8429, time=0.0167\n",
      "Iter=500, loss=0.8103, rmse=0.8075, time=0.0167\n",
      "Iter=600, loss=0.8266, rmse=0.8237, time=0.0167\n",
      "Iter=700, loss=0.8675, rmse=0.8646, time=0.0167\n",
      "Iter=800, loss=0.8153, rmse=0.8125, time=0.0167\n",
      "Iter=900, loss=0.8698, rmse=0.8669, time=0.0167\n",
      "Iter=1000, loss=0.8515, rmse=0.8486, time=0.0167\n",
      "Iter=1100, loss=0.8203, rmse=0.8174, time=0.0167\n",
      "Iter=1200, loss=0.8238, rmse=0.8209, time=0.0167\n",
      "Iter=1300, loss=0.8337, rmse=0.8308, time=0.0167\n",
      "Iter=1400, loss=0.8159, rmse=0.8130, time=0.0167\n",
      "Iter=1500, loss=0.8492, rmse=0.8463, time=0.0167\n",
      "Iter=1600, loss=0.8167, rmse=0.8139, time=0.0167\n",
      "Iter=1700, loss=0.8252, rmse=0.8223, time=0.0167\n",
      "Iter=1800, loss=0.8757, rmse=0.8728, time=0.0167\n",
      "Iter=1900, loss=0.8618, rmse=0.8590, time=0.0167\n",
      "Iter=2000, loss=0.8455, rmse=0.8426, time=0.0167\n",
      "=== Epoch 75, train loss 0.839816, test rmse 0.904183 ===\n",
      "Epoch 76\n",
      "Iter=100, loss=0.8257, rmse=0.8229, time=0.0169\n",
      "Iter=200, loss=0.8370, rmse=0.8341, time=0.0169\n",
      "Iter=300, loss=0.8241, rmse=0.8213, time=0.0169\n",
      "Iter=400, loss=0.8233, rmse=0.8204, time=0.0169\n",
      "Iter=500, loss=0.8524, rmse=0.8495, time=0.0169\n",
      "Iter=600, loss=0.8655, rmse=0.8626, time=0.0169\n",
      "Iter=700, loss=0.8171, rmse=0.8142, time=0.0169\n",
      "Iter=800, loss=0.8106, rmse=0.8077, time=0.0169\n",
      "Iter=900, loss=0.8520, rmse=0.8491, time=0.0169\n",
      "Iter=1000, loss=0.8342, rmse=0.8313, time=0.0169\n",
      "Iter=1100, loss=0.8387, rmse=0.8357, time=0.0169\n",
      "Iter=1200, loss=0.8176, rmse=0.8146, time=0.0169\n",
      "Iter=1300, loss=0.8566, rmse=0.8537, time=0.0169\n",
      "Iter=1400, loss=0.8691, rmse=0.8662, time=0.0169\n",
      "Iter=1500, loss=0.8558, rmse=0.8528, time=0.0169\n",
      "Iter=1600, loss=0.8402, rmse=0.8373, time=0.0169\n",
      "Iter=1700, loss=0.8570, rmse=0.8541, time=0.0169\n",
      "Iter=1800, loss=0.8278, rmse=0.8249, time=0.0169\n",
      "Iter=1900, loss=0.8458, rmse=0.8429, time=0.0168\n",
      "Iter=2000, loss=0.7835, rmse=0.7806, time=0.0168\n",
      "=== Epoch 76, train loss 0.836698, test rmse 0.907106 ===\n",
      "Epoch 77\n",
      "Iter=100, loss=0.8270, rmse=0.8241, time=0.0168\n",
      "Iter=200, loss=0.8329, rmse=0.8300, time=0.0168\n",
      "Iter=300, loss=0.8175, rmse=0.8147, time=0.0168\n",
      "Iter=400, loss=0.8524, rmse=0.8495, time=0.0167\n",
      "Iter=500, loss=0.8282, rmse=0.8253, time=0.0168\n",
      "Iter=600, loss=0.8249, rmse=0.8220, time=0.0168\n",
      "Iter=700, loss=0.7997, rmse=0.7968, time=0.0167\n",
      "Iter=800, loss=0.8718, rmse=0.8689, time=0.0167\n",
      "Iter=900, loss=0.8604, rmse=0.8575, time=0.0167\n",
      "Iter=1000, loss=0.8510, rmse=0.8481, time=0.0167\n",
      "Iter=1100, loss=0.8362, rmse=0.8333, time=0.0167\n",
      "Iter=1200, loss=0.8603, rmse=0.8574, time=0.0167\n",
      "Iter=1300, loss=0.8321, rmse=0.8292, time=0.0167\n",
      "Iter=1400, loss=0.8323, rmse=0.8294, time=0.0167\n",
      "Iter=1500, loss=0.8564, rmse=0.8535, time=0.0167\n",
      "Iter=1600, loss=0.8490, rmse=0.8461, time=0.0167\n",
      "Iter=1700, loss=0.8179, rmse=0.8150, time=0.0167\n",
      "Iter=1800, loss=0.8435, rmse=0.8406, time=0.0167\n",
      "Iter=1900, loss=0.8493, rmse=0.8464, time=0.0167\n",
      "Iter=2000, loss=0.8388, rmse=0.8360, time=0.0167\n",
      "=== Epoch 77, train loss 0.839080, test rmse 0.904584 ===\n",
      "Epoch 78\n",
      "Iter=100, loss=0.7844, rmse=0.7815, time=0.0167\n",
      "Iter=200, loss=0.8804, rmse=0.8775, time=0.0167\n",
      "Iter=300, loss=0.8402, rmse=0.8373, time=0.0167\n",
      "Iter=400, loss=0.8543, rmse=0.8514, time=0.0168\n",
      "Iter=500, loss=0.8519, rmse=0.8490, time=0.0168\n",
      "Iter=600, loss=0.8334, rmse=0.8305, time=0.0168\n",
      "Iter=700, loss=0.8228, rmse=0.8199, time=0.0168\n",
      "Iter=800, loss=0.7906, rmse=0.7877, time=0.0168\n",
      "Iter=900, loss=0.8796, rmse=0.8767, time=0.0168\n",
      "Iter=1000, loss=0.8209, rmse=0.8180, time=0.0168\n",
      "Iter=1100, loss=0.8801, rmse=0.8772, time=0.0168\n",
      "Iter=1200, loss=0.8319, rmse=0.8290, time=0.0169\n",
      "Iter=1300, loss=0.8338, rmse=0.8308, time=0.0169\n",
      "Iter=1400, loss=0.8206, rmse=0.8177, time=0.0169\n",
      "Iter=1500, loss=0.8553, rmse=0.8525, time=0.0169\n",
      "Iter=1600, loss=0.8374, rmse=0.8346, time=0.0169\n",
      "Iter=1700, loss=0.8315, rmse=0.8286, time=0.0169\n",
      "Iter=1800, loss=0.8267, rmse=0.8238, time=0.0169\n",
      "Iter=1900, loss=0.8396, rmse=0.8367, time=0.0168\n",
      "Iter=2000, loss=0.8553, rmse=0.8524, time=0.0168\n",
      "=== Epoch 78, train loss 0.838544, test rmse 0.906718 ===\n",
      "Epoch 79\n",
      "Iter=100, loss=0.8646, rmse=0.8617, time=0.0166\n",
      "Iter=200, loss=0.7999, rmse=0.7970, time=0.0167\n",
      "Iter=300, loss=0.8058, rmse=0.8029, time=0.0167\n",
      "Iter=400, loss=0.8478, rmse=0.8449, time=0.0167\n",
      "Iter=500, loss=0.8527, rmse=0.8498, time=0.0167\n",
      "Iter=600, loss=0.8301, rmse=0.8272, time=0.0167\n",
      "Iter=700, loss=0.8192, rmse=0.8163, time=0.0167\n",
      "Iter=800, loss=0.8332, rmse=0.8302, time=0.0167\n",
      "Iter=900, loss=0.8567, rmse=0.8537, time=0.0167\n",
      "Iter=1000, loss=0.8357, rmse=0.8328, time=0.0167\n",
      "Iter=1100, loss=0.8709, rmse=0.8680, time=0.0167\n",
      "Iter=1200, loss=0.8572, rmse=0.8542, time=0.0167\n",
      "Iter=1300, loss=0.8509, rmse=0.8479, time=0.0166\n",
      "Iter=1400, loss=0.8565, rmse=0.8536, time=0.0166\n",
      "Iter=1500, loss=0.8322, rmse=0.8293, time=0.0166\n",
      "Iter=1600, loss=0.8626, rmse=0.8597, time=0.0166\n",
      "Iter=1700, loss=0.8544, rmse=0.8515, time=0.0166\n",
      "Iter=1800, loss=0.7956, rmse=0.7926, time=0.0166\n",
      "Iter=1900, loss=0.8110, rmse=0.8081, time=0.0166\n",
      "Iter=2000, loss=0.8411, rmse=0.8381, time=0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 79, train loss 0.838899, test rmse 0.905581 ===\n",
      "Epoch 80\n",
      "Iter=100, loss=0.8237, rmse=0.8208, time=0.0167\n",
      "Iter=200, loss=0.8262, rmse=0.8233, time=0.0166\n",
      "Iter=300, loss=0.8391, rmse=0.8361, time=0.0166\n",
      "Iter=400, loss=0.8328, rmse=0.8299, time=0.0166\n",
      "Iter=500, loss=0.8435, rmse=0.8406, time=0.0166\n",
      "Iter=600, loss=0.8528, rmse=0.8499, time=0.0166\n",
      "Iter=700, loss=0.8110, rmse=0.8080, time=0.0166\n",
      "Iter=800, loss=0.8316, rmse=0.8286, time=0.0166\n",
      "Iter=900, loss=0.8291, rmse=0.8261, time=0.0165\n",
      "Iter=1000, loss=0.8901, rmse=0.8872, time=0.0165\n",
      "Iter=1100, loss=0.8686, rmse=0.8656, time=0.0165\n",
      "Iter=1200, loss=0.8606, rmse=0.8576, time=0.0165\n",
      "Iter=1300, loss=0.8354, rmse=0.8324, time=0.0165\n",
      "Iter=1400, loss=0.8578, rmse=0.8548, time=0.0165\n",
      "Iter=1500, loss=0.8073, rmse=0.8043, time=0.0165\n",
      "Iter=1600, loss=0.8171, rmse=0.8142, time=0.0165\n",
      "Iter=1700, loss=0.8366, rmse=0.8337, time=0.0165\n",
      "Iter=1800, loss=0.8290, rmse=0.8261, time=0.0165\n",
      "Iter=1900, loss=0.8293, rmse=0.8264, time=0.0165\n",
      "Iter=2000, loss=0.8553, rmse=0.8524, time=0.0165\n",
      "=== Epoch 80, train loss 0.838841, test rmse 0.906122 ===\n",
      "Training ends. The best testing rmse is 0.904091 at epoch 69\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
